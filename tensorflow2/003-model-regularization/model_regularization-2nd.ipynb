{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NLokhlsVjOlU"
      },
      "source": [
        "# Model Regularization in Practice, an example with Keras and TensorFlow 2.0\n",
        "\n",
        "This is a notebook for the medium article [Model Regularization in Practice, an example with Keras and TensorFlow 2.0](https://medium.com/@bindiatwork/machine-learning-model-regularization-in-practice-an-example-with-keras-and-tensorflow-2-0-52a96746123e)\n",
        "\n",
        "Please check out article for instructions\n",
        "\n",
        "**License**: [BSD 2-Clause](https://opensource.org/licenses/BSD-2-Clause)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**tf.keras.regularizers.Regularizer**\n",
        "\n",
        "*Regularizer base class.*\n",
        "\n",
        "Regularizers allow you to apply penalties on layer parameters or layer activity during optimization. These penalties are summed into the loss function that the network optimizes.\n",
        "\n",
        "Regularization penalties are applied on a per-layer basis. The exact API will depend on the layer, but many layers (e.g. Dense, Conv1D, Conv2D and Conv3D) have a unified API.\n",
        "\n",
        "These layers expose 3 keyword arguments:\n",
        "\n",
        "**kernel_regularizer:** Regularizer to apply a penalty on the layer's kernel\n",
        "\n",
        "**bias_regularizer:** Regularizer to apply a penalty on the layer's bias\n",
        "\n",
        "**activity_regularizer:** Regularizer to apply a penalty on the layer's output"
      ],
      "metadata": {
        "id": "oCMl6CB8jQf_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dropout is a technique where randomly selected neurons are ignored during training. They are “dropped out” randomly. This means that their contribution to the activation of downstream neurons is temporally removed on the forward pass, and any weight updates are not applied to the neuron on the backward pass.**\n",
        "\n",
        "**“Dilution (also called Dropout or DropConnect) is a regularization technique for reducing overfitting in artificial neural networks by preventing complex co-adaptations on training data. It is an efficient way of performing model averaging with neural networks.”**\n",
        "\n",
        "**The Mechanics of Dropout**\n",
        "\n",
        "Dropout is a computationally cheap and effective technique used to reduce overfitting in neural networks. The technique works by randomly dropping out selected neurons during the training phase. Neurons in later layers do not reap the contribution of dropped-out neurons during forward propagation, nor will updates be made to the dropped-out neurons during backpropagation.\n",
        "\n",
        "“By dropping a unit out, we mean temporarily removing it from the network, along with all its incoming and outgoing connections”\n",
        "\n"
      ],
      "metadata": {
        "id": "ifWfy-GKl7fa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OwfOrTIYjOlf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "iris = load_iris()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wsIEOBr3jOlg"
      },
      "source": [
        "## Exploring data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "C76lSXa4jOlg"
      },
      "outputs": [],
      "source": [
        "# Load data into a DataFrame\n",
        "df = pd.DataFrame(iris.data, columns=iris.feature_names)\n",
        "# Convert datatype to float\n",
        "df = df.astype(float)\n",
        "# append \"target\" and name it \"label\"\n",
        "df['label'] = iris.target\n",
        "# Use string label instead\n",
        "df['label'] = df.label.replace(dict(enumerate(iris.target_names)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A146WBaJjOlh",
        "outputId": "f784d8bb-499a-4cca-cf01-06d42b3d46b1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>setosa</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "3                4.6               3.1                1.5               0.2   \n",
              "4                5.0               3.6                1.4               0.2   \n",
              "\n",
              "    label  \n",
              "0  setosa  \n",
              "1  setosa  \n",
              "2  setosa  \n",
              "3  setosa  \n",
              "4  setosa  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZqWZ3qEjOlh"
      },
      "source": [
        "### Preparing data for Keras and TensorFlow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "aynTZRtIjOli"
      },
      "outputs": [],
      "source": [
        "# label -> one-hot encoding\n",
        "label = pd.get_dummies(df['label'], prefix='label')\n",
        "df = pd.concat([df, label], axis=1)\n",
        "# drop old label\n",
        "df.drop(['label'], axis=1, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TSSFlMwgjOli",
        "outputId": "5f8e2593-2038-4f9d-a44c-7ff3d62dcffb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
              "0                5.1               3.5                1.4               0.2   \n",
              "1                4.9               3.0                1.4               0.2   \n",
              "2                4.7               3.2                1.3               0.2   \n",
              "3                4.6               3.1                1.5               0.2   \n",
              "4                5.0               3.6                1.4               0.2   \n",
              "\n",
              "   label_setosa  label_versicolor  label_virginica  \n",
              "0             1                 0                0  \n",
              "1             1                 0                0  \n",
              "2             1                 0                0  \n",
              "3             1                 0                0  \n",
              "4             1                 0                0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6c098bab-d6b1-4208-ac35-ec0411e8191b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sepal length (cm)</th>\n",
              "      <th>sepal width (cm)</th>\n",
              "      <th>petal length (cm)</th>\n",
              "      <th>petal width (cm)</th>\n",
              "      <th>label_setosa</th>\n",
              "      <th>label_versicolor</th>\n",
              "      <th>label_virginica</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.1</td>\n",
              "      <td>3.5</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.9</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.7</td>\n",
              "      <td>3.2</td>\n",
              "      <td>1.3</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.6</td>\n",
              "      <td>3.1</td>\n",
              "      <td>1.5</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5.0</td>\n",
              "      <td>3.6</td>\n",
              "      <td>1.4</td>\n",
              "      <td>0.2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6c098bab-d6b1-4208-ac35-ec0411e8191b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-6c098bab-d6b1-4208-ac35-ec0411e8191b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-6c098bab-d6b1-4208-ac35-ec0411e8191b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-a8f222a2-00ce-4e80-b5cf-9a0f4993ea46\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-a8f222a2-00ce-4e80-b5cf-9a0f4993ea46')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-a8f222a2-00ce-4e80-b5cf-9a0f4993ea46 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W_ZfFWbKjOli"
      },
      "outputs": [],
      "source": [
        "# Creating X and y\n",
        "\n",
        "X = df[['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)']]\n",
        "# Convert DataFrame into np array\n",
        "X = np.asarray(X)\n",
        "\n",
        "y = df[['label_setosa', 'label_versicolor', 'label_virginica']]\n",
        "# Convert DataFrame into np array\n",
        "y = np.asarray(y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "-FgTWZsmjOli"
      },
      "outputs": [],
      "source": [
        "# Split the data set in a training set (80%) and a test set (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "  X,\n",
        "  y,\n",
        "  test_size=0.20\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7tXda41PjOlj",
        "outputId": "05014477-29c6-4410-a0f2-ee70d25b8f94"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(120, 4)\n",
            "(30, 4)\n",
            "(120, 3)\n",
            "(30, 3)\n"
          ]
        }
      ],
      "source": [
        "print(X_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_train.shape)\n",
        "print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXwLOjpMjOlj"
      },
      "source": [
        "## 1. Build an unregularized neural network model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NkyIyuIrjOlj"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(4,)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(3, activation='softmax'),\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dg-cV0EcjOlj",
        "outputId": "cc333eb3-bcd4-4770-a62a-9728dfb39643"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 64)                320       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 128)               16512     \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 64)                8256      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 64)                4160      \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58435 (228.26 KB)\n",
            "Trainable params: 58435 (228.26 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model = create_model()\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B32kTkUgjOlj"
      },
      "source": [
        "### Compile the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MU7sxFWRjOlk"
      },
      "outputs": [],
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ElRQ4VrpjOlk"
      },
      "source": [
        "### Fit the model to the training data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fp2F9MVjOlk",
        "outputId": "01452c4c-d805-4826-9361-53ad082be234"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3/3 - 2s - loss: 1.0732 - accuracy: 0.3000 - val_loss: 0.9694 - val_accuracy: 0.4000 - 2s/epoch - 635ms/step\n",
            "Epoch 2/200\n",
            "3/3 - 0s - loss: 0.9859 - accuracy: 0.4556 - val_loss: 0.9065 - val_accuracy: 0.7000 - 44ms/epoch - 15ms/step\n",
            "Epoch 3/200\n",
            "3/3 - 0s - loss: 0.9169 - accuracy: 0.5889 - val_loss: 0.8118 - val_accuracy: 0.7000 - 59ms/epoch - 20ms/step\n",
            "Epoch 4/200\n",
            "3/3 - 0s - loss: 0.8247 - accuracy: 0.6667 - val_loss: 0.7392 - val_accuracy: 0.9667 - 42ms/epoch - 14ms/step\n",
            "Epoch 5/200\n",
            "3/3 - 0s - loss: 0.7246 - accuracy: 0.9667 - val_loss: 0.6344 - val_accuracy: 0.9667 - 43ms/epoch - 14ms/step\n",
            "Epoch 6/200\n",
            "3/3 - 0s - loss: 0.6072 - accuracy: 0.9556 - val_loss: 0.5362 - val_accuracy: 0.8667 - 40ms/epoch - 13ms/step\n",
            "Epoch 7/200\n",
            "3/3 - 0s - loss: 0.4918 - accuracy: 0.8778 - val_loss: 0.4414 - val_accuracy: 0.8667 - 40ms/epoch - 13ms/step\n",
            "Epoch 8/200\n",
            "3/3 - 0s - loss: 0.3805 - accuracy: 0.9444 - val_loss: 0.3147 - val_accuracy: 0.9667 - 48ms/epoch - 16ms/step\n",
            "Epoch 9/200\n",
            "3/3 - 0s - loss: 0.3063 - accuracy: 0.9333 - val_loss: 0.2587 - val_accuracy: 0.9667 - 63ms/epoch - 21ms/step\n",
            "Epoch 10/200\n",
            "3/3 - 0s - loss: 0.2494 - accuracy: 0.9444 - val_loss: 0.2085 - val_accuracy: 0.9667 - 43ms/epoch - 14ms/step\n",
            "Epoch 11/200\n",
            "3/3 - 0s - loss: 0.1883 - accuracy: 0.9667 - val_loss: 0.1952 - val_accuracy: 0.9333 - 47ms/epoch - 16ms/step\n",
            "Epoch 12/200\n",
            "3/3 - 0s - loss: 0.1469 - accuracy: 0.9667 - val_loss: 0.1415 - val_accuracy: 0.9667 - 65ms/epoch - 22ms/step\n",
            "Epoch 13/200\n",
            "3/3 - 0s - loss: 0.1660 - accuracy: 0.9444 - val_loss: 0.1246 - val_accuracy: 0.9667 - 66ms/epoch - 22ms/step\n",
            "Epoch 14/200\n",
            "3/3 - 0s - loss: 0.1562 - accuracy: 0.9333 - val_loss: 0.1171 - val_accuracy: 0.9667 - 56ms/epoch - 19ms/step\n",
            "Epoch 15/200\n",
            "3/3 - 0s - loss: 0.1488 - accuracy: 0.9444 - val_loss: 0.2084 - val_accuracy: 0.8667 - 46ms/epoch - 15ms/step\n",
            "Epoch 16/200\n",
            "3/3 - 0s - loss: 0.0873 - accuracy: 0.9667 - val_loss: 0.1268 - val_accuracy: 0.9667 - 42ms/epoch - 14ms/step\n",
            "Epoch 17/200\n",
            "3/3 - 0s - loss: 0.1441 - accuracy: 0.9444 - val_loss: 0.1414 - val_accuracy: 0.8667 - 58ms/epoch - 19ms/step\n",
            "Epoch 18/200\n",
            "3/3 - 0s - loss: 0.1350 - accuracy: 0.9556 - val_loss: 0.0967 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 19/200\n",
            "3/3 - 0s - loss: 0.1561 - accuracy: 0.9444 - val_loss: 0.1866 - val_accuracy: 0.9333 - 42ms/epoch - 14ms/step\n",
            "Epoch 20/200\n",
            "3/3 - 0s - loss: 0.1575 - accuracy: 0.9333 - val_loss: 0.3132 - val_accuracy: 0.8667 - 51ms/epoch - 17ms/step\n",
            "Epoch 21/200\n",
            "3/3 - 0s - loss: 0.1709 - accuracy: 0.9222 - val_loss: 0.3511 - val_accuracy: 0.8667 - 41ms/epoch - 14ms/step\n",
            "Epoch 22/200\n",
            "3/3 - 0s - loss: 0.1201 - accuracy: 0.9444 - val_loss: 0.0918 - val_accuracy: 0.9667 - 60ms/epoch - 20ms/step\n",
            "Epoch 23/200\n",
            "3/3 - 0s - loss: 0.1182 - accuracy: 0.9556 - val_loss: 0.1037 - val_accuracy: 0.9667 - 43ms/epoch - 14ms/step\n",
            "Epoch 24/200\n",
            "3/3 - 0s - loss: 0.0877 - accuracy: 0.9667 - val_loss: 0.2198 - val_accuracy: 0.8667 - 44ms/epoch - 15ms/step\n",
            "Epoch 25/200\n",
            "3/3 - 0s - loss: 0.1314 - accuracy: 0.9444 - val_loss: 0.2338 - val_accuracy: 0.8667 - 41ms/epoch - 14ms/step\n",
            "Epoch 26/200\n",
            "3/3 - 0s - loss: 0.0816 - accuracy: 0.9778 - val_loss: 0.1028 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 27/200\n",
            "3/3 - 0s - loss: 0.1281 - accuracy: 0.9556 - val_loss: 0.0966 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 28/200\n",
            "3/3 - 0s - loss: 0.1157 - accuracy: 0.9556 - val_loss: 0.1583 - val_accuracy: 0.8667 - 42ms/epoch - 14ms/step\n",
            "Epoch 29/200\n",
            "3/3 - 0s - loss: 0.0793 - accuracy: 0.9667 - val_loss: 0.1129 - val_accuracy: 0.9333 - 43ms/epoch - 14ms/step\n",
            "Epoch 30/200\n",
            "3/3 - 0s - loss: 0.0719 - accuracy: 0.9889 - val_loss: 0.0886 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 31/200\n",
            "3/3 - 0s - loss: 0.0724 - accuracy: 0.9889 - val_loss: 0.0848 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 32/200\n",
            "3/3 - 0s - loss: 0.0752 - accuracy: 0.9778 - val_loss: 0.1017 - val_accuracy: 0.9667 - 48ms/epoch - 16ms/step\n",
            "Epoch 33/200\n",
            "3/3 - 0s - loss: 0.0647 - accuracy: 0.9778 - val_loss: 0.2765 - val_accuracy: 0.8667 - 37ms/epoch - 12ms/step\n",
            "Epoch 34/200\n",
            "3/3 - 0s - loss: 0.0989 - accuracy: 0.9444 - val_loss: 0.1251 - val_accuracy: 0.9667 - 37ms/epoch - 12ms/step\n",
            "Epoch 35/200\n",
            "3/3 - 0s - loss: 0.0701 - accuracy: 0.9889 - val_loss: 0.0796 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 36/200\n",
            "3/3 - 0s - loss: 0.0653 - accuracy: 0.9889 - val_loss: 0.1292 - val_accuracy: 0.9333 - 36ms/epoch - 12ms/step\n",
            "Epoch 37/200\n",
            "3/3 - 0s - loss: 0.0722 - accuracy: 0.9778 - val_loss: 0.0867 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 38/200\n",
            "3/3 - 0s - loss: 0.0837 - accuracy: 0.9667 - val_loss: 0.1048 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 39/200\n",
            "3/3 - 0s - loss: 0.1152 - accuracy: 0.9556 - val_loss: 0.0839 - val_accuracy: 0.9667 - 36ms/epoch - 12ms/step\n",
            "Epoch 40/200\n",
            "3/3 - 0s - loss: 0.0699 - accuracy: 0.9778 - val_loss: 0.1481 - val_accuracy: 0.8667 - 37ms/epoch - 12ms/step\n",
            "Epoch 41/200\n",
            "3/3 - 0s - loss: 0.0634 - accuracy: 0.9778 - val_loss: 0.0813 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 42/200\n",
            "3/3 - 0s - loss: 0.0660 - accuracy: 0.9889 - val_loss: 0.0806 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 43/200\n",
            "3/3 - 0s - loss: 0.0661 - accuracy: 0.9889 - val_loss: 0.0987 - val_accuracy: 0.9333 - 85ms/epoch - 28ms/step\n",
            "Epoch 44/200\n",
            "3/3 - 0s - loss: 0.0565 - accuracy: 0.9778 - val_loss: 0.2013 - val_accuracy: 0.8667 - 95ms/epoch - 32ms/step\n",
            "Epoch 45/200\n",
            "3/3 - 0s - loss: 0.0758 - accuracy: 0.9667 - val_loss: 0.0992 - val_accuracy: 0.9667 - 74ms/epoch - 25ms/step\n",
            "Epoch 46/200\n",
            "3/3 - 0s - loss: 0.0722 - accuracy: 0.9667 - val_loss: 0.0912 - val_accuracy: 0.9667 - 92ms/epoch - 31ms/step\n",
            "Epoch 47/200\n",
            "3/3 - 0s - loss: 0.0948 - accuracy: 0.9556 - val_loss: 0.0789 - val_accuracy: 0.9667 - 81ms/epoch - 27ms/step\n",
            "Epoch 48/200\n",
            "3/3 - 0s - loss: 0.0585 - accuracy: 0.9889 - val_loss: 0.2031 - val_accuracy: 0.8667 - 89ms/epoch - 30ms/step\n",
            "Epoch 49/200\n",
            "3/3 - 0s - loss: 0.0831 - accuracy: 0.9556 - val_loss: 0.1041 - val_accuracy: 0.9667 - 91ms/epoch - 30ms/step\n",
            "Epoch 50/200\n",
            "3/3 - 0s - loss: 0.0718 - accuracy: 0.9778 - val_loss: 0.0783 - val_accuracy: 0.9667 - 88ms/epoch - 29ms/step\n",
            "Epoch 51/200\n",
            "3/3 - 0s - loss: 0.0686 - accuracy: 0.9667 - val_loss: 0.1494 - val_accuracy: 0.8667 - 116ms/epoch - 39ms/step\n",
            "Epoch 52/200\n",
            "3/3 - 0s - loss: 0.0790 - accuracy: 0.9667 - val_loss: 0.0849 - val_accuracy: 0.9667 - 79ms/epoch - 26ms/step\n",
            "Epoch 53/200\n",
            "3/3 - 0s - loss: 0.0701 - accuracy: 0.9667 - val_loss: 0.1020 - val_accuracy: 0.9667 - 83ms/epoch - 28ms/step\n",
            "Epoch 54/200\n",
            "3/3 - 0s - loss: 0.1225 - accuracy: 0.9556 - val_loss: 0.0797 - val_accuracy: 0.9667 - 83ms/epoch - 28ms/step\n",
            "Epoch 55/200\n",
            "3/3 - 0s - loss: 0.0604 - accuracy: 0.9778 - val_loss: 0.2911 - val_accuracy: 0.8667 - 127ms/epoch - 42ms/step\n",
            "Epoch 56/200\n",
            "3/3 - 0s - loss: 0.1182 - accuracy: 0.9556 - val_loss: 0.1574 - val_accuracy: 0.8667 - 113ms/epoch - 38ms/step\n",
            "Epoch 57/200\n",
            "3/3 - 0s - loss: 0.0682 - accuracy: 0.9667 - val_loss: 0.0801 - val_accuracy: 0.9667 - 99ms/epoch - 33ms/step\n",
            "Epoch 58/200\n",
            "3/3 - 0s - loss: 0.0925 - accuracy: 0.9667 - val_loss: 0.0826 - val_accuracy: 0.9667 - 77ms/epoch - 26ms/step\n",
            "Epoch 59/200\n",
            "3/3 - 0s - loss: 0.0582 - accuracy: 0.9778 - val_loss: 0.4362 - val_accuracy: 0.8667 - 90ms/epoch - 30ms/step\n",
            "Epoch 60/200\n",
            "3/3 - 0s - loss: 0.1711 - accuracy: 0.9222 - val_loss: 0.1630 - val_accuracy: 0.8667 - 77ms/epoch - 26ms/step\n",
            "Epoch 61/200\n",
            "3/3 - 0s - loss: 0.0718 - accuracy: 0.9667 - val_loss: 0.0831 - val_accuracy: 0.9667 - 77ms/epoch - 26ms/step\n",
            "Epoch 62/200\n",
            "3/3 - 0s - loss: 0.0858 - accuracy: 0.9667 - val_loss: 0.0842 - val_accuracy: 0.9667 - 77ms/epoch - 26ms/step\n",
            "Epoch 63/200\n",
            "3/3 - 0s - loss: 0.0636 - accuracy: 0.9778 - val_loss: 0.1583 - val_accuracy: 0.8667 - 81ms/epoch - 27ms/step\n",
            "Epoch 64/200\n",
            "3/3 - 0s - loss: 0.0812 - accuracy: 0.9667 - val_loss: 0.1397 - val_accuracy: 0.9000 - 75ms/epoch - 25ms/step\n",
            "Epoch 65/200\n",
            "3/3 - 0s - loss: 0.0638 - accuracy: 0.9889 - val_loss: 0.0854 - val_accuracy: 0.9667 - 72ms/epoch - 24ms/step\n",
            "Epoch 66/200\n",
            "3/3 - 0s - loss: 0.0620 - accuracy: 0.9889 - val_loss: 0.0825 - val_accuracy: 0.9667 - 78ms/epoch - 26ms/step\n",
            "Epoch 67/200\n",
            "3/3 - 0s - loss: 0.0629 - accuracy: 0.9889 - val_loss: 0.0947 - val_accuracy: 0.9667 - 95ms/epoch - 32ms/step\n",
            "Epoch 68/200\n",
            "3/3 - 0s - loss: 0.0730 - accuracy: 0.9778 - val_loss: 0.1700 - val_accuracy: 0.8667 - 80ms/epoch - 27ms/step\n",
            "Epoch 69/200\n",
            "3/3 - 0s - loss: 0.0709 - accuracy: 0.9667 - val_loss: 0.0794 - val_accuracy: 0.9667 - 108ms/epoch - 36ms/step\n",
            "Epoch 70/200\n",
            "3/3 - 0s - loss: 0.1121 - accuracy: 0.9556 - val_loss: 0.1561 - val_accuracy: 0.9667 - 107ms/epoch - 36ms/step\n",
            "Epoch 71/200\n",
            "3/3 - 0s - loss: 0.1813 - accuracy: 0.9222 - val_loss: 0.0835 - val_accuracy: 0.9667 - 73ms/epoch - 24ms/step\n",
            "Epoch 72/200\n",
            "3/3 - 0s - loss: 0.0676 - accuracy: 0.9778 - val_loss: 0.3365 - val_accuracy: 0.8667 - 113ms/epoch - 38ms/step\n",
            "Epoch 73/200\n",
            "3/3 - 0s - loss: 0.1256 - accuracy: 0.9556 - val_loss: 0.1493 - val_accuracy: 0.9000 - 90ms/epoch - 30ms/step\n",
            "Epoch 74/200\n",
            "3/3 - 0s - loss: 0.0789 - accuracy: 0.9556 - val_loss: 0.0866 - val_accuracy: 0.9667 - 93ms/epoch - 31ms/step\n",
            "Epoch 75/200\n",
            "3/3 - 0s - loss: 0.0915 - accuracy: 0.9556 - val_loss: 0.0825 - val_accuracy: 0.9667 - 61ms/epoch - 20ms/step\n",
            "Epoch 76/200\n",
            "3/3 - 0s - loss: 0.0682 - accuracy: 0.9778 - val_loss: 0.1494 - val_accuracy: 0.9000 - 81ms/epoch - 27ms/step\n",
            "Epoch 77/200\n",
            "3/3 - 0s - loss: 0.0793 - accuracy: 0.9667 - val_loss: 0.1921 - val_accuracy: 0.8667 - 67ms/epoch - 22ms/step\n",
            "Epoch 78/200\n",
            "3/3 - 0s - loss: 0.0719 - accuracy: 0.9778 - val_loss: 0.0836 - val_accuracy: 0.9667 - 93ms/epoch - 31ms/step\n",
            "Epoch 79/200\n",
            "3/3 - 0s - loss: 0.0598 - accuracy: 0.9889 - val_loss: 0.0802 - val_accuracy: 0.9667 - 128ms/epoch - 43ms/step\n",
            "Epoch 80/200\n",
            "3/3 - 0s - loss: 0.0602 - accuracy: 0.9889 - val_loss: 0.0851 - val_accuracy: 0.9667 - 102ms/epoch - 34ms/step\n",
            "Epoch 81/200\n",
            "3/3 - 0s - loss: 0.0557 - accuracy: 0.9778 - val_loss: 0.0833 - val_accuracy: 0.9667 - 94ms/epoch - 31ms/step\n",
            "Epoch 82/200\n",
            "3/3 - 0s - loss: 0.0591 - accuracy: 0.9778 - val_loss: 0.0801 - val_accuracy: 0.9667 - 74ms/epoch - 25ms/step\n",
            "Epoch 83/200\n",
            "3/3 - 0s - loss: 0.0570 - accuracy: 0.9778 - val_loss: 0.0777 - val_accuracy: 0.9667 - 76ms/epoch - 25ms/step\n",
            "Epoch 84/200\n",
            "3/3 - 0s - loss: 0.0638 - accuracy: 0.9889 - val_loss: 0.0776 - val_accuracy: 0.9667 - 158ms/epoch - 53ms/step\n",
            "Epoch 85/200\n",
            "3/3 - 0s - loss: 0.0605 - accuracy: 0.9778 - val_loss: 0.1327 - val_accuracy: 0.9333 - 81ms/epoch - 27ms/step\n",
            "Epoch 86/200\n",
            "3/3 - 0s - loss: 0.0624 - accuracy: 0.9778 - val_loss: 0.1026 - val_accuracy: 0.9667 - 114ms/epoch - 38ms/step\n",
            "Epoch 87/200\n",
            "3/3 - 0s - loss: 0.0585 - accuracy: 0.9778 - val_loss: 0.0959 - val_accuracy: 0.9667 - 73ms/epoch - 24ms/step\n",
            "Epoch 88/200\n",
            "3/3 - 0s - loss: 0.0571 - accuracy: 0.9778 - val_loss: 0.0754 - val_accuracy: 0.9667 - 127ms/epoch - 42ms/step\n",
            "Epoch 89/200\n",
            "3/3 - 0s - loss: 0.0561 - accuracy: 0.9889 - val_loss: 0.0753 - val_accuracy: 0.9667 - 87ms/epoch - 29ms/step\n",
            "Epoch 90/200\n",
            "3/3 - 0s - loss: 0.0569 - accuracy: 0.9889 - val_loss: 0.0991 - val_accuracy: 0.9667 - 99ms/epoch - 33ms/step\n",
            "Epoch 91/200\n",
            "3/3 - 0s - loss: 0.0602 - accuracy: 0.9778 - val_loss: 0.1944 - val_accuracy: 0.8667 - 145ms/epoch - 48ms/step\n",
            "Epoch 92/200\n",
            "3/3 - 0s - loss: 0.0677 - accuracy: 0.9667 - val_loss: 0.0773 - val_accuracy: 0.9667 - 85ms/epoch - 28ms/step\n",
            "Epoch 93/200\n",
            "3/3 - 0s - loss: 0.0523 - accuracy: 0.9778 - val_loss: 0.0774 - val_accuracy: 0.9667 - 72ms/epoch - 24ms/step\n",
            "Epoch 94/200\n",
            "3/3 - 0s - loss: 0.0591 - accuracy: 0.9889 - val_loss: 0.0771 - val_accuracy: 0.9667 - 72ms/epoch - 24ms/step\n",
            "Epoch 95/200\n",
            "3/3 - 0s - loss: 0.0522 - accuracy: 0.9778 - val_loss: 0.1060 - val_accuracy: 0.9667 - 70ms/epoch - 23ms/step\n",
            "Epoch 96/200\n",
            "3/3 - 0s - loss: 0.0648 - accuracy: 0.9778 - val_loss: 0.0908 - val_accuracy: 0.9333 - 67ms/epoch - 22ms/step\n",
            "Epoch 97/200\n",
            "3/3 - 0s - loss: 0.0535 - accuracy: 0.9778 - val_loss: 0.0767 - val_accuracy: 0.9667 - 80ms/epoch - 27ms/step\n",
            "Epoch 98/200\n",
            "3/3 - 0s - loss: 0.0722 - accuracy: 0.9667 - val_loss: 0.0775 - val_accuracy: 0.9667 - 80ms/epoch - 27ms/step\n",
            "Epoch 99/200\n",
            "3/3 - 0s - loss: 0.0503 - accuracy: 0.9889 - val_loss: 0.1731 - val_accuracy: 0.8667 - 71ms/epoch - 24ms/step\n",
            "Epoch 100/200\n",
            "3/3 - 0s - loss: 0.0826 - accuracy: 0.9667 - val_loss: 0.0937 - val_accuracy: 0.9667 - 107ms/epoch - 36ms/step\n",
            "Epoch 101/200\n",
            "3/3 - 0s - loss: 0.0757 - accuracy: 0.9667 - val_loss: 0.0762 - val_accuracy: 0.9667 - 98ms/epoch - 33ms/step\n",
            "Epoch 102/200\n",
            "3/3 - 0s - loss: 0.0523 - accuracy: 0.9889 - val_loss: 0.1657 - val_accuracy: 0.8667 - 83ms/epoch - 28ms/step\n",
            "Epoch 103/200\n",
            "3/3 - 0s - loss: 0.0761 - accuracy: 0.9667 - val_loss: 0.1536 - val_accuracy: 0.9000 - 84ms/epoch - 28ms/step\n",
            "Epoch 104/200\n",
            "3/3 - 0s - loss: 0.0684 - accuracy: 0.9778 - val_loss: 0.0908 - val_accuracy: 0.9667 - 72ms/epoch - 24ms/step\n",
            "Epoch 105/200\n",
            "3/3 - 0s - loss: 0.0714 - accuracy: 0.9667 - val_loss: 0.1419 - val_accuracy: 0.9000 - 76ms/epoch - 25ms/step\n",
            "Epoch 106/200\n",
            "3/3 - 0s - loss: 0.0573 - accuracy: 0.9778 - val_loss: 0.0759 - val_accuracy: 0.9667 - 92ms/epoch - 31ms/step\n",
            "Epoch 107/200\n",
            "3/3 - 0s - loss: 0.0617 - accuracy: 0.9778 - val_loss: 0.0751 - val_accuracy: 0.9667 - 131ms/epoch - 44ms/step\n",
            "Epoch 108/200\n",
            "3/3 - 0s - loss: 0.0654 - accuracy: 0.9778 - val_loss: 0.0915 - val_accuracy: 0.9333 - 109ms/epoch - 36ms/step\n",
            "Epoch 109/200\n",
            "3/3 - 0s - loss: 0.0625 - accuracy: 0.9778 - val_loss: 0.0897 - val_accuracy: 0.9333 - 91ms/epoch - 30ms/step\n",
            "Epoch 110/200\n",
            "3/3 - 0s - loss: 0.0513 - accuracy: 0.9778 - val_loss: 0.0748 - val_accuracy: 0.9667 - 109ms/epoch - 36ms/step\n",
            "Epoch 111/200\n",
            "3/3 - 0s - loss: 0.0628 - accuracy: 0.9778 - val_loss: 0.0761 - val_accuracy: 0.9667 - 163ms/epoch - 54ms/step\n",
            "Epoch 112/200\n",
            "3/3 - 0s - loss: 0.0708 - accuracy: 0.9778 - val_loss: 0.0760 - val_accuracy: 0.9667 - 131ms/epoch - 44ms/step\n",
            "Epoch 113/200\n",
            "3/3 - 0s - loss: 0.0508 - accuracy: 0.9889 - val_loss: 0.0978 - val_accuracy: 0.9667 - 208ms/epoch - 69ms/step\n",
            "Epoch 114/200\n",
            "3/3 - 0s - loss: 0.1205 - accuracy: 0.9556 - val_loss: 0.0774 - val_accuracy: 0.9667 - 172ms/epoch - 57ms/step\n",
            "Epoch 115/200\n",
            "3/3 - 0s - loss: 0.0634 - accuracy: 0.9778 - val_loss: 0.3135 - val_accuracy: 0.8667 - 185ms/epoch - 62ms/step\n",
            "Epoch 116/200\n",
            "3/3 - 0s - loss: 0.0991 - accuracy: 0.9667 - val_loss: 0.1528 - val_accuracy: 0.9000 - 131ms/epoch - 44ms/step\n",
            "Epoch 117/200\n",
            "3/3 - 0s - loss: 0.0663 - accuracy: 0.9667 - val_loss: 0.0754 - val_accuracy: 0.9667 - 118ms/epoch - 39ms/step\n",
            "Epoch 118/200\n",
            "3/3 - 0s - loss: 0.0734 - accuracy: 0.9667 - val_loss: 0.0754 - val_accuracy: 0.9667 - 111ms/epoch - 37ms/step\n",
            "Epoch 119/200\n",
            "3/3 - 0s - loss: 0.0651 - accuracy: 0.9667 - val_loss: 0.1207 - val_accuracy: 0.9667 - 143ms/epoch - 48ms/step\n",
            "Epoch 120/200\n",
            "3/3 - 0s - loss: 0.0580 - accuracy: 0.9778 - val_loss: 0.1432 - val_accuracy: 0.9000 - 195ms/epoch - 65ms/step\n",
            "Epoch 121/200\n",
            "3/3 - 0s - loss: 0.0638 - accuracy: 0.9778 - val_loss: 0.0790 - val_accuracy: 0.9667 - 102ms/epoch - 34ms/step\n",
            "Epoch 122/200\n",
            "3/3 - 0s - loss: 0.0805 - accuracy: 0.9667 - val_loss: 0.0875 - val_accuracy: 0.9667 - 117ms/epoch - 39ms/step\n",
            "Epoch 123/200\n",
            "3/3 - 0s - loss: 0.0924 - accuracy: 0.9667 - val_loss: 0.0823 - val_accuracy: 0.9667 - 186ms/epoch - 62ms/step\n",
            "Epoch 124/200\n",
            "3/3 - 0s - loss: 0.0586 - accuracy: 0.9778 - val_loss: 0.1615 - val_accuracy: 0.8667 - 159ms/epoch - 53ms/step\n",
            "Epoch 125/200\n",
            "3/3 - 0s - loss: 0.0663 - accuracy: 0.9667 - val_loss: 0.0916 - val_accuracy: 0.9667 - 157ms/epoch - 52ms/step\n",
            "Epoch 126/200\n",
            "3/3 - 0s - loss: 0.0633 - accuracy: 0.9778 - val_loss: 0.0798 - val_accuracy: 0.9667 - 157ms/epoch - 52ms/step\n",
            "Epoch 127/200\n",
            "3/3 - 0s - loss: 0.0907 - accuracy: 0.9556 - val_loss: 0.0737 - val_accuracy: 0.9667 - 126ms/epoch - 42ms/step\n",
            "Epoch 128/200\n",
            "3/3 - 0s - loss: 0.0578 - accuracy: 0.9889 - val_loss: 0.1530 - val_accuracy: 0.8667 - 122ms/epoch - 41ms/step\n",
            "Epoch 129/200\n",
            "3/3 - 0s - loss: 0.0861 - accuracy: 0.9667 - val_loss: 0.1845 - val_accuracy: 0.8667 - 199ms/epoch - 66ms/step\n",
            "Epoch 130/200\n",
            "3/3 - 0s - loss: 0.0752 - accuracy: 0.9667 - val_loss: 0.0722 - val_accuracy: 0.9667 - 206ms/epoch - 69ms/step\n",
            "Epoch 131/200\n",
            "3/3 - 0s - loss: 0.0634 - accuracy: 0.9667 - val_loss: 0.0741 - val_accuracy: 0.9667 - 132ms/epoch - 44ms/step\n",
            "Epoch 132/200\n",
            "3/3 - 0s - loss: 0.0710 - accuracy: 0.9667 - val_loss: 0.0745 - val_accuracy: 0.9667 - 216ms/epoch - 72ms/step\n",
            "Epoch 133/200\n",
            "3/3 - 0s - loss: 0.0557 - accuracy: 0.9778 - val_loss: 0.1182 - val_accuracy: 0.9667 - 174ms/epoch - 58ms/step\n",
            "Epoch 134/200\n",
            "3/3 - 0s - loss: 0.0630 - accuracy: 0.9778 - val_loss: 0.0767 - val_accuracy: 0.9667 - 186ms/epoch - 62ms/step\n",
            "Epoch 135/200\n",
            "3/3 - 0s - loss: 0.0603 - accuracy: 0.9778 - val_loss: 0.0901 - val_accuracy: 0.9667 - 207ms/epoch - 69ms/step\n",
            "Epoch 136/200\n",
            "3/3 - 0s - loss: 0.1035 - accuracy: 0.9556 - val_loss: 0.0739 - val_accuracy: 0.9667 - 206ms/epoch - 69ms/step\n",
            "Epoch 137/200\n",
            "3/3 - 0s - loss: 0.0677 - accuracy: 0.9667 - val_loss: 0.0872 - val_accuracy: 0.9667 - 182ms/epoch - 61ms/step\n",
            "Epoch 138/200\n",
            "3/3 - 0s - loss: 0.0515 - accuracy: 0.9778 - val_loss: 0.1589 - val_accuracy: 0.8667 - 94ms/epoch - 31ms/step\n",
            "Epoch 139/200\n",
            "3/3 - 0s - loss: 0.0666 - accuracy: 0.9667 - val_loss: 0.1184 - val_accuracy: 0.9667 - 81ms/epoch - 27ms/step\n",
            "Epoch 140/200\n",
            "3/3 - 0s - loss: 0.0570 - accuracy: 0.9778 - val_loss: 0.0757 - val_accuracy: 0.9667 - 70ms/epoch - 23ms/step\n",
            "Epoch 141/200\n",
            "3/3 - 0s - loss: 0.0653 - accuracy: 0.9778 - val_loss: 0.0753 - val_accuracy: 0.9667 - 98ms/epoch - 33ms/step\n",
            "Epoch 142/200\n",
            "3/3 - 0s - loss: 0.0528 - accuracy: 0.9889 - val_loss: 0.2119 - val_accuracy: 0.8667 - 103ms/epoch - 34ms/step\n",
            "Epoch 143/200\n",
            "3/3 - 0s - loss: 0.0789 - accuracy: 0.9667 - val_loss: 0.1175 - val_accuracy: 0.9667 - 74ms/epoch - 25ms/step\n",
            "Epoch 144/200\n",
            "3/3 - 0s - loss: 0.0532 - accuracy: 0.9778 - val_loss: 0.0760 - val_accuracy: 0.9667 - 88ms/epoch - 29ms/step\n",
            "Epoch 145/200\n",
            "3/3 - 0s - loss: 0.0555 - accuracy: 0.9778 - val_loss: 0.0732 - val_accuracy: 0.9667 - 76ms/epoch - 25ms/step\n",
            "Epoch 146/200\n",
            "3/3 - 0s - loss: 0.0577 - accuracy: 0.9778 - val_loss: 0.0888 - val_accuracy: 0.9667 - 114ms/epoch - 38ms/step\n",
            "Epoch 147/200\n",
            "3/3 - 0s - loss: 0.0800 - accuracy: 0.9667 - val_loss: 0.1686 - val_accuracy: 0.8667 - 57ms/epoch - 19ms/step\n",
            "Epoch 148/200\n",
            "3/3 - 0s - loss: 0.0685 - accuracy: 0.9667 - val_loss: 0.0830 - val_accuracy: 0.9667 - 70ms/epoch - 23ms/step\n",
            "Epoch 149/200\n",
            "3/3 - 0s - loss: 0.0545 - accuracy: 0.9889 - val_loss: 0.0828 - val_accuracy: 0.9667 - 71ms/epoch - 24ms/step\n",
            "Epoch 150/200\n",
            "3/3 - 0s - loss: 0.0530 - accuracy: 0.9889 - val_loss: 0.0891 - val_accuracy: 0.9667 - 80ms/epoch - 27ms/step\n",
            "Epoch 151/200\n",
            "3/3 - 0s - loss: 0.0531 - accuracy: 0.9778 - val_loss: 0.0913 - val_accuracy: 0.9667 - 74ms/epoch - 25ms/step\n",
            "Epoch 152/200\n",
            "3/3 - 0s - loss: 0.0544 - accuracy: 0.9778 - val_loss: 0.0754 - val_accuracy: 0.9667 - 103ms/epoch - 34ms/step\n",
            "Epoch 153/200\n",
            "3/3 - 0s - loss: 0.0663 - accuracy: 0.9778 - val_loss: 0.0883 - val_accuracy: 0.9667 - 111ms/epoch - 37ms/step\n",
            "Epoch 154/200\n",
            "3/3 - 0s - loss: 0.0999 - accuracy: 0.9556 - val_loss: 0.0759 - val_accuracy: 0.9667 - 98ms/epoch - 33ms/step\n",
            "Epoch 155/200\n",
            "3/3 - 0s - loss: 0.0663 - accuracy: 0.9667 - val_loss: 0.0924 - val_accuracy: 1.0000 - 60ms/epoch - 20ms/step\n",
            "Epoch 156/200\n",
            "3/3 - 0s - loss: 0.0514 - accuracy: 0.9778 - val_loss: 0.1299 - val_accuracy: 0.9333 - 90ms/epoch - 30ms/step\n",
            "Epoch 157/200\n",
            "3/3 - 0s - loss: 0.0604 - accuracy: 0.9778 - val_loss: 0.0854 - val_accuracy: 0.9667 - 93ms/epoch - 31ms/step\n",
            "Epoch 158/200\n",
            "3/3 - 0s - loss: 0.0628 - accuracy: 0.9667 - val_loss: 0.0759 - val_accuracy: 0.9667 - 76ms/epoch - 25ms/step\n",
            "Epoch 159/200\n",
            "3/3 - 0s - loss: 0.0484 - accuracy: 0.9889 - val_loss: 0.1357 - val_accuracy: 0.9000 - 67ms/epoch - 22ms/step\n",
            "Epoch 160/200\n",
            "3/3 - 0s - loss: 0.0786 - accuracy: 0.9667 - val_loss: 0.1069 - val_accuracy: 0.9667 - 81ms/epoch - 27ms/step\n",
            "Epoch 161/200\n",
            "3/3 - 0s - loss: 0.0559 - accuracy: 0.9778 - val_loss: 0.0750 - val_accuracy: 0.9667 - 117ms/epoch - 39ms/step\n",
            "Epoch 162/200\n",
            "3/3 - 0s - loss: 0.0519 - accuracy: 0.9889 - val_loss: 0.0933 - val_accuracy: 0.9667 - 79ms/epoch - 26ms/step\n",
            "Epoch 163/200\n",
            "3/3 - 0s - loss: 0.0525 - accuracy: 0.9778 - val_loss: 0.0809 - val_accuracy: 0.9667 - 60ms/epoch - 20ms/step\n",
            "Epoch 164/200\n",
            "3/3 - 0s - loss: 0.0519 - accuracy: 0.9778 - val_loss: 0.0736 - val_accuracy: 0.9667 - 74ms/epoch - 25ms/step\n",
            "Epoch 165/200\n",
            "3/3 - 0s - loss: 0.0512 - accuracy: 0.9889 - val_loss: 0.0750 - val_accuracy: 0.9667 - 88ms/epoch - 29ms/step\n",
            "Epoch 166/200\n",
            "3/3 - 0s - loss: 0.0498 - accuracy: 0.9889 - val_loss: 0.0790 - val_accuracy: 0.9667 - 105ms/epoch - 35ms/step\n",
            "Epoch 167/200\n",
            "3/3 - 0s - loss: 0.0586 - accuracy: 0.9778 - val_loss: 0.0779 - val_accuracy: 0.9667 - 89ms/epoch - 30ms/step\n",
            "Epoch 168/200\n",
            "3/3 - 0s - loss: 0.0638 - accuracy: 0.9778 - val_loss: 0.0720 - val_accuracy: 0.9667 - 70ms/epoch - 23ms/step\n",
            "Epoch 169/200\n",
            "3/3 - 0s - loss: 0.0505 - accuracy: 0.9778 - val_loss: 0.1050 - val_accuracy: 0.9667 - 112ms/epoch - 37ms/step\n",
            "Epoch 170/200\n",
            "3/3 - 0s - loss: 0.0592 - accuracy: 0.9778 - val_loss: 0.0834 - val_accuracy: 0.9667 - 101ms/epoch - 34ms/step\n",
            "Epoch 171/200\n",
            "3/3 - 0s - loss: 0.0632 - accuracy: 0.9778 - val_loss: 0.0706 - val_accuracy: 0.9667 - 109ms/epoch - 36ms/step\n",
            "Epoch 172/200\n",
            "3/3 - 0s - loss: 0.0530 - accuracy: 0.9778 - val_loss: 0.1508 - val_accuracy: 0.9000 - 135ms/epoch - 45ms/step\n",
            "Epoch 173/200\n",
            "3/3 - 0s - loss: 0.0767 - accuracy: 0.9667 - val_loss: 0.0838 - val_accuracy: 0.9667 - 151ms/epoch - 50ms/step\n",
            "Epoch 174/200\n",
            "3/3 - 0s - loss: 0.0592 - accuracy: 0.9778 - val_loss: 0.0733 - val_accuracy: 0.9667 - 88ms/epoch - 29ms/step\n",
            "Epoch 175/200\n",
            "3/3 - 0s - loss: 0.0716 - accuracy: 0.9667 - val_loss: 0.0730 - val_accuracy: 0.9667 - 95ms/epoch - 32ms/step\n",
            "Epoch 176/200\n",
            "3/3 - 0s - loss: 0.0505 - accuracy: 0.9889 - val_loss: 0.1070 - val_accuracy: 0.9667 - 74ms/epoch - 25ms/step\n",
            "Epoch 177/200\n",
            "3/3 - 0s - loss: 0.0630 - accuracy: 0.9667 - val_loss: 0.1265 - val_accuracy: 0.9667 - 93ms/epoch - 31ms/step\n",
            "Epoch 178/200\n",
            "3/3 - 0s - loss: 0.0561 - accuracy: 0.9778 - val_loss: 0.0741 - val_accuracy: 0.9667 - 82ms/epoch - 27ms/step\n",
            "Epoch 179/200\n",
            "3/3 - 0s - loss: 0.0592 - accuracy: 0.9778 - val_loss: 0.0754 - val_accuracy: 0.9667 - 139ms/epoch - 46ms/step\n",
            "Epoch 180/200\n",
            "3/3 - 0s - loss: 0.0631 - accuracy: 0.9778 - val_loss: 0.1562 - val_accuracy: 0.9000 - 79ms/epoch - 26ms/step\n",
            "Epoch 181/200\n",
            "3/3 - 0s - loss: 0.0646 - accuracy: 0.9667 - val_loss: 0.0714 - val_accuracy: 0.9667 - 170ms/epoch - 57ms/step\n",
            "Epoch 182/200\n",
            "3/3 - 0s - loss: 0.0594 - accuracy: 0.9889 - val_loss: 0.0716 - val_accuracy: 0.9667 - 90ms/epoch - 30ms/step\n",
            "Epoch 183/200\n",
            "3/3 - 0s - loss: 0.0479 - accuracy: 0.9889 - val_loss: 0.1016 - val_accuracy: 0.9667 - 146ms/epoch - 49ms/step\n",
            "Epoch 184/200\n",
            "3/3 - 0s - loss: 0.0592 - accuracy: 0.9778 - val_loss: 0.0674 - val_accuracy: 0.9667 - 214ms/epoch - 71ms/step\n",
            "Epoch 185/200\n",
            "3/3 - 0s - loss: 0.0495 - accuracy: 0.9889 - val_loss: 0.0830 - val_accuracy: 0.9667 - 150ms/epoch - 50ms/step\n",
            "Epoch 186/200\n",
            "3/3 - 0s - loss: 0.0848 - accuracy: 0.9667 - val_loss: 0.0746 - val_accuracy: 0.9667 - 89ms/epoch - 30ms/step\n",
            "Epoch 187/200\n",
            "3/3 - 0s - loss: 0.0514 - accuracy: 0.9889 - val_loss: 0.1095 - val_accuracy: 0.9667 - 99ms/epoch - 33ms/step\n",
            "Epoch 188/200\n",
            "3/3 - 0s - loss: 0.0732 - accuracy: 0.9778 - val_loss: 0.0724 - val_accuracy: 0.9667 - 91ms/epoch - 30ms/step\n",
            "Epoch 189/200\n",
            "3/3 - 0s - loss: 0.0579 - accuracy: 0.9778 - val_loss: 0.0961 - val_accuracy: 0.9667 - 75ms/epoch - 25ms/step\n",
            "Epoch 190/200\n",
            "3/3 - 0s - loss: 0.1067 - accuracy: 0.9556 - val_loss: 0.0745 - val_accuracy: 0.9667 - 82ms/epoch - 27ms/step\n",
            "Epoch 191/200\n",
            "3/3 - 0s - loss: 0.0719 - accuracy: 0.9556 - val_loss: 0.1838 - val_accuracy: 0.8667 - 83ms/epoch - 28ms/step\n",
            "Epoch 192/200\n",
            "3/3 - 0s - loss: 0.0819 - accuracy: 0.9667 - val_loss: 0.1662 - val_accuracy: 0.8667 - 93ms/epoch - 31ms/step\n",
            "Epoch 193/200\n",
            "3/3 - 0s - loss: 0.0734 - accuracy: 0.9778 - val_loss: 0.0873 - val_accuracy: 0.9667 - 87ms/epoch - 29ms/step\n",
            "Epoch 194/200\n",
            "3/3 - 0s - loss: 0.0563 - accuracy: 0.9778 - val_loss: 0.0847 - val_accuracy: 0.9667 - 98ms/epoch - 33ms/step\n",
            "Epoch 195/200\n",
            "3/3 - 0s - loss: 0.0592 - accuracy: 0.9778 - val_loss: 0.0868 - val_accuracy: 0.9667 - 74ms/epoch - 25ms/step\n",
            "Epoch 196/200\n",
            "3/3 - 0s - loss: 0.0559 - accuracy: 0.9778 - val_loss: 0.1055 - val_accuracy: 0.9667 - 88ms/epoch - 29ms/step\n",
            "Epoch 197/200\n",
            "3/3 - 0s - loss: 0.0629 - accuracy: 0.9778 - val_loss: 0.1137 - val_accuracy: 0.9667 - 79ms/epoch - 26ms/step\n",
            "Epoch 198/200\n",
            "3/3 - 0s - loss: 0.0581 - accuracy: 0.9778 - val_loss: 0.0772 - val_accuracy: 0.9667 - 98ms/epoch - 33ms/step\n",
            "Epoch 199/200\n",
            "3/3 - 0s - loss: 0.0561 - accuracy: 0.9889 - val_loss: 0.0745 - val_accuracy: 0.9667 - 78ms/epoch - 26ms/step\n",
            "Epoch 200/200\n",
            "3/3 - 0s - loss: 0.0624 - accuracy: 0.9889 - val_loss: 0.0736 - val_accuracy: 0.9667 - 77ms/epoch - 26ms/step\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    validation_split=0.25,\n",
        "    batch_size=40,\n",
        "    verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfZXxu76jOlk"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "I52itWyejOlk"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "def plot_metric(history, metric):\n",
        "    train_metrics = history.history[metric]\n",
        "    val_metrics = history.history['val_'+metric]\n",
        "    epochs = range(1, len(train_metrics) + 1)\n",
        "    plt.plot(epochs, train_metrics)\n",
        "    plt.plot(epochs, val_metrics)\n",
        "    plt.title('Training and validation '+ metric)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "RhyHyegYjOlk",
        "outputId": "6033320a-340d-4285-f4da-1dd52be5f0ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"408.10125pt\" height=\"325.986375pt\" viewBox=\"0 0 408.10125 325.986375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-11-23T14:41:43.092988</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 325.986375 \nL 408.10125 325.986375 \nL 408.10125 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 288.430125 \nL 400.90125 288.430125 \nL 400.90125 22.318125 \nL 43.78125 22.318125 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m1cb09c38b0\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m1cb09c38b0\" x=\"58.382547\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(55.201297 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m1cb09c38b0\" x=\"99.168294\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <g transform=\"translate(92.805794 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m1cb09c38b0\" x=\"139.954041\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(133.591541 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m1cb09c38b0\" x=\"180.739788\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <g transform=\"translate(174.377288 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m1cb09c38b0\" x=\"221.525535\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(211.981785 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m1cb09c38b0\" x=\"262.311282\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(252.767532 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m1cb09c38b0\" x=\"303.097029\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(293.553279 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m1cb09c38b0\" x=\"343.882776\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(334.339026 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m1cb09c38b0\" x=\"384.668523\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(375.124773 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- Epochs -->\n     <g transform=\"translate(204.425625 316.706687) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"m5a47a96508\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m5a47a96508\" x=\"43.78125\" y=\"276.334129\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.3 -->\n      <g transform=\"translate(20.878125 280.133348) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m5a47a96508\" x=\"43.78125\" y=\"241.774129\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 245.573347) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m5a47a96508\" x=\"43.78125\" y=\"207.214128\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.5 -->\n      <g transform=\"translate(20.878125 211.013347) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m5a47a96508\" x=\"43.78125\" y=\"172.654127\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 176.453346) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m5a47a96508\" x=\"43.78125\" y=\"138.094127\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.7 -->\n      <g transform=\"translate(20.878125 141.893346) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use xlink:href=\"#m5a47a96508\" x=\"43.78125\" y=\"103.534126\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 107.333345) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#m5a47a96508\" x=\"43.78125\" y=\"68.974126\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 0.9 -->\n      <g transform=\"translate(20.878125 72.773344) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_8\">\n     <g id=\"line2d_17\">\n      <g>\n       <use xlink:href=\"#m5a47a96508\" x=\"43.78125\" y=\"34.414125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_18\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 38.213344) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_19\">\n     <!-- accuracy -->\n     <g transform=\"translate(14.798438 177.9335) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-61\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"61.279297\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"116.259766\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"171.240234\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"234.619141\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"275.732422\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"337.011719\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"391.992188\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 60.013977 276.334125 \nL 61.645407 222.574127 \nL 63.276837 176.494129 \nL 64.908267 149.61412 \nL 66.539697 45.934135 \nL 68.171127 49.774124 \nL 69.802557 76.654134 \nL 71.433986 53.614134 \nL 73.065416 57.454124 \nL 74.696846 53.614134 \nL 76.328276 45.934135 \nL 77.959706 45.934135 \nL 79.591136 53.614134 \nL 81.222566 57.454124 \nL 82.853996 53.614134 \nL 84.485425 45.934135 \nL 86.116855 53.614134 \nL 87.748285 49.774124 \nL 92.642575 61.294134 \nL 94.274005 53.614134 \nL 97.536864 45.934135 \nL 99.168294 53.614134 \nL 100.799724 42.094125 \nL 102.431154 49.774124 \nL 104.062584 49.774124 \nL 105.694014 45.934135 \nL 107.325444 38.254135 \nL 108.956874 38.254135 \nL 110.588303 42.094125 \nL 112.219733 42.094125 \nL 113.851163 53.614134 \nL 115.482593 38.254135 \nL 117.114023 38.254135 \nL 122.008313 49.774124 \nL 123.639742 42.094125 \nL 125.271172 42.094125 \nL 126.902602 38.254135 \nL 128.534032 38.254135 \nL 131.796892 45.934135 \nL 133.428322 45.934135 \nL 135.059752 49.774124 \nL 136.691181 38.254135 \nL 138.322611 49.774124 \nL 139.954041 42.094125 \nL 141.585471 45.934135 \nL 144.848331 45.934135 \nL 146.479761 49.774124 \nL 148.111191 42.094125 \nL 149.74262 49.774124 \nL 151.37405 45.934135 \nL 153.00548 45.934135 \nL 154.63691 42.094125 \nL 156.26834 61.294134 \nL 157.89977 45.934135 \nL 159.5312 45.934135 \nL 161.16263 42.094125 \nL 162.79406 45.934135 \nL 164.425489 38.254135 \nL 167.688349 38.254135 \nL 172.582639 49.774124 \nL 174.214069 61.294134 \nL 175.845499 42.094125 \nL 177.476928 49.774124 \nL 180.739788 49.774124 \nL 182.371218 42.094125 \nL 184.002648 45.934135 \nL 187.265508 38.254135 \nL 188.896938 38.254135 \nL 190.528367 42.094125 \nL 193.791227 42.094125 \nL 195.422657 38.254135 \nL 197.054087 42.094125 \nL 201.948377 42.094125 \nL 203.579806 38.254135 \nL 205.211236 38.254135 \nL 208.474096 45.934135 \nL 211.736956 38.254135 \nL 213.368386 42.094125 \nL 216.631245 42.094125 \nL 218.262675 45.934135 \nL 219.894105 38.254135 \nL 221.525535 45.934135 \nL 223.156965 45.934135 \nL 224.788395 38.254135 \nL 226.419825 45.934135 \nL 228.051255 42.094125 \nL 229.682684 45.934135 \nL 231.314114 42.094125 \nL 241.102694 42.094125 \nL 242.734123 38.254135 \nL 244.365553 49.774124 \nL 245.996983 42.094125 \nL 247.628413 45.934135 \nL 252.522703 45.934135 \nL 254.154133 42.094125 \nL 255.785562 42.094125 \nL 257.416992 45.934135 \nL 259.048422 45.934135 \nL 260.679852 42.094125 \nL 262.311282 45.934135 \nL 263.942712 42.094125 \nL 265.574142 49.774124 \nL 267.205572 38.254135 \nL 268.837001 45.934135 \nL 273.731291 45.934135 \nL 275.362721 42.094125 \nL 278.625581 42.094125 \nL 280.257011 49.774124 \nL 283.51987 42.094125 \nL 285.1513 45.934135 \nL 286.78273 42.094125 \nL 288.41416 42.094125 \nL 290.04559 38.254135 \nL 291.67702 45.934135 \nL 293.30845 42.094125 \nL 296.571309 42.094125 \nL 298.202739 45.934135 \nL 299.834169 45.934135 \nL 301.465599 38.254135 \nL 303.097029 38.254135 \nL 304.728459 42.094125 \nL 307.991319 42.094125 \nL 309.622748 49.774124 \nL 312.885608 42.094125 \nL 314.517038 42.094125 \nL 316.148468 45.934135 \nL 317.779898 38.254135 \nL 319.411328 45.934135 \nL 322.674187 38.254135 \nL 324.305617 42.094125 \nL 325.937047 42.094125 \nL 327.568477 38.254135 \nL 329.199907 38.254135 \nL 330.831337 42.094125 \nL 338.988486 42.094125 \nL 340.619916 45.934135 \nL 342.251346 42.094125 \nL 343.882776 45.934135 \nL 345.514206 38.254135 \nL 347.145636 45.934135 \nL 348.777065 42.094125 \nL 352.039925 42.094125 \nL 353.671355 45.934135 \nL 355.302785 38.254135 \nL 356.934215 38.254135 \nL 358.565645 42.094125 \nL 360.197075 38.254135 \nL 361.828504 45.934135 \nL 363.459934 38.254135 \nL 365.091364 42.094125 \nL 366.722794 42.094125 \nL 368.354224 49.774124 \nL 369.985654 49.774124 \nL 373.248514 42.094125 \nL 381.405663 42.094125 \nL 383.037093 38.254135 \nL 384.668523 38.254135 \nL 384.668523 38.254135 \n\" clip-path=\"url(#p508bccac80)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_19\">\n    <path d=\"M 60.013977 241.774126 \nL 61.645407 138.094131 \nL 63.276837 138.094131 \nL 64.908267 45.934135 \nL 66.539697 45.934135 \nL 68.171127 80.494123 \nL 69.802557 80.494123 \nL 71.433986 45.934135 \nL 74.696846 45.934135 \nL 76.328276 57.454124 \nL 77.959706 45.934135 \nL 81.222566 45.934135 \nL 82.853996 80.494123 \nL 84.485425 45.934135 \nL 86.116855 80.494123 \nL 87.748285 45.934135 \nL 89.379715 57.454124 \nL 91.011145 80.494123 \nL 92.642575 80.494123 \nL 94.274005 45.934135 \nL 95.905435 45.934135 \nL 97.536864 80.494123 \nL 99.168294 80.494123 \nL 100.799724 45.934135 \nL 102.431154 45.934135 \nL 104.062584 80.494123 \nL 105.694014 57.454124 \nL 107.325444 45.934135 \nL 110.588303 45.934135 \nL 112.219733 80.494123 \nL 113.851163 45.934135 \nL 115.482593 45.934135 \nL 117.114023 57.454124 \nL 118.745453 45.934135 \nL 122.008313 45.934135 \nL 123.639742 80.494123 \nL 125.271172 45.934135 \nL 126.902602 45.934135 \nL 128.534032 57.454124 \nL 130.165462 80.494123 \nL 131.796892 45.934135 \nL 135.059752 45.934135 \nL 136.691181 80.494123 \nL 138.322611 45.934135 \nL 139.954041 45.934135 \nL 141.585471 80.494123 \nL 143.216901 45.934135 \nL 146.479761 45.934135 \nL 148.111191 80.494123 \nL 149.74262 80.494123 \nL 151.37405 45.934135 \nL 153.00548 45.934135 \nL 154.63691 80.494123 \nL 156.26834 80.494123 \nL 157.89977 45.934135 \nL 159.5312 45.934135 \nL 161.16263 80.494123 \nL 162.79406 68.974134 \nL 164.425489 45.934135 \nL 167.688349 45.934135 \nL 169.319779 80.494123 \nL 170.951209 45.934135 \nL 174.214069 45.934135 \nL 175.845499 80.494123 \nL 177.476928 68.974134 \nL 179.108358 45.934135 \nL 180.739788 45.934135 \nL 182.371218 68.974134 \nL 184.002648 80.494123 \nL 185.634078 45.934135 \nL 195.422657 45.934135 \nL 197.054087 57.454124 \nL 198.685517 45.934135 \nL 205.211236 45.934135 \nL 206.842666 80.494123 \nL 208.474096 45.934135 \nL 213.368386 45.934135 \nL 214.999816 57.454124 \nL 216.631245 45.934135 \nL 218.262675 45.934135 \nL 219.894105 80.494123 \nL 221.525535 45.934135 \nL 223.156965 45.934135 \nL 224.788395 80.494123 \nL 226.419825 68.974134 \nL 228.051255 45.934135 \nL 229.682684 68.974134 \nL 231.314114 45.934135 \nL 232.945544 45.934135 \nL 234.576974 57.454124 \nL 236.208404 57.454124 \nL 237.839834 45.934135 \nL 244.365553 45.934135 \nL 245.996983 80.494123 \nL 247.628413 68.974134 \nL 249.259843 45.934135 \nL 252.522703 45.934135 \nL 254.154133 68.974134 \nL 255.785562 45.934135 \nL 259.048422 45.934135 \nL 260.679852 80.494123 \nL 262.311282 45.934135 \nL 265.574142 45.934135 \nL 267.205572 80.494123 \nL 268.837001 80.494123 \nL 270.468431 45.934135 \nL 281.88844 45.934135 \nL 283.51987 80.494123 \nL 285.1513 45.934135 \nL 288.41416 45.934135 \nL 290.04559 80.494123 \nL 291.67702 45.934135 \nL 296.571309 45.934135 \nL 298.202739 80.494123 \nL 299.834169 45.934135 \nL 309.622748 45.934135 \nL 311.254178 34.414125 \nL 312.885608 57.454124 \nL 314.517038 45.934135 \nL 316.148468 45.934135 \nL 317.779898 68.974134 \nL 319.411328 45.934135 \nL 337.357056 45.934135 \nL 338.988486 68.974134 \nL 340.619916 45.934135 \nL 350.408495 45.934135 \nL 352.039925 68.974134 \nL 353.671355 45.934135 \nL 368.354224 45.934135 \nL 369.985654 80.494123 \nL 371.617084 80.494123 \nL 373.248514 45.934135 \nL 384.668523 45.934135 \nL 384.668523 45.934135 \n\" clip-path=\"url(#p508bccac80)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 288.430125 \nL 43.78125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 400.90125 288.430125 \nL 400.90125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 288.430125 \nL 400.90125 288.430125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 22.318125 \nL 400.90125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_20\">\n    <!-- Training and validation accuracy -->\n    <g transform=\"translate(125.049375 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"487.59375\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"550.972656\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"614.449219\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"646.236328\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"705.416016\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"766.695312\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"794.478516\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"822.261719\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"885.738281\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"947.017578\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"986.226562\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1014.009766\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1075.191406\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1138.570312\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1170.357422\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1231.636719\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1286.617188\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"1341.597656\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"1404.976562\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1446.089844\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1507.369141\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"1562.349609\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 288.5075 283.430125 \nL 393.90125 283.430125 \nQ 395.90125 283.430125 395.90125 281.430125 \nL 395.90125 252.517625 \nQ 395.90125 250.517625 393.90125 250.517625 \nL 288.5075 250.517625 \nQ 286.5075 250.517625 286.5075 252.517625 \nL 286.5075 281.430125 \nQ 286.5075 283.430125 288.5075 283.430125 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 290.5075 258.616062 \nL 300.5075 258.616062 \nL 310.5075 258.616062 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_21\">\n     <!-- train_accuracy -->\n     <g transform=\"translate(318.5075 262.116062) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"344.042969\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"399.023438\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"454.003906\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"517.382812\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"558.496094\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"619.775391\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"674.755859\"/>\n     </g>\n    </g>\n    <g id=\"line2d_21\">\n     <path d=\"M 290.5075 273.572312 \nL 300.5075 273.572312 \nL 310.5075 273.572312 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_22\">\n     <!-- val_accuracy -->\n     <g transform=\"translate(318.5075 277.072312) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"369.482422\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"432.861328\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"473.974609\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"535.253906\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"590.234375\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p508bccac80\">\n   <rect x=\"43.78125\" y=\"22.318125\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_metric(history, 'accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "lhZ7MnBkjOll",
        "outputId": "a2981513-b4a6-4f93-b8e2-e9fc29200b91"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"408.10125pt\" height=\"325.986375pt\" viewBox=\"0 0 408.10125 325.986375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-11-23T14:41:43.435143</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 325.986375 \nL 408.10125 325.986375 \nL 408.10125 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 288.430125 \nL 400.90125 288.430125 \nL 400.90125 22.318125 \nL 43.78125 22.318125 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m3d7815a41e\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m3d7815a41e\" x=\"58.382547\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(55.201297 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m3d7815a41e\" x=\"99.168294\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <g transform=\"translate(92.805794 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m3d7815a41e\" x=\"139.954041\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(133.591541 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m3d7815a41e\" x=\"180.739788\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <g transform=\"translate(174.377288 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m3d7815a41e\" x=\"221.525535\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(211.981785 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m3d7815a41e\" x=\"262.311282\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(252.767532 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m3d7815a41e\" x=\"303.097029\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(293.553279 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m3d7815a41e\" x=\"343.882776\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(334.339026 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m3d7815a41e\" x=\"384.668523\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(375.124773 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- Epochs -->\n     <g transform=\"translate(204.425625 316.706687) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"mbd22128209\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mbd22128209\" x=\"43.78125\" y=\"287.645643\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.0 -->\n      <g transform=\"translate(20.878125 291.444862) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#mbd22128209\" x=\"43.78125\" y=\"240.455088\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 244.254307) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#mbd22128209\" x=\"43.78125\" y=\"193.264533\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 197.063752) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#mbd22128209\" x=\"43.78125\" y=\"146.073979\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 149.873197) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#mbd22128209\" x=\"43.78125\" y=\"98.883424\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 102.682643) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use xlink:href=\"#mbd22128209\" x=\"43.78125\" y=\"51.692869\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 55.492088) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- loss -->\n     <g transform=\"translate(14.798438 165.031937) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-6c\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"27.783203\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"88.964844\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"141.064453\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 60.013977 34.414125 \nL 61.645407 55.018752 \nL 63.276837 71.306076 \nL 64.908267 93.05909 \nL 66.539697 116.682866 \nL 69.802557 171.614537 \nL 71.433986 197.872598 \nL 73.065416 215.375049 \nL 74.696846 228.804132 \nL 76.328276 243.206503 \nL 77.959706 252.976147 \nL 79.591136 248.483486 \nL 81.222566 250.788802 \nL 82.853996 252.538398 \nL 84.485425 267.045197 \nL 86.116855 253.656269 \nL 87.748285 255.794359 \nL 89.379715 250.818178 \nL 91.011145 250.489561 \nL 92.642575 247.331137 \nL 94.274005 259.305567 \nL 95.905435 259.744237 \nL 97.536864 266.94423 \nL 99.168294 256.633829 \nL 100.799724 268.383576 \nL 102.431154 257.423041 \nL 104.062584 260.338346 \nL 105.694014 268.938062 \nL 107.325444 270.671973 \nL 108.956874 270.560132 \nL 110.588303 269.891719 \nL 112.219733 272.373525 \nL 113.851163 264.311344 \nL 115.482593 271.114228 \nL 117.114023 272.229889 \nL 118.745453 270.605127 \nL 120.376883 267.899091 \nL 122.008313 260.458983 \nL 123.639742 271.14983 \nL 125.271172 272.688732 \nL 126.902602 272.075983 \nL 128.534032 272.051745 \nL 130.165462 274.305717 \nL 131.796892 269.764455 \nL 133.428322 270.608181 \nL 135.059752 265.281994 \nL 136.691181 273.835424 \nL 138.322611 268.043361 \nL 139.954041 270.715151 \nL 141.585471 271.468374 \nL 143.216901 269.015285 \nL 144.848331 271.108556 \nL 146.479761 258.749625 \nL 148.111191 273.403863 \nL 149.74262 259.757789 \nL 151.37405 271.553335 \nL 153.00548 265.821933 \nL 154.63691 273.922452 \nL 156.26834 247.26259 \nL 157.89977 270.715636 \nL 159.5312 267.411948 \nL 161.16263 272.640087 \nL 162.79406 268.478846 \nL 164.425489 272.583154 \nL 166.056919 273.016624 \nL 167.688349 272.810789 \nL 169.319779 270.417178 \nL 170.951209 270.921804 \nL 172.582639 261.199589 \nL 174.214069 244.861442 \nL 175.845499 271.698956 \nL 177.476928 258.001488 \nL 179.108358 269.017394 \nL 180.739788 266.061942 \nL 182.371218 271.550834 \nL 184.002648 268.930362 \nL 185.634078 270.682732 \nL 187.265508 273.545907 \nL 188.896938 273.433211 \nL 190.528367 274.509868 \nL 192.159797 273.699274 \nL 193.791227 274.196482 \nL 195.422657 272.598301 \nL 197.054087 273.365019 \nL 198.685517 272.919884 \nL 200.316947 273.841705 \nL 203.579806 274.408214 \nL 205.211236 274.210316 \nL 206.842666 273.444128 \nL 208.474096 271.676463 \nL 210.105526 275.296765 \nL 211.736956 273.699988 \nL 213.368386 275.317254 \nL 214.999816 272.358853 \nL 216.631245 275.015612 \nL 218.262675 270.619538 \nL 219.894105 275.779449 \nL 221.525535 268.151015 \nL 223.156965 269.772755 \nL 224.788395 275.307559 \nL 226.419825 269.688451 \nL 228.051255 271.513914 \nL 229.682684 270.791163 \nL 231.314114 274.115816 \nL 232.945544 273.09297 \nL 234.576974 272.216544 \nL 236.208404 272.8893 \nL 237.839834 275.552881 \nL 239.471264 272.816089 \nL 241.102694 270.940203 \nL 242.734123 275.659785 \nL 244.365553 259.217481 \nL 245.996983 272.692657 \nL 247.628413 264.251758 \nL 249.259843 272.010086 \nL 250.891273 270.32819 \nL 252.522703 272.290829 \nL 254.154133 273.96098 \nL 255.785562 272.583117 \nL 257.416992 268.643895 \nL 259.048422 265.85229 \nL 260.679852 273.826825 \nL 262.311282 272.007752 \nL 263.942712 272.713695 \nL 265.574142 266.233233 \nL 267.205572 273.997343 \nL 268.837001 267.330597 \nL 272.099861 272.680963 \nL 273.731291 270.891438 \nL 275.362721 274.496876 \nL 276.994151 272.779432 \nL 278.625581 273.423749 \nL 280.257011 263.22208 \nL 281.88844 271.663547 \nL 283.51987 275.487625 \nL 285.1513 271.940491 \nL 286.78273 274.207756 \nL 288.41416 272.23486 \nL 290.04559 275.183505 \nL 291.67702 269.024319 \nL 293.30845 275.082247 \nL 296.571309 274.041917 \nL 298.202739 268.763815 \nL 299.834169 271.482279 \nL 301.465599 274.794447 \nL 303.097029 275.13924 \nL 304.728459 275.117549 \nL 306.359889 274.801592 \nL 307.991319 272.001653 \nL 309.622748 264.085047 \nL 311.254178 271.990502 \nL 312.885608 275.511379 \nL 314.517038 273.401576 \nL 316.148468 272.824135 \nL 317.779898 276.219513 \nL 319.411328 269.093673 \nL 321.042758 274.456849 \nL 322.674187 275.392615 \nL 324.305617 275.257896 \nL 327.568477 275.567048 \nL 329.199907 275.887821 \nL 330.831337 273.823818 \nL 332.462767 272.596436 \nL 334.094197 275.734371 \nL 335.725626 273.668756 \nL 337.357056 272.743105 \nL 338.988486 275.148832 \nL 340.619916 269.541831 \nL 342.251346 273.688421 \nL 343.882776 270.74552 \nL 345.514206 275.733755 \nL 347.145636 272.775116 \nL 348.777065 274.415964 \nL 350.408495 273.665447 \nL 352.039925 272.751696 \nL 353.671355 272.402832 \nL 355.302785 273.633925 \nL 356.934215 276.334125 \nL 358.565645 273.680366 \nL 360.197075 275.971799 \nL 361.828504 267.646417 \nL 363.459934 275.512045 \nL 365.091364 270.367117 \nL 366.722794 273.988723 \nL 368.354224 262.474493 \nL 369.985654 270.680401 \nL 371.617084 268.330683 \nL 373.248514 270.325509 \nL 374.879943 274.365329 \nL 376.511373 273.670541 \nL 378.142803 274.445263 \nL 379.774233 272.812007 \nL 381.405663 273.933031 \nL 383.037093 274.403267 \nL 384.668523 272.925328 \nL 384.668523 272.925328 \n\" clip-path=\"url(#pa648e67665)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 60.013977 58.908259 \nL 61.645407 73.75374 \nL 63.276837 96.091262 \nL 64.908267 113.221098 \nL 68.171127 161.130441 \nL 69.802557 183.49441 \nL 71.433986 213.387373 \nL 73.065416 226.615508 \nL 74.696846 238.45867 \nL 76.328276 241.579847 \nL 77.959706 254.265453 \nL 79.591136 258.248083 \nL 81.222566 260.017597 \nL 82.853996 238.483331 \nL 84.485425 257.736451 \nL 86.116855 254.288996 \nL 87.748285 264.819827 \nL 89.379715 243.617488 \nL 91.011145 213.749349 \nL 92.642575 204.796113 \nL 94.274005 265.977502 \nL 95.905435 263.177236 \nL 97.536864 235.771682 \nL 99.168294 232.474777 \nL 100.799724 263.391487 \nL 102.431154 264.845571 \nL 104.062584 250.290171 \nL 105.694014 261.012251 \nL 107.325444 266.735412 \nL 108.956874 267.626522 \nL 110.588303 263.649812 \nL 112.219733 222.411497 \nL 113.851163 258.127128 \nL 115.482593 268.863862 \nL 117.114023 257.150824 \nL 118.745453 267.198298 \nL 120.376883 262.925807 \nL 122.008313 267.849201 \nL 123.639742 252.698744 \nL 125.271172 268.458554 \nL 126.902602 268.62975 \nL 128.534032 264.358231 \nL 130.165462 240.153881 \nL 131.796892 264.245498 \nL 133.428322 266.13288 \nL 135.059752 269.019562 \nL 136.691181 239.728498 \nL 138.322611 263.076631 \nL 139.954041 269.159308 \nL 141.585471 252.403378 \nL 143.216901 267.610698 \nL 144.848331 263.578426 \nL 146.479761 268.851498 \nL 148.111191 218.964285 \nL 149.74262 250.508527 \nL 151.37405 268.755432 \nL 153.00548 268.165327 \nL 154.63691 184.717229 \nL 156.26834 249.173928 \nL 157.89977 268.026432 \nL 159.5312 267.778025 \nL 161.16263 250.288652 \nL 162.79406 254.690685 \nL 164.425489 267.483914 \nL 166.056919 268.177035 \nL 167.688349 265.297341 \nL 169.319779 247.538861 \nL 170.951209 268.909878 \nL 172.582639 250.81886 \nL 174.214069 267.932837 \nL 175.845499 208.237911 \nL 177.476928 252.424955 \nL 179.108358 267.212318 \nL 180.739788 268.188659 \nL 182.371218 252.383861 \nL 184.002648 242.320967 \nL 185.634078 267.908417 \nL 187.265508 268.733293 \nL 188.896938 267.573983 \nL 190.528367 267.989803 \nL 192.159797 268.747522 \nL 193.791227 269.318764 \nL 195.422657 269.331045 \nL 197.054087 256.334869 \nL 198.685517 263.445495 \nL 200.316947 265.007205 \nL 201.948377 269.854837 \nL 203.579806 269.881055 \nL 205.211236 264.268104 \nL 206.842666 241.780116 \nL 208.474096 269.410819 \nL 210.105526 269.371683 \nL 211.736956 269.45736 \nL 213.368386 262.626077 \nL 216.631245 269.556391 \nL 218.262675 269.358057 \nL 219.894105 246.797666 \nL 221.525535 265.538718 \nL 223.156965 269.675438 \nL 224.788395 248.544836 \nL 226.419825 251.414012 \nL 228.051255 266.220445 \nL 229.682684 254.157014 \nL 231.314114 269.73195 \nL 232.945544 269.932886 \nL 234.576974 266.054621 \nL 236.208404 266.484598 \nL 237.839834 269.985401 \nL 239.471264 269.694496 \nL 241.102694 269.711389 \nL 242.734123 264.557839 \nL 244.365553 269.375164 \nL 245.996983 213.665282 \nL 247.628413 251.596508 \nL 249.259843 269.854169 \nL 250.891273 269.85534 \nL 252.522703 259.17057 \nL 254.154133 253.864119 \nL 255.785562 269.014724 \nL 257.416992 266.998178 \nL 259.048422 268.221034 \nL 260.679852 249.530707 \nL 262.311282 266.043075 \nL 263.942712 268.809242 \nL 265.574142 270.256637 \nL 267.205572 251.545871 \nL 268.837001 244.124027 \nL 270.468431 270.615884 \nL 272.099861 270.1555 \nL 273.731291 270.060521 \nL 275.362721 259.753145 \nL 276.994151 269.540411 \nL 278.625581 266.387923 \nL 280.257011 270.213091 \nL 281.88844 267.06666 \nL 283.51987 250.156543 \nL 286.78273 269.785214 \nL 288.41416 269.867341 \nL 290.04559 237.648064 \nL 291.67702 259.91867 \nL 293.30845 269.701915 \nL 294.93988 270.378463 \nL 296.571309 266.692301 \nL 298.202739 247.859426 \nL 299.834169 268.066572 \nL 301.465599 268.118491 \nL 303.097029 266.632809 \nL 304.728459 266.096289 \nL 306.359889 269.851687 \nL 307.991319 266.806392 \nL 309.622748 269.747559 \nL 311.254178 265.842269 \nL 312.885608 257.004676 \nL 314.517038 267.4853 \nL 316.148468 269.737461 \nL 317.779898 255.622636 \nL 319.411328 262.428005 \nL 321.042758 269.946579 \nL 322.674187 265.622704 \nL 324.305617 268.558949 \nL 325.937047 270.284103 \nL 327.568477 269.958349 \nL 329.199907 269.012579 \nL 330.831337 269.268452 \nL 332.462767 270.663391 \nL 334.094197 262.859749 \nL 335.725626 267.977648 \nL 337.357056 270.997353 \nL 338.988486 252.066478 \nL 340.619916 267.878626 \nL 342.251346 270.351749 \nL 343.882776 270.414845 \nL 345.514206 262.407052 \nL 347.145636 257.794535 \nL 348.777065 270.172334 \nL 350.408495 269.84929 \nL 352.039925 250.788553 \nL 353.671355 270.795452 \nL 355.302785 270.744381 \nL 356.934215 263.675561 \nL 358.565645 271.745404 \nL 360.197075 268.050425 \nL 361.828504 270.0416 \nL 363.459934 261.799575 \nL 365.091364 270.553805 \nL 366.722794 264.974698 \nL 368.354224 270.05749 \nL 369.985654 244.280966 \nL 371.617084 248.438155 \nL 373.248514 267.058086 \nL 374.879943 267.654079 \nL 376.511373 267.1686 \nL 378.142803 262.744701 \nL 379.774233 260.821831 \nL 381.405663 269.429941 \nL 383.037093 270.066715 \nL 384.668523 270.276505 \nL 384.668523 270.276505 \n\" clip-path=\"url(#pa648e67665)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 288.430125 \nL 43.78125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 400.90125 288.430125 \nL 400.90125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 288.430125 \nL 400.90125 288.430125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 22.318125 \nL 400.90125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_18\">\n    <!-- Training and validation loss -->\n    <g transform=\"translate(140.53125 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"487.59375\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"550.972656\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"614.449219\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"646.236328\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"705.416016\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"766.695312\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"794.478516\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"822.261719\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"885.738281\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"947.017578\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"986.226562\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1014.009766\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1075.191406\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1138.570312\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1170.357422\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1198.140625\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1259.322266\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1311.421875\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 314.310625 60.230625 \nL 393.90125 60.230625 \nQ 395.90125 60.230625 395.90125 58.230625 \nL 395.90125 29.318125 \nQ 395.90125 27.318125 393.90125 27.318125 \nL 314.310625 27.318125 \nQ 312.310625 27.318125 312.310625 29.318125 \nL 312.310625 58.230625 \nQ 312.310625 60.230625 314.310625 60.230625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 316.310625 35.416562 \nL 326.310625 35.416562 \nL 336.310625 35.416562 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_19\">\n     <!-- train_loss -->\n     <g transform=\"translate(344.310625 38.916562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 316.310625 50.372813 \nL 326.310625 50.372813 \nL 336.310625 50.372813 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_20\">\n     <!-- val_loss -->\n     <g transform=\"translate(344.310625 53.872813) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pa648e67665\">\n   <rect x=\"43.78125\" y=\"22.318125\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_metric(history, 'loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaBLUARyjOll"
      },
      "source": [
        "Plot the training and validation loss\n",
        "\n",
        "Finally, let's plot the loss vs. epochs graph on the training and validation sets\n",
        "\n",
        "From the graph, we can see that the model has vastly overfit the training data, so it outperform the validation set\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IalZpqnUjOll",
        "outputId": "6dfd8467-c980-4171-8844-9ba2fdcf0ef3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - loss: 0.0625 - accuracy: 0.9667 - 23ms/epoch - 23ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.06253813207149506, 0.9666666388511658]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "model.evaluate(X_test, y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rbHYwH8QjOll"
      },
      "source": [
        "## 2. Adding L2 regularization and Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "ADv8goctjOll"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def create_regularized_model(factor, rate):\n",
        "    model = Sequential([\n",
        "        Dense(64, kernel_regularizer=l2(factor), activation=\"relu\", input_shape=(4,)),\n",
        "        Dropout(rate),\n",
        "        Dense(128, kernel_regularizer=l2(factor), activation=\"relu\"),\n",
        "        Dropout(rate),\n",
        "        Dense(128, kernel_regularizer=l2(factor), activation=\"relu\"),\n",
        "        Dropout(rate),\n",
        "        Dense(128, kernel_regularizer=l2(factor), activation=\"relu\"),\n",
        "        Dropout(rate),\n",
        "        Dense(64, kernel_regularizer=l2(factor), activation=\"relu\"),\n",
        "        Dropout(rate),\n",
        "        Dense(64, kernel_regularizer=l2(factor), activation=\"relu\"),\n",
        "        Dropout(rate),\n",
        "        Dense(64, kernel_regularizer=l2(factor), activation=\"relu\"),\n",
        "        Dropout(rate),\n",
        "        Dense(3, activation='softmax')\n",
        "    ])\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1 * 10**-5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kMy0j6LZoddl",
        "outputId": "0d2748ae-e6a6-4ff6-9a12-5dcbb1068aca"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1e-05"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "1e-5 == 0.00001"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mw375f4lpVRk",
        "outputId": "34f48fc8-46cc-484a-979c-53c948655390"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "EWr72pRGjOll"
      },
      "outputs": [],
      "source": [
        "# Re-build the model with weight decay and dropout layers\n",
        "model = create_regularized_model(1e-5, 0.3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdho2xYKjOll",
        "outputId": "b3aff743-7c7f-4c0b-93c0-d5877658ad02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_8 (Dense)             (None, 64)                320       \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64)                0         \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 128)               16512     \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 64)                8256      \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 64)                4160      \n",
            "                                                                 \n",
            " dropout_6 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 3)                 195       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 58435 (228.26 KB)\n",
            "Trainable params: 58435 (228.26 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Mzhj-HvDjOlm"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "91Ss6EUjjOlm",
        "outputId": "773d524c-3c20-44ce-9501-010fb23d6c6d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "3/3 - 2s - loss: 1.2415 - accuracy: 0.2111 - val_loss: 1.0870 - val_accuracy: 0.4000 - 2s/epoch - 813ms/step\n",
            "Epoch 2/200\n",
            "3/3 - 0s - loss: 1.1440 - accuracy: 0.3222 - val_loss: 1.0854 - val_accuracy: 0.4000 - 55ms/epoch - 18ms/step\n",
            "Epoch 3/200\n",
            "3/3 - 0s - loss: 1.1734 - accuracy: 0.3000 - val_loss: 1.0908 - val_accuracy: 0.4000 - 52ms/epoch - 17ms/step\n",
            "Epoch 4/200\n",
            "3/3 - 0s - loss: 1.1050 - accuracy: 0.3889 - val_loss: 1.0881 - val_accuracy: 0.3667 - 54ms/epoch - 18ms/step\n",
            "Epoch 5/200\n",
            "3/3 - 0s - loss: 1.0938 - accuracy: 0.3667 - val_loss: 1.0868 - val_accuracy: 0.6667 - 55ms/epoch - 18ms/step\n",
            "Epoch 6/200\n",
            "3/3 - 0s - loss: 1.1186 - accuracy: 0.3556 - val_loss: 1.0921 - val_accuracy: 0.6000 - 56ms/epoch - 19ms/step\n",
            "Epoch 7/200\n",
            "3/3 - 0s - loss: 1.0903 - accuracy: 0.3778 - val_loss: 1.0947 - val_accuracy: 0.3000 - 55ms/epoch - 18ms/step\n",
            "Epoch 8/200\n",
            "3/3 - 0s - loss: 1.1004 - accuracy: 0.3556 - val_loss: 1.0986 - val_accuracy: 0.3000 - 56ms/epoch - 19ms/step\n",
            "Epoch 9/200\n",
            "3/3 - 0s - loss: 1.1037 - accuracy: 0.3444 - val_loss: 1.0963 - val_accuracy: 0.3000 - 57ms/epoch - 19ms/step\n",
            "Epoch 10/200\n",
            "3/3 - 0s - loss: 1.1087 - accuracy: 0.3556 - val_loss: 1.0889 - val_accuracy: 0.3000 - 55ms/epoch - 18ms/step\n",
            "Epoch 11/200\n",
            "3/3 - 0s - loss: 1.0978 - accuracy: 0.4333 - val_loss: 1.0776 - val_accuracy: 0.3000 - 83ms/epoch - 28ms/step\n",
            "Epoch 12/200\n",
            "3/3 - 0s - loss: 1.0807 - accuracy: 0.4000 - val_loss: 1.0623 - val_accuracy: 0.3000 - 76ms/epoch - 25ms/step\n",
            "Epoch 13/200\n",
            "3/3 - 0s - loss: 1.0775 - accuracy: 0.3667 - val_loss: 1.0530 - val_accuracy: 0.3000 - 65ms/epoch - 22ms/step\n",
            "Epoch 14/200\n",
            "3/3 - 0s - loss: 1.0784 - accuracy: 0.3778 - val_loss: 1.0417 - val_accuracy: 0.3000 - 75ms/epoch - 25ms/step\n",
            "Epoch 15/200\n",
            "3/3 - 0s - loss: 1.0580 - accuracy: 0.4111 - val_loss: 1.0244 - val_accuracy: 0.3000 - 58ms/epoch - 19ms/step\n",
            "Epoch 16/200\n",
            "3/3 - 0s - loss: 1.0653 - accuracy: 0.4556 - val_loss: 1.0077 - val_accuracy: 0.3000 - 54ms/epoch - 18ms/step\n",
            "Epoch 17/200\n",
            "3/3 - 0s - loss: 1.0388 - accuracy: 0.4222 - val_loss: 0.9898 - val_accuracy: 0.3000 - 57ms/epoch - 19ms/step\n",
            "Epoch 18/200\n",
            "3/3 - 0s - loss: 1.0641 - accuracy: 0.4111 - val_loss: 0.9719 - val_accuracy: 0.5667 - 74ms/epoch - 25ms/step\n",
            "Epoch 19/200\n",
            "3/3 - 0s - loss: 1.0199 - accuracy: 0.4111 - val_loss: 0.9555 - val_accuracy: 0.6000 - 61ms/epoch - 20ms/step\n",
            "Epoch 20/200\n",
            "3/3 - 0s - loss: 0.9984 - accuracy: 0.5111 - val_loss: 0.9427 - val_accuracy: 0.6000 - 57ms/epoch - 19ms/step\n",
            "Epoch 21/200\n",
            "3/3 - 0s - loss: 0.9950 - accuracy: 0.4778 - val_loss: 0.9262 - val_accuracy: 0.6000 - 68ms/epoch - 23ms/step\n",
            "Epoch 22/200\n",
            "3/3 - 0s - loss: 1.0403 - accuracy: 0.4444 - val_loss: 0.9106 - val_accuracy: 0.6000 - 55ms/epoch - 18ms/step\n",
            "Epoch 23/200\n",
            "3/3 - 0s - loss: 0.9591 - accuracy: 0.5222 - val_loss: 0.8911 - val_accuracy: 0.6000 - 77ms/epoch - 26ms/step\n",
            "Epoch 24/200\n",
            "3/3 - 0s - loss: 1.0059 - accuracy: 0.4667 - val_loss: 0.8581 - val_accuracy: 0.6000 - 80ms/epoch - 27ms/step\n",
            "Epoch 25/200\n",
            "3/3 - 0s - loss: 1.0104 - accuracy: 0.4556 - val_loss: 0.8004 - val_accuracy: 0.6000 - 59ms/epoch - 20ms/step\n",
            "Epoch 26/200\n",
            "3/3 - 0s - loss: 1.0008 - accuracy: 0.4889 - val_loss: 0.7462 - val_accuracy: 0.9000 - 79ms/epoch - 26ms/step\n",
            "Epoch 27/200\n",
            "3/3 - 0s - loss: 0.8582 - accuracy: 0.5667 - val_loss: 0.7053 - val_accuracy: 0.7000 - 62ms/epoch - 21ms/step\n",
            "Epoch 28/200\n",
            "3/3 - 0s - loss: 0.9644 - accuracy: 0.5444 - val_loss: 0.6753 - val_accuracy: 0.7000 - 59ms/epoch - 20ms/step\n",
            "Epoch 29/200\n",
            "3/3 - 0s - loss: 0.9001 - accuracy: 0.5778 - val_loss: 0.6446 - val_accuracy: 0.7000 - 59ms/epoch - 20ms/step\n",
            "Epoch 30/200\n",
            "3/3 - 0s - loss: 0.7326 - accuracy: 0.6444 - val_loss: 0.6012 - val_accuracy: 0.7000 - 99ms/epoch - 33ms/step\n",
            "Epoch 31/200\n",
            "3/3 - 0s - loss: 0.7289 - accuracy: 0.6222 - val_loss: 0.5611 - val_accuracy: 0.7000 - 64ms/epoch - 21ms/step\n",
            "Epoch 32/200\n",
            "3/3 - 0s - loss: 0.7160 - accuracy: 0.6444 - val_loss: 0.5327 - val_accuracy: 0.7000 - 76ms/epoch - 25ms/step\n",
            "Epoch 33/200\n",
            "3/3 - 0s - loss: 0.7472 - accuracy: 0.6111 - val_loss: 0.5142 - val_accuracy: 0.7333 - 61ms/epoch - 20ms/step\n",
            "Epoch 34/200\n",
            "3/3 - 0s - loss: 0.6443 - accuracy: 0.6000 - val_loss: 0.4989 - val_accuracy: 0.7333 - 78ms/epoch - 26ms/step\n",
            "Epoch 35/200\n",
            "3/3 - 0s - loss: 0.5981 - accuracy: 0.6889 - val_loss: 0.4944 - val_accuracy: 0.7667 - 75ms/epoch - 25ms/step\n",
            "Epoch 36/200\n",
            "3/3 - 0s - loss: 0.5529 - accuracy: 0.7111 - val_loss: 0.4912 - val_accuracy: 0.9000 - 55ms/epoch - 18ms/step\n",
            "Epoch 37/200\n",
            "3/3 - 0s - loss: 0.6576 - accuracy: 0.6333 - val_loss: 0.4840 - val_accuracy: 0.8333 - 69ms/epoch - 23ms/step\n",
            "Epoch 38/200\n",
            "3/3 - 0s - loss: 0.6802 - accuracy: 0.6444 - val_loss: 0.4796 - val_accuracy: 0.7667 - 72ms/epoch - 24ms/step\n",
            "Epoch 39/200\n",
            "3/3 - 0s - loss: 0.5594 - accuracy: 0.7111 - val_loss: 0.4778 - val_accuracy: 0.8333 - 77ms/epoch - 26ms/step\n",
            "Epoch 40/200\n",
            "3/3 - 0s - loss: 0.5686 - accuracy: 0.7000 - val_loss: 0.4762 - val_accuracy: 0.8000 - 70ms/epoch - 23ms/step\n",
            "Epoch 41/200\n",
            "3/3 - 0s - loss: 0.5229 - accuracy: 0.6889 - val_loss: 0.4729 - val_accuracy: 0.7667 - 73ms/epoch - 24ms/step\n",
            "Epoch 42/200\n",
            "3/3 - 0s - loss: 0.5706 - accuracy: 0.7111 - val_loss: 0.4797 - val_accuracy: 0.9333 - 54ms/epoch - 18ms/step\n",
            "Epoch 43/200\n",
            "3/3 - 0s - loss: 0.6224 - accuracy: 0.6000 - val_loss: 0.4838 - val_accuracy: 0.9667 - 70ms/epoch - 23ms/step\n",
            "Epoch 44/200\n",
            "3/3 - 0s - loss: 0.5185 - accuracy: 0.7444 - val_loss: 0.4774 - val_accuracy: 0.7333 - 54ms/epoch - 18ms/step\n",
            "Epoch 45/200\n",
            "3/3 - 0s - loss: 0.5363 - accuracy: 0.6667 - val_loss: 0.4663 - val_accuracy: 0.7000 - 74ms/epoch - 25ms/step\n",
            "Epoch 46/200\n",
            "3/3 - 0s - loss: 0.5115 - accuracy: 0.7222 - val_loss: 0.4598 - val_accuracy: 0.7000 - 58ms/epoch - 19ms/step\n",
            "Epoch 47/200\n",
            "3/3 - 0s - loss: 0.6646 - accuracy: 0.6444 - val_loss: 0.4569 - val_accuracy: 0.7000 - 73ms/epoch - 24ms/step\n",
            "Epoch 48/200\n",
            "3/3 - 0s - loss: 0.4977 - accuracy: 0.6667 - val_loss: 0.4566 - val_accuracy: 0.7000 - 75ms/epoch - 25ms/step\n",
            "Epoch 49/200\n",
            "3/3 - 0s - loss: 0.5374 - accuracy: 0.7000 - val_loss: 0.4570 - val_accuracy: 0.7000 - 54ms/epoch - 18ms/step\n",
            "Epoch 50/200\n",
            "3/3 - 0s - loss: 0.4849 - accuracy: 0.7333 - val_loss: 0.4582 - val_accuracy: 0.7000 - 71ms/epoch - 24ms/step\n",
            "Epoch 51/200\n",
            "3/3 - 0s - loss: 0.5753 - accuracy: 0.6444 - val_loss: 0.4600 - val_accuracy: 0.7000 - 73ms/epoch - 24ms/step\n",
            "Epoch 52/200\n",
            "3/3 - 0s - loss: 0.6184 - accuracy: 0.7111 - val_loss: 0.4642 - val_accuracy: 0.7000 - 75ms/epoch - 25ms/step\n",
            "Epoch 53/200\n",
            "3/3 - 0s - loss: 0.4954 - accuracy: 0.7444 - val_loss: 0.4688 - val_accuracy: 0.7333 - 37ms/epoch - 12ms/step\n",
            "Epoch 54/200\n",
            "3/3 - 0s - loss: 0.4780 - accuracy: 0.7333 - val_loss: 0.4702 - val_accuracy: 0.7667 - 39ms/epoch - 13ms/step\n",
            "Epoch 55/200\n",
            "3/3 - 0s - loss: 0.5056 - accuracy: 0.7000 - val_loss: 0.4711 - val_accuracy: 0.8000 - 38ms/epoch - 13ms/step\n",
            "Epoch 56/200\n",
            "3/3 - 0s - loss: 0.5286 - accuracy: 0.6556 - val_loss: 0.4680 - val_accuracy: 0.7667 - 49ms/epoch - 16ms/step\n",
            "Epoch 57/200\n",
            "3/3 - 0s - loss: 0.5432 - accuracy: 0.6667 - val_loss: 0.4638 - val_accuracy: 0.7667 - 39ms/epoch - 13ms/step\n",
            "Epoch 58/200\n",
            "3/3 - 0s - loss: 0.4910 - accuracy: 0.6444 - val_loss: 0.4651 - val_accuracy: 0.8000 - 39ms/epoch - 13ms/step\n",
            "Epoch 59/200\n",
            "3/3 - 0s - loss: 0.4998 - accuracy: 0.7111 - val_loss: 0.4761 - val_accuracy: 0.9667 - 37ms/epoch - 12ms/step\n",
            "Epoch 60/200\n",
            "3/3 - 0s - loss: 0.5079 - accuracy: 0.7667 - val_loss: 0.4852 - val_accuracy: 0.6333 - 41ms/epoch - 14ms/step\n",
            "Epoch 61/200\n",
            "3/3 - 0s - loss: 0.4919 - accuracy: 0.7778 - val_loss: 0.4855 - val_accuracy: 0.6000 - 46ms/epoch - 15ms/step\n",
            "Epoch 62/200\n",
            "3/3 - 0s - loss: 0.5303 - accuracy: 0.6889 - val_loss: 0.4826 - val_accuracy: 0.7333 - 40ms/epoch - 13ms/step\n",
            "Epoch 63/200\n",
            "3/3 - 0s - loss: 0.5051 - accuracy: 0.7444 - val_loss: 0.4779 - val_accuracy: 0.8000 - 39ms/epoch - 13ms/step\n",
            "Epoch 64/200\n",
            "3/3 - 0s - loss: 0.4959 - accuracy: 0.6556 - val_loss: 0.4769 - val_accuracy: 0.8000 - 40ms/epoch - 13ms/step\n",
            "Epoch 65/200\n",
            "3/3 - 0s - loss: 0.5151 - accuracy: 0.6444 - val_loss: 0.4781 - val_accuracy: 0.8000 - 38ms/epoch - 13ms/step\n",
            "Epoch 66/200\n",
            "3/3 - 0s - loss: 0.4977 - accuracy: 0.6778 - val_loss: 0.4736 - val_accuracy: 0.9000 - 38ms/epoch - 13ms/step\n",
            "Epoch 67/200\n",
            "3/3 - 0s - loss: 0.4659 - accuracy: 0.7667 - val_loss: 0.4662 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 68/200\n",
            "3/3 - 0s - loss: 0.4602 - accuracy: 0.7222 - val_loss: 0.4585 - val_accuracy: 0.9000 - 39ms/epoch - 13ms/step\n",
            "Epoch 69/200\n",
            "3/3 - 0s - loss: 0.4889 - accuracy: 0.6667 - val_loss: 0.4582 - val_accuracy: 0.9333 - 42ms/epoch - 14ms/step\n",
            "Epoch 70/200\n",
            "3/3 - 0s - loss: 0.4581 - accuracy: 0.7444 - val_loss: 0.4557 - val_accuracy: 0.9000 - 41ms/epoch - 14ms/step\n",
            "Epoch 71/200\n",
            "3/3 - 0s - loss: 0.4774 - accuracy: 0.7333 - val_loss: 0.4553 - val_accuracy: 0.9333 - 39ms/epoch - 13ms/step\n",
            "Epoch 72/200\n",
            "3/3 - 0s - loss: 0.5810 - accuracy: 0.6667 - val_loss: 0.4517 - val_accuracy: 0.8667 - 37ms/epoch - 12ms/step\n",
            "Epoch 73/200\n",
            "3/3 - 0s - loss: 0.4341 - accuracy: 0.8111 - val_loss: 0.4474 - val_accuracy: 0.7667 - 42ms/epoch - 14ms/step\n",
            "Epoch 74/200\n",
            "3/3 - 0s - loss: 0.4438 - accuracy: 0.7556 - val_loss: 0.4449 - val_accuracy: 0.7333 - 38ms/epoch - 13ms/step\n",
            "Epoch 75/200\n",
            "3/3 - 0s - loss: 0.4624 - accuracy: 0.7000 - val_loss: 0.4433 - val_accuracy: 0.7333 - 39ms/epoch - 13ms/step\n",
            "Epoch 76/200\n",
            "3/3 - 0s - loss: 0.4798 - accuracy: 0.6889 - val_loss: 0.4442 - val_accuracy: 0.7333 - 38ms/epoch - 13ms/step\n",
            "Epoch 77/200\n",
            "3/3 - 0s - loss: 0.4636 - accuracy: 0.7222 - val_loss: 0.4507 - val_accuracy: 0.8333 - 37ms/epoch - 12ms/step\n",
            "Epoch 78/200\n",
            "3/3 - 0s - loss: 0.4666 - accuracy: 0.7444 - val_loss: 0.4573 - val_accuracy: 0.9333 - 38ms/epoch - 13ms/step\n",
            "Epoch 79/200\n",
            "3/3 - 0s - loss: 0.4783 - accuracy: 0.7000 - val_loss: 0.4597 - val_accuracy: 0.9667 - 50ms/epoch - 17ms/step\n",
            "Epoch 80/200\n",
            "3/3 - 0s - loss: 0.4617 - accuracy: 0.7111 - val_loss: 0.4586 - val_accuracy: 0.9667 - 46ms/epoch - 15ms/step\n",
            "Epoch 81/200\n",
            "3/3 - 0s - loss: 0.4443 - accuracy: 0.7556 - val_loss: 0.4546 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 82/200\n",
            "3/3 - 0s - loss: 0.4433 - accuracy: 0.7556 - val_loss: 0.4506 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 83/200\n",
            "3/3 - 0s - loss: 0.4441 - accuracy: 0.7778 - val_loss: 0.4474 - val_accuracy: 0.9667 - 42ms/epoch - 14ms/step\n",
            "Epoch 84/200\n",
            "3/3 - 0s - loss: 0.4901 - accuracy: 0.7778 - val_loss: 0.4423 - val_accuracy: 0.9333 - 42ms/epoch - 14ms/step\n",
            "Epoch 85/200\n",
            "3/3 - 0s - loss: 0.4670 - accuracy: 0.7333 - val_loss: 0.4369 - val_accuracy: 0.8667 - 38ms/epoch - 13ms/step\n",
            "Epoch 86/200\n",
            "3/3 - 0s - loss: 0.4347 - accuracy: 0.7667 - val_loss: 0.4342 - val_accuracy: 0.8667 - 39ms/epoch - 13ms/step\n",
            "Epoch 87/200\n",
            "3/3 - 0s - loss: 0.4471 - accuracy: 0.7889 - val_loss: 0.4330 - val_accuracy: 0.8333 - 40ms/epoch - 13ms/step\n",
            "Epoch 88/200\n",
            "3/3 - 0s - loss: 0.4512 - accuracy: 0.7444 - val_loss: 0.4324 - val_accuracy: 0.8667 - 40ms/epoch - 13ms/step\n",
            "Epoch 89/200\n",
            "3/3 - 0s - loss: 0.4274 - accuracy: 0.7333 - val_loss: 0.4333 - val_accuracy: 0.9000 - 40ms/epoch - 13ms/step\n",
            "Epoch 90/200\n",
            "3/3 - 0s - loss: 0.4087 - accuracy: 0.7778 - val_loss: 0.4354 - val_accuracy: 0.9333 - 41ms/epoch - 14ms/step\n",
            "Epoch 91/200\n",
            "3/3 - 0s - loss: 0.4002 - accuracy: 0.8333 - val_loss: 0.4409 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 92/200\n",
            "3/3 - 0s - loss: 0.4836 - accuracy: 0.6889 - val_loss: 0.4432 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 93/200\n",
            "3/3 - 0s - loss: 0.4868 - accuracy: 0.7778 - val_loss: 0.4383 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 94/200\n",
            "3/3 - 0s - loss: 0.5235 - accuracy: 0.6556 - val_loss: 0.4433 - val_accuracy: 1.0000 - 39ms/epoch - 13ms/step\n",
            "Epoch 95/200\n",
            "3/3 - 0s - loss: 0.4520 - accuracy: 0.7778 - val_loss: 0.4575 - val_accuracy: 0.9000 - 46ms/epoch - 15ms/step\n",
            "Epoch 96/200\n",
            "3/3 - 0s - loss: 0.4373 - accuracy: 0.8667 - val_loss: 0.4613 - val_accuracy: 0.9000 - 37ms/epoch - 12ms/step\n",
            "Epoch 97/200\n",
            "3/3 - 0s - loss: 0.4700 - accuracy: 0.8333 - val_loss: 0.4479 - val_accuracy: 0.9000 - 41ms/epoch - 14ms/step\n",
            "Epoch 98/200\n",
            "3/3 - 0s - loss: 0.4695 - accuracy: 0.7556 - val_loss: 0.4254 - val_accuracy: 0.9667 - 36ms/epoch - 12ms/step\n",
            "Epoch 99/200\n",
            "3/3 - 0s - loss: 0.4171 - accuracy: 0.8222 - val_loss: 0.4050 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 100/200\n",
            "3/3 - 0s - loss: 0.3949 - accuracy: 0.8222 - val_loss: 0.3953 - val_accuracy: 0.8667 - 36ms/epoch - 12ms/step\n",
            "Epoch 101/200\n",
            "3/3 - 0s - loss: 0.4393 - accuracy: 0.7222 - val_loss: 0.3900 - val_accuracy: 0.8667 - 40ms/epoch - 13ms/step\n",
            "Epoch 102/200\n",
            "3/3 - 0s - loss: 0.4564 - accuracy: 0.7333 - val_loss: 0.3894 - val_accuracy: 0.8667 - 47ms/epoch - 16ms/step\n",
            "Epoch 103/200\n",
            "3/3 - 0s - loss: 0.4388 - accuracy: 0.7222 - val_loss: 0.3949 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 104/200\n",
            "3/3 - 0s - loss: 0.3882 - accuracy: 0.8444 - val_loss: 0.4053 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 105/200\n",
            "3/3 - 0s - loss: 0.4435 - accuracy: 0.7889 - val_loss: 0.4171 - val_accuracy: 0.9667 - 37ms/epoch - 12ms/step\n",
            "Epoch 106/200\n",
            "3/3 - 0s - loss: 0.4387 - accuracy: 0.7667 - val_loss: 0.4240 - val_accuracy: 0.9333 - 38ms/epoch - 13ms/step\n",
            "Epoch 107/200\n",
            "3/3 - 0s - loss: 0.4475 - accuracy: 0.7778 - val_loss: 0.4251 - val_accuracy: 0.9000 - 38ms/epoch - 13ms/step\n",
            "Epoch 108/200\n",
            "3/3 - 0s - loss: 0.4471 - accuracy: 0.8000 - val_loss: 0.4206 - val_accuracy: 0.9000 - 43ms/epoch - 14ms/step\n",
            "Epoch 109/200\n",
            "3/3 - 0s - loss: 0.4282 - accuracy: 0.8222 - val_loss: 0.4030 - val_accuracy: 1.0000 - 39ms/epoch - 13ms/step\n",
            "Epoch 110/200\n",
            "3/3 - 0s - loss: 0.4289 - accuracy: 0.8222 - val_loss: 0.3750 - val_accuracy: 0.9667 - 43ms/epoch - 14ms/step\n",
            "Epoch 111/200\n",
            "3/3 - 0s - loss: 0.3753 - accuracy: 0.8333 - val_loss: 0.3541 - val_accuracy: 0.9667 - 42ms/epoch - 14ms/step\n",
            "Epoch 112/200\n",
            "3/3 - 0s - loss: 0.4056 - accuracy: 0.7889 - val_loss: 0.3424 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 113/200\n",
            "3/3 - 0s - loss: 0.4199 - accuracy: 0.8444 - val_loss: 0.3450 - val_accuracy: 0.9667 - 36ms/epoch - 12ms/step\n",
            "Epoch 114/200\n",
            "3/3 - 0s - loss: 0.3920 - accuracy: 0.8000 - val_loss: 0.3558 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 115/200\n",
            "3/3 - 0s - loss: 0.4002 - accuracy: 0.8333 - val_loss: 0.3773 - val_accuracy: 0.9333 - 38ms/epoch - 13ms/step\n",
            "Epoch 116/200\n",
            "3/3 - 0s - loss: 0.3618 - accuracy: 0.8444 - val_loss: 0.3699 - val_accuracy: 0.9333 - 38ms/epoch - 13ms/step\n",
            "Epoch 117/200\n",
            "3/3 - 0s - loss: 0.3807 - accuracy: 0.8222 - val_loss: 0.3465 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 118/200\n",
            "3/3 - 0s - loss: 0.4114 - accuracy: 0.8000 - val_loss: 0.3448 - val_accuracy: 1.0000 - 39ms/epoch - 13ms/step\n",
            "Epoch 119/200\n",
            "3/3 - 0s - loss: 0.3737 - accuracy: 0.8778 - val_loss: 0.3269 - val_accuracy: 0.9667 - 44ms/epoch - 15ms/step\n",
            "Epoch 120/200\n",
            "3/3 - 0s - loss: 0.3174 - accuracy: 0.9222 - val_loss: 0.3028 - val_accuracy: 0.9667 - 42ms/epoch - 14ms/step\n",
            "Epoch 121/200\n",
            "3/3 - 0s - loss: 0.3413 - accuracy: 0.9222 - val_loss: 0.2843 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 122/200\n",
            "3/3 - 0s - loss: 0.3603 - accuracy: 0.8667 - val_loss: 0.2873 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 123/200\n",
            "3/3 - 0s - loss: 0.3715 - accuracy: 0.8889 - val_loss: 0.2903 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 124/200\n",
            "3/3 - 0s - loss: 0.3615 - accuracy: 0.8667 - val_loss: 0.2719 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 125/200\n",
            "3/3 - 0s - loss: 0.3672 - accuracy: 0.8889 - val_loss: 0.2801 - val_accuracy: 0.9667 - 48ms/epoch - 16ms/step\n",
            "Epoch 126/200\n",
            "3/3 - 0s - loss: 0.3320 - accuracy: 0.8667 - val_loss: 0.2976 - val_accuracy: 0.9000 - 40ms/epoch - 13ms/step\n",
            "Epoch 127/200\n",
            "3/3 - 0s - loss: 0.2735 - accuracy: 0.9222 - val_loss: 0.2750 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 128/200\n",
            "3/3 - 0s - loss: 0.2615 - accuracy: 0.9333 - val_loss: 0.2087 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 129/200\n",
            "3/3 - 0s - loss: 0.2506 - accuracy: 0.9222 - val_loss: 0.1846 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 130/200\n",
            "3/3 - 0s - loss: 0.3519 - accuracy: 0.8667 - val_loss: 0.1710 - val_accuracy: 0.9667 - 41ms/epoch - 14ms/step\n",
            "Epoch 131/200\n",
            "3/3 - 0s - loss: 0.3129 - accuracy: 0.8556 - val_loss: 0.1949 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 132/200\n",
            "3/3 - 0s - loss: 0.2504 - accuracy: 0.9000 - val_loss: 0.2087 - val_accuracy: 0.9333 - 41ms/epoch - 14ms/step\n",
            "Epoch 133/200\n",
            "3/3 - 0s - loss: 0.3226 - accuracy: 0.9000 - val_loss: 0.2020 - val_accuracy: 0.9333 - 39ms/epoch - 13ms/step\n",
            "Epoch 134/200\n",
            "3/3 - 0s - loss: 0.2528 - accuracy: 0.9111 - val_loss: 0.1771 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 135/200\n",
            "3/3 - 0s - loss: 0.2465 - accuracy: 0.8778 - val_loss: 0.1400 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 136/200\n",
            "3/3 - 0s - loss: 0.2436 - accuracy: 0.9333 - val_loss: 0.1412 - val_accuracy: 0.9667 - 42ms/epoch - 14ms/step\n",
            "Epoch 137/200\n",
            "3/3 - 0s - loss: 0.2719 - accuracy: 0.9111 - val_loss: 0.1400 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 138/200\n",
            "3/3 - 0s - loss: 0.2514 - accuracy: 0.9111 - val_loss: 0.1257 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 139/200\n",
            "3/3 - 0s - loss: 0.1784 - accuracy: 0.9667 - val_loss: 0.1461 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 140/200\n",
            "3/3 - 0s - loss: 0.2200 - accuracy: 0.9333 - val_loss: 0.1809 - val_accuracy: 0.9333 - 38ms/epoch - 13ms/step\n",
            "Epoch 141/200\n",
            "3/3 - 0s - loss: 0.2458 - accuracy: 0.9000 - val_loss: 0.1183 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 142/200\n",
            "3/3 - 0s - loss: 0.2080 - accuracy: 0.9333 - val_loss: 0.1110 - val_accuracy: 0.9667 - 41ms/epoch - 14ms/step\n",
            "Epoch 143/200\n",
            "3/3 - 0s - loss: 0.1626 - accuracy: 0.9222 - val_loss: 0.1038 - val_accuracy: 0.9667 - 44ms/epoch - 15ms/step\n",
            "Epoch 144/200\n",
            "3/3 - 0s - loss: 0.3028 - accuracy: 0.9222 - val_loss: 0.1114 - val_accuracy: 0.9667 - 41ms/epoch - 14ms/step\n",
            "Epoch 145/200\n",
            "3/3 - 0s - loss: 0.1899 - accuracy: 0.9222 - val_loss: 0.1293 - val_accuracy: 0.9333 - 43ms/epoch - 14ms/step\n",
            "Epoch 146/200\n",
            "3/3 - 0s - loss: 0.2307 - accuracy: 0.8778 - val_loss: 0.1348 - val_accuracy: 0.9333 - 63ms/epoch - 21ms/step\n",
            "Epoch 147/200\n",
            "3/3 - 0s - loss: 0.1738 - accuracy: 0.9333 - val_loss: 0.1125 - val_accuracy: 0.9667 - 68ms/epoch - 23ms/step\n",
            "Epoch 148/200\n",
            "3/3 - 0s - loss: 0.2336 - accuracy: 0.9222 - val_loss: 0.1316 - val_accuracy: 0.9667 - 60ms/epoch - 20ms/step\n",
            "Epoch 149/200\n",
            "3/3 - 0s - loss: 0.3261 - accuracy: 0.9111 - val_loss: 0.1109 - val_accuracy: 0.9667 - 60ms/epoch - 20ms/step\n",
            "Epoch 150/200\n",
            "3/3 - 0s - loss: 0.2007 - accuracy: 0.9778 - val_loss: 0.1365 - val_accuracy: 0.9667 - 62ms/epoch - 21ms/step\n",
            "Epoch 151/200\n",
            "3/3 - 0s - loss: 0.2060 - accuracy: 0.9111 - val_loss: 0.2365 - val_accuracy: 0.8667 - 42ms/epoch - 14ms/step\n",
            "Epoch 152/200\n",
            "3/3 - 0s - loss: 0.2806 - accuracy: 0.9222 - val_loss: 0.1293 - val_accuracy: 0.9333 - 62ms/epoch - 21ms/step\n",
            "Epoch 153/200\n",
            "3/3 - 0s - loss: 0.1161 - accuracy: 0.9778 - val_loss: 0.1048 - val_accuracy: 0.9667 - 62ms/epoch - 21ms/step\n",
            "Epoch 154/200\n",
            "3/3 - 0s - loss: 0.1915 - accuracy: 0.9444 - val_loss: 0.1020 - val_accuracy: 0.9667 - 45ms/epoch - 15ms/step\n",
            "Epoch 155/200\n",
            "3/3 - 0s - loss: 0.1490 - accuracy: 0.9444 - val_loss: 0.1172 - val_accuracy: 0.9333 - 44ms/epoch - 15ms/step\n",
            "Epoch 156/200\n",
            "3/3 - 0s - loss: 0.2733 - accuracy: 0.9000 - val_loss: 0.0993 - val_accuracy: 0.9667 - 41ms/epoch - 14ms/step\n",
            "Epoch 157/200\n",
            "3/3 - 0s - loss: 0.1910 - accuracy: 0.9333 - val_loss: 0.0956 - val_accuracy: 0.9667 - 44ms/epoch - 15ms/step\n",
            "Epoch 158/200\n",
            "3/3 - 0s - loss: 0.1072 - accuracy: 0.9778 - val_loss: 0.1038 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 159/200\n",
            "3/3 - 0s - loss: 0.1584 - accuracy: 0.9667 - val_loss: 0.0862 - val_accuracy: 0.9667 - 44ms/epoch - 15ms/step\n",
            "Epoch 160/200\n",
            "3/3 - 0s - loss: 0.1813 - accuracy: 0.9444 - val_loss: 0.0934 - val_accuracy: 0.9667 - 42ms/epoch - 14ms/step\n",
            "Epoch 161/200\n",
            "3/3 - 0s - loss: 0.1398 - accuracy: 0.9444 - val_loss: 0.1429 - val_accuracy: 0.9667 - 43ms/epoch - 14ms/step\n",
            "Epoch 162/200\n",
            "3/3 - 0s - loss: 0.1852 - accuracy: 0.9444 - val_loss: 0.0946 - val_accuracy: 0.9667 - 63ms/epoch - 21ms/step\n",
            "Epoch 163/200\n",
            "3/3 - 0s - loss: 0.1456 - accuracy: 0.9667 - val_loss: 0.0821 - val_accuracy: 0.9667 - 41ms/epoch - 14ms/step\n",
            "Epoch 164/200\n",
            "3/3 - 0s - loss: 0.1560 - accuracy: 0.9333 - val_loss: 0.0816 - val_accuracy: 0.9667 - 62ms/epoch - 21ms/step\n",
            "Epoch 165/200\n",
            "3/3 - 0s - loss: 0.1223 - accuracy: 0.9778 - val_loss: 0.0813 - val_accuracy: 0.9667 - 51ms/epoch - 17ms/step\n",
            "Epoch 166/200\n",
            "3/3 - 0s - loss: 0.1384 - accuracy: 0.9667 - val_loss: 0.0797 - val_accuracy: 0.9667 - 69ms/epoch - 23ms/step\n",
            "Epoch 167/200\n",
            "3/3 - 0s - loss: 0.2150 - accuracy: 0.9667 - val_loss: 0.0799 - val_accuracy: 0.9667 - 61ms/epoch - 20ms/step\n",
            "Epoch 168/200\n",
            "3/3 - 0s - loss: 0.0730 - accuracy: 0.9778 - val_loss: 0.0846 - val_accuracy: 0.9667 - 63ms/epoch - 21ms/step\n",
            "Epoch 169/200\n",
            "3/3 - 0s - loss: 0.1361 - accuracy: 0.9333 - val_loss: 0.1024 - val_accuracy: 0.9667 - 42ms/epoch - 14ms/step\n",
            "Epoch 170/200\n",
            "3/3 - 0s - loss: 0.1572 - accuracy: 0.9444 - val_loss: 0.0801 - val_accuracy: 0.9667 - 63ms/epoch - 21ms/step\n",
            "Epoch 171/200\n",
            "3/3 - 0s - loss: 0.1487 - accuracy: 0.9444 - val_loss: 0.0789 - val_accuracy: 0.9667 - 48ms/epoch - 16ms/step\n",
            "Epoch 172/200\n",
            "3/3 - 0s - loss: 0.1161 - accuracy: 0.9333 - val_loss: 0.1117 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 173/200\n",
            "3/3 - 0s - loss: 0.2260 - accuracy: 0.9333 - val_loss: 0.2849 - val_accuracy: 0.8667 - 43ms/epoch - 14ms/step\n",
            "Epoch 174/200\n",
            "3/3 - 0s - loss: 0.2458 - accuracy: 0.9444 - val_loss: 0.1882 - val_accuracy: 0.9333 - 41ms/epoch - 14ms/step\n",
            "Epoch 175/200\n",
            "3/3 - 0s - loss: 0.1032 - accuracy: 0.9667 - val_loss: 0.1109 - val_accuracy: 0.9667 - 45ms/epoch - 15ms/step\n",
            "Epoch 176/200\n",
            "3/3 - 0s - loss: 0.0681 - accuracy: 0.9889 - val_loss: 0.0782 - val_accuracy: 0.9667 - 61ms/epoch - 20ms/step\n",
            "Epoch 177/200\n",
            "3/3 - 0s - loss: 0.1754 - accuracy: 0.9444 - val_loss: 0.0810 - val_accuracy: 0.9667 - 41ms/epoch - 14ms/step\n",
            "Epoch 178/200\n",
            "3/3 - 0s - loss: 0.2172 - accuracy: 0.9444 - val_loss: 0.0886 - val_accuracy: 0.9667 - 68ms/epoch - 23ms/step\n",
            "Epoch 179/200\n",
            "3/3 - 0s - loss: 0.2645 - accuracy: 0.9333 - val_loss: 0.0889 - val_accuracy: 0.9667 - 42ms/epoch - 14ms/step\n",
            "Epoch 180/200\n",
            "3/3 - 0s - loss: 0.0744 - accuracy: 0.9667 - val_loss: 0.1784 - val_accuracy: 0.9667 - 65ms/epoch - 22ms/step\n",
            "Epoch 181/200\n",
            "3/3 - 0s - loss: 0.1158 - accuracy: 0.9444 - val_loss: 0.2133 - val_accuracy: 0.9000 - 64ms/epoch - 21ms/step\n",
            "Epoch 182/200\n",
            "3/3 - 0s - loss: 0.2238 - accuracy: 0.9000 - val_loss: 0.1189 - val_accuracy: 0.9333 - 41ms/epoch - 14ms/step\n",
            "Epoch 183/200\n",
            "3/3 - 0s - loss: 0.1233 - accuracy: 0.9667 - val_loss: 0.0923 - val_accuracy: 0.9667 - 46ms/epoch - 15ms/step\n",
            "Epoch 184/200\n",
            "3/3 - 0s - loss: 0.1475 - accuracy: 0.9556 - val_loss: 0.1009 - val_accuracy: 0.9667 - 37ms/epoch - 12ms/step\n",
            "Epoch 185/200\n",
            "3/3 - 0s - loss: 0.2705 - accuracy: 0.9444 - val_loss: 0.0997 - val_accuracy: 0.9667 - 47ms/epoch - 16ms/step\n",
            "Epoch 186/200\n",
            "3/3 - 0s - loss: 0.1342 - accuracy: 0.9556 - val_loss: 0.1042 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 187/200\n",
            "3/3 - 0s - loss: 0.1365 - accuracy: 0.9667 - val_loss: 0.1133 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 188/200\n",
            "3/3 - 0s - loss: 0.1537 - accuracy: 0.9667 - val_loss: 0.1263 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 189/200\n",
            "3/3 - 0s - loss: 0.1538 - accuracy: 0.9444 - val_loss: 0.1273 - val_accuracy: 1.0000 - 43ms/epoch - 14ms/step\n",
            "Epoch 190/200\n",
            "3/3 - 0s - loss: 0.1251 - accuracy: 0.9667 - val_loss: 0.1180 - val_accuracy: 1.0000 - 43ms/epoch - 14ms/step\n",
            "Epoch 191/200\n",
            "3/3 - 0s - loss: 0.1578 - accuracy: 0.9444 - val_loss: 0.1040 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 192/200\n",
            "3/3 - 0s - loss: 0.1035 - accuracy: 0.9667 - val_loss: 0.0912 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 193/200\n",
            "3/3 - 0s - loss: 0.0699 - accuracy: 0.9667 - val_loss: 0.0860 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 194/200\n",
            "3/3 - 0s - loss: 0.0675 - accuracy: 0.9778 - val_loss: 0.0813 - val_accuracy: 0.9667 - 56ms/epoch - 19ms/step\n",
            "Epoch 195/200\n",
            "3/3 - 0s - loss: 0.1150 - accuracy: 0.9667 - val_loss: 0.0777 - val_accuracy: 0.9667 - 38ms/epoch - 13ms/step\n",
            "Epoch 196/200\n",
            "3/3 - 0s - loss: 0.0795 - accuracy: 0.9889 - val_loss: 0.0922 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n",
            "Epoch 197/200\n",
            "3/3 - 0s - loss: 0.0562 - accuracy: 0.9667 - val_loss: 0.1407 - val_accuracy: 0.9667 - 40ms/epoch - 13ms/step\n",
            "Epoch 198/200\n",
            "3/3 - 0s - loss: 0.0810 - accuracy: 0.9778 - val_loss: 0.1491 - val_accuracy: 0.9667 - 41ms/epoch - 14ms/step\n",
            "Epoch 199/200\n",
            "3/3 - 0s - loss: 0.1054 - accuracy: 0.9667 - val_loss: 0.1412 - val_accuracy: 0.9667 - 37ms/epoch - 12ms/step\n",
            "Epoch 200/200\n",
            "3/3 - 0s - loss: 0.0903 - accuracy: 0.9667 - val_loss: 0.0689 - val_accuracy: 0.9667 - 39ms/epoch - 13ms/step\n"
          ]
        }
      ],
      "source": [
        "# Train the model, with some of the data reserved for validation\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    validation_split=0.25,\n",
        "    batch_size=40,\n",
        "    verbose=2\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MsOaukfqjOlm"
      },
      "source": [
        "### Plot the learning curves"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "Y9Ra_2NujOlm",
        "outputId": "3dc01e8f-2f0e-488a-e010-8e30231f7f67"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"408.10125pt\" height=\"325.986375pt\" viewBox=\"0 0 408.10125 325.986375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-11-23T14:47:00.815751</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 325.986375 \nL 408.10125 325.986375 \nL 408.10125 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 288.430125 \nL 400.90125 288.430125 \nL 400.90125 22.318125 \nL 43.78125 22.318125 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m14d76a4bfd\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m14d76a4bfd\" x=\"58.382547\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(55.201297 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m14d76a4bfd\" x=\"99.168294\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <g transform=\"translate(92.805794 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m14d76a4bfd\" x=\"139.954041\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(133.591541 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m14d76a4bfd\" x=\"180.739788\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <g transform=\"translate(174.377288 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m14d76a4bfd\" x=\"221.525535\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(211.981785 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m14d76a4bfd\" x=\"262.311282\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(252.767532 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m14d76a4bfd\" x=\"303.097029\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(293.553279 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m14d76a4bfd\" x=\"343.882776\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(334.339026 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m14d76a4bfd\" x=\"384.668523\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(375.124773 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- Epochs -->\n     <g transform=\"translate(204.425625 316.706687) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"mc3d1435ccd\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#mc3d1435ccd\" x=\"43.78125\" y=\"287.795067\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.0 -->\n      <g transform=\"translate(20.878125 291.594286) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#mc3d1435ccd\" x=\"43.78125\" y=\"246.975144\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 250.774363) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#mc3d1435ccd\" x=\"43.78125\" y=\"206.155221\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 209.95444) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#mc3d1435ccd\" x=\"43.78125\" y=\"165.335298\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 169.134517) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#mc3d1435ccd\" x=\"43.78125\" y=\"124.515375\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 128.314594) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use xlink:href=\"#mc3d1435ccd\" x=\"43.78125\" y=\"83.695452\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 1.0 -->\n      <g transform=\"translate(20.878125 87.49467) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_16\">\n      <g>\n       <use xlink:href=\"#mc3d1435ccd\" x=\"43.78125\" y=\"42.875528\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_17\">\n      <!-- 1.2 -->\n      <g transform=\"translate(20.878125 46.674747) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_18\">\n     <!-- loss -->\n     <g transform=\"translate(14.798438 165.031937) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-6c\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"27.783203\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"88.964844\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"141.064453\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 60.013977 34.414125 \nL 61.645407 54.312566 \nL 63.276837 48.308292 \nL 64.908267 62.265183 \nL 66.539697 64.54323 \nL 68.171127 59.482471 \nL 69.802557 65.255507 \nL 71.433986 63.212177 \nL 73.065416 62.539242 \nL 74.696846 61.508599 \nL 76.328276 63.72925 \nL 77.959706 67.226405 \nL 79.591136 67.883452 \nL 81.222566 67.699562 \nL 82.853996 71.852693 \nL 84.485425 70.368041 \nL 86.116855 75.786094 \nL 87.748285 70.614899 \nL 89.379715 79.628256 \nL 91.011145 84.030739 \nL 92.642575 84.710851 \nL 94.274005 75.465588 \nL 95.905435 92.047273 \nL 97.536864 82.498874 \nL 99.168294 81.580444 \nL 100.799724 83.523994 \nL 102.431154 112.63804 \nL 104.062584 90.958589 \nL 105.694014 104.079275 \nL 107.325444 138.270709 \nL 108.956874 139.035455 \nL 110.588303 141.664872 \nL 112.219733 135.299362 \nL 113.851163 156.299856 \nL 117.114023 174.948228 \nL 118.745453 153.582886 \nL 120.376883 148.966805 \nL 122.008313 173.628684 \nL 123.639742 171.748308 \nL 125.271172 181.071296 \nL 126.902602 171.340625 \nL 128.534032 160.771413 \nL 130.165462 181.961126 \nL 131.796892 178.346297 \nL 133.428322 183.394926 \nL 135.059752 152.159535 \nL 136.691181 186.206287 \nL 138.322611 178.105923 \nL 139.954041 188.833429 \nL 141.585471 170.383047 \nL 143.216901 161.589346 \nL 144.848331 186.677917 \nL 146.479761 190.228246 \nL 148.111191 184.607805 \nL 149.74262 179.916032 \nL 151.37405 176.919905 \nL 153.00548 187.592132 \nL 154.63691 185.77771 \nL 156.26834 184.133943 \nL 157.89977 187.400292 \nL 159.5312 179.561292 \nL 161.16263 184.710432 \nL 162.79406 186.572992 \nL 164.425489 182.658477 \nL 166.056919 186.220399 \nL 167.688349 192.705037 \nL 169.319779 193.867558 \nL 170.951209 188.017066 \nL 172.582639 194.30698 \nL 174.214069 190.364947 \nL 175.845499 169.211092 \nL 177.476928 199.202242 \nL 179.108358 197.220542 \nL 182.371218 189.858385 \nL 184.002648 193.166284 \nL 185.634078 192.566809 \nL 187.265508 190.166136 \nL 190.528367 197.121924 \nL 192.159797 197.312785 \nL 193.791227 197.149034 \nL 195.422657 187.757203 \nL 197.054087 192.481123 \nL 198.685517 199.074525 \nL 200.316947 196.533136 \nL 201.948377 195.700483 \nL 203.579806 200.558003 \nL 205.211236 204.377914 \nL 206.842666 206.120816 \nL 208.474096 189.08842 \nL 210.105526 188.437054 \nL 211.736956 180.955458 \nL 213.368386 195.533807 \nL 214.999816 198.544283 \nL 216.631245 191.872038 \nL 218.262675 191.960674 \nL 219.894105 202.665894 \nL 221.525535 207.191958 \nL 223.156965 198.143498 \nL 224.788395 194.63863 \nL 226.419825 198.241094 \nL 228.051255 208.567657 \nL 229.682684 197.27705 \nL 231.314114 198.253527 \nL 232.945544 196.470047 \nL 234.576974 196.549061 \nL 236.208404 200.3932 \nL 237.839834 200.25249 \nL 239.471264 211.19475 \nL 241.102694 205.006111 \nL 242.734123 202.087836 \nL 244.365553 207.779821 \nL 245.996983 206.121486 \nL 247.628413 213.95911 \nL 249.259843 210.092235 \nL 250.891273 203.833408 \nL 252.522703 211.531467 \nL 254.154133 223.021992 \nL 255.785562 218.138896 \nL 257.416992 214.257592 \nL 259.048422 211.966856 \nL 260.679852 214.002893 \nL 262.311282 212.857082 \nL 263.942712 220.040275 \nL 265.574142 231.965916 \nL 267.205572 234.419368 \nL 268.837001 236.639253 \nL 270.468431 215.976699 \nL 272.099861 223.92788 \nL 273.731291 236.684453 \nL 275.362721 221.945267 \nL 276.994151 236.193559 \nL 278.625581 237.481562 \nL 280.257011 238.085283 \nL 281.88844 232.306483 \nL 283.51987 236.488884 \nL 285.1513 251.382517 \nL 286.78273 242.892054 \nL 288.41416 237.633476 \nL 290.04559 245.352501 \nL 291.67702 254.598425 \nL 293.30845 225.994361 \nL 294.93988 249.034879 \nL 296.571309 240.714553 \nL 298.202739 252.315643 \nL 299.834169 240.116316 \nL 301.465599 221.22861 \nL 303.097029 246.827332 \nL 304.728459 245.746657 \nL 306.359889 230.521361 \nL 307.991319 264.101288 \nL 309.622748 248.714396 \nL 311.254178 257.37739 \nL 312.885608 232.018482 \nL 316.148468 265.915539 \nL 317.779898 255.461172 \nL 319.411328 250.80073 \nL 321.042758 259.261355 \nL 322.674187 250.003658 \nL 324.305617 258.082882 \nL 325.937047 255.96143 \nL 327.568477 262.839436 \nL 329.199907 259.552567 \nL 330.831337 243.905118 \nL 332.462767 272.893086 \nL 334.094197 260.012427 \nL 335.725626 255.707787 \nL 337.357056 257.446684 \nL 338.988486 264.095371 \nL 340.619916 241.665578 \nL 342.251346 237.632582 \nL 343.882776 266.725218 \nL 345.514206 273.903883 \nL 347.145636 251.988838 \nL 348.777065 243.47041 \nL 350.408495 233.806463 \nL 352.039925 272.614071 \nL 353.671355 264.16373 \nL 355.302785 242.120258 \nL 356.934215 262.630439 \nL 358.565645 257.693529 \nL 360.197075 232.578091 \nL 361.828504 260.395196 \nL 363.459934 259.945552 \nL 365.091364 256.428957 \nL 366.722794 256.409772 \nL 368.354224 262.269988 \nL 369.985654 255.592402 \nL 371.617084 266.667938 \nL 373.248514 273.52671 \nL 374.879943 274.016222 \nL 376.511373 264.330117 \nL 378.142803 271.572204 \nL 379.774233 276.334125 \nL 383.037093 266.291069 \nL 384.668523 269.368026 \nL 384.668523 269.368026 \n\" clip-path=\"url(#p293bffc7e7)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_18\">\n    <path d=\"M 60.013977 65.948101 \nL 61.645407 66.266418 \nL 63.276837 65.161834 \nL 64.908267 65.712898 \nL 66.539697 65.974889 \nL 68.171127 64.903663 \nL 69.802557 64.37041 \nL 71.433986 63.563973 \nL 73.065416 64.047811 \nL 74.696846 65.544214 \nL 76.328276 67.864474 \nL 77.959706 70.970004 \nL 79.591136 72.878932 \nL 81.222566 75.179728 \nL 89.379715 92.779562 \nL 91.011145 95.383991 \nL 94.274005 101.943647 \nL 95.905435 105.918484 \nL 97.536864 112.660229 \nL 100.799724 135.494676 \nL 102.431154 143.841959 \nL 105.694014 156.24111 \nL 107.325444 165.091695 \nL 108.956874 173.278312 \nL 110.588303 179.071384 \nL 112.219733 182.849958 \nL 113.851163 185.966285 \nL 115.482593 186.897555 \nL 117.114023 187.538052 \nL 118.745453 189.014662 \nL 120.376883 189.917715 \nL 123.639742 190.593296 \nL 125.271172 191.268731 \nL 126.902602 189.879109 \nL 128.534032 189.048043 \nL 130.165462 190.355063 \nL 131.796892 192.617161 \nL 133.428322 193.953329 \nL 135.059752 194.53983 \nL 136.691181 194.605577 \nL 138.322611 194.520493 \nL 141.585471 193.910757 \nL 144.848331 192.105788 \nL 148.111191 191.640368 \nL 149.74262 192.27744 \nL 151.37405 193.132124 \nL 153.00548 192.862985 \nL 154.63691 190.616659 \nL 156.26834 188.768601 \nL 157.89977 188.696126 \nL 159.5312 189.288746 \nL 161.16263 190.264973 \nL 162.79406 190.458523 \nL 164.425489 190.224639 \nL 166.056919 191.127024 \nL 169.319779 194.219713 \nL 170.951209 194.280126 \nL 172.582639 194.777163 \nL 174.214069 194.877179 \nL 175.845499 195.602018 \nL 177.476928 196.48484 \nL 179.108358 196.998471 \nL 180.739788 197.318953 \nL 182.371218 197.132879 \nL 185.634078 194.461254 \nL 187.265508 193.973463 \nL 188.896938 194.18593 \nL 192.159797 195.826643 \nL 193.791227 196.478618 \nL 197.054087 198.63413 \nL 198.685517 199.174731 \nL 200.316947 199.420707 \nL 201.948377 199.547201 \nL 203.579806 199.349637 \nL 205.211236 198.936534 \nL 206.842666 197.816927 \nL 208.474096 197.340485 \nL 210.105526 198.346579 \nL 211.736956 197.31256 \nL 213.368386 194.421723 \nL 214.999816 193.650183 \nL 216.631245 196.37351 \nL 218.262675 200.968137 \nL 219.894105 205.138628 \nL 221.525535 207.105304 \nL 223.156965 208.192936 \nL 224.788395 208.310848 \nL 226.419825 207.198198 \nL 228.051255 205.064225 \nL 229.682684 202.661374 \nL 231.314114 201.247853 \nL 232.945544 201.025776 \nL 234.576974 201.950174 \nL 236.208404 205.540143 \nL 237.839834 211.261744 \nL 239.471264 215.525433 \nL 241.102694 217.902098 \nL 242.734123 217.378395 \nL 244.365553 215.183218 \nL 245.996983 210.798022 \nL 247.628413 212.294328 \nL 249.259843 217.07565 \nL 250.891273 217.424599 \nL 252.522703 221.078485 \nL 254.154133 225.998898 \nL 255.785562 229.769632 \nL 259.048422 228.55269 \nL 260.679852 232.294981 \nL 262.311282 230.626184 \nL 263.942712 227.052546 \nL 265.574142 231.670896 \nL 267.205572 245.209 \nL 268.837001 250.11119 \nL 270.468431 252.892989 \nL 272.099861 248.007648 \nL 273.731291 245.200387 \nL 275.362721 246.574906 \nL 276.994151 251.65606 \nL 278.625581 259.220753 \nL 280.257011 258.984239 \nL 281.88844 259.224041 \nL 283.51987 262.134281 \nL 285.1513 257.973608 \nL 286.78273 250.873826 \nL 288.41416 263.651244 \nL 291.67702 266.619222 \nL 293.30845 265.064285 \nL 294.93988 261.403777 \nL 296.571309 260.282536 \nL 298.202739 264.834304 \nL 299.834169 260.938227 \nL 301.465599 265.155337 \nL 303.097029 259.938763 \nL 304.728459 239.535242 \nL 306.359889 261.398111 \nL 307.991319 266.4117 \nL 309.622748 266.977134 \nL 311.254178 263.87231 \nL 312.885608 267.536568 \nL 314.517038 268.273669 \nL 316.148468 266.602898 \nL 317.779898 270.20829 \nL 319.411328 268.724129 \nL 321.042758 258.634633 \nL 322.674187 268.491657 \nL 324.305617 271.034065 \nL 327.568477 271.210705 \nL 329.199907 271.52385 \nL 330.831337 271.48019 \nL 332.462767 270.536182 \nL 334.094197 266.892827 \nL 335.725626 271.456334 \nL 337.357056 271.687369 \nL 338.988486 265.000716 \nL 340.619916 229.643521 \nL 342.251346 249.37707 \nL 343.882776 265.166045 \nL 345.514206 271.833576 \nL 347.145636 271.266256 \nL 348.777065 269.703988 \nL 350.408495 269.657899 \nL 352.039925 251.380318 \nL 353.671355 244.25324 \nL 355.302785 263.530765 \nL 356.934215 268.959531 \nL 358.565645 267.206682 \nL 360.197075 267.441782 \nL 361.828504 266.518562 \nL 363.459934 264.671944 \nL 365.091364 262.008483 \nL 366.722794 261.810733 \nL 368.354224 263.703569 \nL 369.985654 266.563587 \nL 371.617084 269.182604 \nL 374.879943 271.209632 \nL 376.511373 271.935994 \nL 378.142803 268.971266 \nL 379.774233 259.084925 \nL 381.405663 257.363908 \nL 383.037093 258.97805 \nL 384.668523 273.729998 \nL 384.668523 273.729998 \n\" clip-path=\"url(#p293bffc7e7)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 288.430125 \nL 43.78125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 400.90125 288.430125 \nL 400.90125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 288.430125 \nL 400.90125 288.430125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 22.318125 \nL 400.90125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_19\">\n    <!-- Training and validation loss -->\n    <g transform=\"translate(140.53125 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"487.59375\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"550.972656\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"614.449219\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"646.236328\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"705.416016\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"766.695312\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"794.478516\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"822.261719\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"885.738281\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"947.017578\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"986.226562\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1014.009766\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1075.191406\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1138.570312\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1170.357422\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1198.140625\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1259.322266\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1311.421875\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 314.310625 60.230625 \nL 393.90125 60.230625 \nQ 395.90125 60.230625 395.90125 58.230625 \nL 395.90125 29.318125 \nQ 395.90125 27.318125 393.90125 27.318125 \nL 314.310625 27.318125 \nQ 312.310625 27.318125 312.310625 29.318125 \nL 312.310625 58.230625 \nQ 312.310625 60.230625 314.310625 60.230625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 316.310625 35.416562 \nL 326.310625 35.416562 \nL 336.310625 35.416562 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_20\">\n     <!-- train_loss -->\n     <g transform=\"translate(344.310625 38.916562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_20\">\n     <path d=\"M 316.310625 50.372813 \nL 326.310625 50.372813 \nL 336.310625 50.372813 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_21\">\n     <!-- val_loss -->\n     <g transform=\"translate(344.310625 53.872813) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p293bffc7e7\">\n   <rect x=\"43.78125\" y=\"22.318125\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plot_metric(history, 'loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mi26jt_2jOlm"
      },
      "source": [
        "Here, you can see that the overfitting is not completely fixed, but there is a signficant improvement when we compare it to the unregularized model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S2HDgPd_jOlm",
        "outputId": "33c315d9-7d87-44c5-8dbf-67efc99469e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 - 0s - loss: 0.0500 - accuracy: 0.9667 - 21ms/epoch - 21ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.05001683533191681, 0.9666666388511658]"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "# Evaluate the model on the test set\n",
        "model.evaluate(X_test, y_test, verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVuC7wzzjOln"
      },
      "source": [
        "## That's it\n",
        "\n",
        "Thanks for reading\n",
        "\n",
        "This is a notebook for the medium article [Model Regularization in Practice, an example with Keras and TensorFlow 2.0](https://medium.com/@bindiatwork/machine-learning-model-regularization-in-practice-an-example-with-keras-and-tensorflow-2-0-52a96746123e)\n",
        "\n",
        "Please check out article for instructions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Q1. What is the use of keras regularization?**\n",
        "\n",
        "Answer: It is the technique for preventing the model from large weights. The regularization category is applied to the per-layer basis.\n",
        "\n",
        "\n",
        "**Q2. How many types of weight regularization are in keras?**\n",
        "\n",
        "Answer: Basically there are multiple types of weight regularization like vector norms, L1 and L2. It will require the hyper parameter which is configured.\n",
        "\n",
        "**Q3. Which modules do we need to import at the time of using keras regularization?**\n",
        "\n",
        "Answer: We need to import the keras and tensorflow module at the time of using it. Also, we need to import is a dense layer.\n",
        "\n",
        "**Conclusion:-**\n",
        "\n",
        "**There are two popular keras regularization parameters available i.e. L1 and L2. In that L1 is nothing but the Lasso and L2 is called Ridge. It allows us to apply the penalties to the parameters of layer activities at the time of optimization.**\n",
        "\n",
        "--------------**KERAS REGULAZIATION----------------**\n",
        "\n",
        "Keras regularization allows us to apply the penalties in the parameters of layer activities at the optimization time. Those penalties were summed into the function of loss, and it will optimize the network. It applies on a per-layer basis. The exact API depends on the layer, but multiple layers contain a unified API. The layer will expose arguments of 3 keywords.\n",
        "\n",
        "The keras regularization prevents the over-fitting penalizing model from containing large weights. There are two popular parameters available, i.e., L1 and L2. L1 is nothing but the Lasso, and L2 is called Ridge. Both of these parameters are defined at the time of learning the linear regression. When working with tensorflow, we can implement the regularization using an optimizer. We are adding regularization to our code by adding a parameter name as kernel_regularizer. While adding L2 regularization, we need to pass the keras regularizers.l2 () function.\n",
        "\n",
        "This function takes one parameter, which contains the strength of regularization. We pass L1 regularizers by replacing the l2 function with the l1 function. Suppose we need to use L2 and l1 regularization this is called the elastic net. The weight regularization provides an approach to reducing the overfitting of neural network models for deep learning. Activity regularization encourages the neural network to learn the sparse features of internal representations for the raw observations. It is common to seek the representation of spark known for autoencoders called sparse encoders.\n",
        "\n",
        "python -m pip install tensorflow\n",
        "\n",
        "python –m pip install keras\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Dense\n",
        "\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "from keras.layers import Dense\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.regularizers import l1\n",
        "\n",
        "from keras.layers import Activation"
      ],
      "metadata": {
        "id": "YuQbhyDHK9jD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "xzuc7AJ3jOln"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import Dense\n",
        "\n",
        "from sklearn.datasets import make_circles\n",
        "\n",
        "from keras.layers import Dense\n",
        "\n",
        "from keras.models import Sequential\n",
        "\n",
        "from keras.regularizers import l1\n",
        "\n",
        "from keras.layers import Activation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = make_circles(n_samples=60)\n"
      ],
      "metadata": {
        "id": "8xyws5V_Me_m"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape, y.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5EQHxZS7NLAS",
        "outputId": "0376854a-40be-4422-97d6-a8ef3a8b03f7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60, 2), (60,))"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = 25\n",
        "X_train, X_test = X[:train, :], X[train:, :]\n",
        "y_train, y_test = y[:train], y[train:]\n",
        "\n",
        "X_train.shape, X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qskOcCNWMnK_",
        "outputId": "17951782-16d2-4a0e-96aa-39c5eafa0d20"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((25, 2), (35, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "\n",
        "def create_model():\n",
        "    model = Sequential([\n",
        "        Dense(64, activation='relu', input_shape=(2,)),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(128, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(3, activation='softmax'),\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TPIFnBnkMnal"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "lhF-uP05SqHD"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model, with some of the data reserved for validation\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    validation_split=0.25,\n",
        "    batch_size=40,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gj1zxbNpSqKU",
        "outputId": "e5bc8a16-d077-47f5-f018-b6f0d8ab7f0d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 - 1s - loss: 4.8389 - accuracy: 0.6111 - val_loss: 6.3754 - val_accuracy: 0.5714 - 900ms/epoch - 900ms/step\n",
            "Epoch 2/200\n",
            "1/1 - 0s - loss: 4.4364 - accuracy: 0.5556 - val_loss: 6.2726 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 3/200\n",
            "1/1 - 0s - loss: 3.9953 - accuracy: 0.5000 - val_loss: 6.2167 - val_accuracy: 0.5714 - 39ms/epoch - 39ms/step\n",
            "Epoch 4/200\n",
            "1/1 - 0s - loss: 3.3842 - accuracy: 0.5556 - val_loss: 4.6478 - val_accuracy: 0.7143 - 50ms/epoch - 50ms/step\n",
            "Epoch 5/200\n",
            "1/1 - 0s - loss: 3.2310 - accuracy: 0.5556 - val_loss: 4.4870 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 6/200\n",
            "1/1 - 0s - loss: 2.5404 - accuracy: 0.5000 - val_loss: 4.3960 - val_accuracy: 0.5714 - 37ms/epoch - 37ms/step\n",
            "Epoch 7/200\n",
            "1/1 - 0s - loss: 2.1553 - accuracy: 0.5000 - val_loss: 4.3342 - val_accuracy: 0.5714 - 50ms/epoch - 50ms/step\n",
            "Epoch 8/200\n",
            "1/1 - 0s - loss: 2.0644 - accuracy: 0.5000 - val_loss: 3.4865 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 9/200\n",
            "1/1 - 0s - loss: 2.0054 - accuracy: 0.5000 - val_loss: 3.3984 - val_accuracy: 0.5714 - 31ms/epoch - 31ms/step\n",
            "Epoch 10/200\n",
            "1/1 - 0s - loss: 1.9609 - accuracy: 0.5000 - val_loss: 3.3394 - val_accuracy: 0.5714 - 50ms/epoch - 50ms/step\n",
            "Epoch 11/200\n",
            "1/1 - 0s - loss: 1.9254 - accuracy: 0.5000 - val_loss: 3.2940 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 12/200\n",
            "1/1 - 0s - loss: 1.8964 - accuracy: 0.5000 - val_loss: 3.2574 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 13/200\n",
            "1/1 - 0s - loss: 1.8720 - accuracy: 0.5000 - val_loss: 2.5579 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 14/200\n",
            "1/1 - 0s - loss: 1.8510 - accuracy: 0.5000 - val_loss: 2.4215 - val_accuracy: 0.5714 - 52ms/epoch - 52ms/step\n",
            "Epoch 15/200\n",
            "1/1 - 0s - loss: 1.8328 - accuracy: 0.5000 - val_loss: 2.3598 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 16/200\n",
            "1/1 - 0s - loss: 1.8168 - accuracy: 0.5000 - val_loss: 2.3163 - val_accuracy: 0.5714 - 41ms/epoch - 41ms/step\n",
            "Epoch 17/200\n",
            "1/1 - 0s - loss: 1.8028 - accuracy: 0.5000 - val_loss: 2.2821 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 18/200\n",
            "1/1 - 0s - loss: 1.7902 - accuracy: 0.5000 - val_loss: 2.2536 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 19/200\n",
            "1/1 - 0s - loss: 1.7790 - accuracy: 0.5000 - val_loss: 2.2292 - val_accuracy: 0.5714 - 51ms/epoch - 51ms/step\n",
            "Epoch 20/200\n",
            "1/1 - 0s - loss: 1.7688 - accuracy: 0.5000 - val_loss: 2.2079 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 21/200\n",
            "1/1 - 0s - loss: 1.7597 - accuracy: 0.5000 - val_loss: 2.1891 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 22/200\n",
            "1/1 - 0s - loss: 1.7514 - accuracy: 0.5000 - val_loss: 2.1723 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 23/200\n",
            "1/1 - 0s - loss: 1.7438 - accuracy: 0.5000 - val_loss: 2.1571 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 24/200\n",
            "1/1 - 0s - loss: 1.7368 - accuracy: 0.5000 - val_loss: 2.1433 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 25/200\n",
            "1/1 - 0s - loss: 1.7306 - accuracy: 0.5000 - val_loss: 2.1309 - val_accuracy: 0.5714 - 29ms/epoch - 29ms/step\n",
            "Epoch 26/200\n",
            "1/1 - 0s - loss: 1.7248 - accuracy: 0.5000 - val_loss: 2.1195 - val_accuracy: 0.5714 - 29ms/epoch - 29ms/step\n",
            "Epoch 27/200\n",
            "1/1 - 0s - loss: 1.7196 - accuracy: 0.5000 - val_loss: 2.1091 - val_accuracy: 0.5714 - 31ms/epoch - 31ms/step\n",
            "Epoch 28/200\n",
            "1/1 - 0s - loss: 1.7147 - accuracy: 0.5000 - val_loss: 2.0995 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 29/200\n",
            "1/1 - 0s - loss: 1.7103 - accuracy: 0.5000 - val_loss: 2.0906 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 30/200\n",
            "1/1 - 0s - loss: 1.7062 - accuracy: 0.5000 - val_loss: 2.0824 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 31/200\n",
            "1/1 - 0s - loss: 1.7023 - accuracy: 0.5000 - val_loss: 2.0747 - val_accuracy: 0.5714 - 31ms/epoch - 31ms/step\n",
            "Epoch 32/200\n",
            "1/1 - 0s - loss: 1.6988 - accuracy: 0.5000 - val_loss: 2.0676 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 33/200\n",
            "1/1 - 0s - loss: 1.6955 - accuracy: 0.5000 - val_loss: 2.0610 - val_accuracy: 0.5714 - 31ms/epoch - 31ms/step\n",
            "Epoch 34/200\n",
            "1/1 - 0s - loss: 1.6924 - accuracy: 0.5000 - val_loss: 2.0548 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 35/200\n",
            "1/1 - 0s - loss: 1.6896 - accuracy: 0.5000 - val_loss: 2.0490 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 36/200\n",
            "1/1 - 0s - loss: 1.6869 - accuracy: 0.5000 - val_loss: 2.0436 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 37/200\n",
            "1/1 - 0s - loss: 1.6844 - accuracy: 0.5000 - val_loss: 2.0385 - val_accuracy: 0.5714 - 38ms/epoch - 38ms/step\n",
            "Epoch 38/200\n",
            "1/1 - 0s - loss: 1.6820 - accuracy: 0.5000 - val_loss: 2.0336 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 39/200\n",
            "1/1 - 0s - loss: 1.6798 - accuracy: 0.5000 - val_loss: 2.0291 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 40/200\n",
            "1/1 - 0s - loss: 1.6778 - accuracy: 0.5000 - val_loss: 2.0247 - val_accuracy: 0.5714 - 31ms/epoch - 31ms/step\n",
            "Epoch 41/200\n",
            "1/1 - 0s - loss: 1.6759 - accuracy: 0.5000 - val_loss: 2.0207 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 42/200\n",
            "1/1 - 0s - loss: 1.6741 - accuracy: 0.5000 - val_loss: 2.0168 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 43/200\n",
            "1/1 - 0s - loss: 1.6723 - accuracy: 0.5000 - val_loss: 2.0132 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 44/200\n",
            "1/1 - 0s - loss: 1.6707 - accuracy: 0.5000 - val_loss: 2.0098 - val_accuracy: 0.5714 - 31ms/epoch - 31ms/step\n",
            "Epoch 45/200\n",
            "1/1 - 0s - loss: 1.6691 - accuracy: 0.5000 - val_loss: 2.0066 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 46/200\n",
            "1/1 - 0s - loss: 1.6677 - accuracy: 0.5000 - val_loss: 2.0036 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 47/200\n",
            "1/1 - 0s - loss: 1.6662 - accuracy: 0.5000 - val_loss: 2.0007 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 48/200\n",
            "1/1 - 0s - loss: 1.6649 - accuracy: 0.5000 - val_loss: 1.9981 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 49/200\n",
            "1/1 - 0s - loss: 1.6636 - accuracy: 0.5000 - val_loss: 1.9955 - val_accuracy: 0.5714 - 31ms/epoch - 31ms/step\n",
            "Epoch 50/200\n",
            "1/1 - 0s - loss: 1.6623 - accuracy: 0.5000 - val_loss: 1.9931 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 51/200\n",
            "1/1 - 0s - loss: 1.6611 - accuracy: 0.5000 - val_loss: 1.9908 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 52/200\n",
            "1/1 - 0s - loss: 1.6599 - accuracy: 0.5000 - val_loss: 1.9887 - val_accuracy: 0.5714 - 40ms/epoch - 40ms/step\n",
            "Epoch 53/200\n",
            "1/1 - 0s - loss: 1.6587 - accuracy: 0.5000 - val_loss: 1.9866 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 54/200\n",
            "1/1 - 0s - loss: 1.6576 - accuracy: 0.5000 - val_loss: 1.9847 - val_accuracy: 0.5714 - 31ms/epoch - 31ms/step\n",
            "Epoch 55/200\n",
            "1/1 - 0s - loss: 1.6565 - accuracy: 0.5000 - val_loss: 1.9828 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 56/200\n",
            "1/1 - 0s - loss: 1.6554 - accuracy: 0.5000 - val_loss: 1.9809 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 57/200\n",
            "1/1 - 0s - loss: 1.6544 - accuracy: 0.5000 - val_loss: 1.9790 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 58/200\n",
            "1/1 - 0s - loss: 1.6534 - accuracy: 0.5000 - val_loss: 1.9771 - val_accuracy: 0.5714 - 31ms/epoch - 31ms/step\n",
            "Epoch 59/200\n",
            "1/1 - 0s - loss: 1.6524 - accuracy: 0.5000 - val_loss: 1.9752 - val_accuracy: 0.5714 - 29ms/epoch - 29ms/step\n",
            "Epoch 60/200\n",
            "1/1 - 0s - loss: 1.6514 - accuracy: 0.5000 - val_loss: 1.9734 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 61/200\n",
            "1/1 - 0s - loss: 1.6504 - accuracy: 0.5000 - val_loss: 1.9715 - val_accuracy: 0.5714 - 29ms/epoch - 29ms/step\n",
            "Epoch 62/200\n",
            "1/1 - 0s - loss: 1.6495 - accuracy: 0.5000 - val_loss: 1.9697 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 63/200\n",
            "1/1 - 0s - loss: 1.6485 - accuracy: 0.5000 - val_loss: 1.9679 - val_accuracy: 0.5714 - 31ms/epoch - 31ms/step\n",
            "Epoch 64/200\n",
            "1/1 - 0s - loss: 1.6476 - accuracy: 0.5000 - val_loss: 1.9661 - val_accuracy: 0.5714 - 31ms/epoch - 31ms/step\n",
            "Epoch 65/200\n",
            "1/1 - 0s - loss: 1.6467 - accuracy: 0.5000 - val_loss: 1.9643 - val_accuracy: 0.5714 - 54ms/epoch - 54ms/step\n",
            "Epoch 66/200\n",
            "1/1 - 0s - loss: 1.6458 - accuracy: 0.5000 - val_loss: 1.9626 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 67/200\n",
            "1/1 - 0s - loss: 1.6449 - accuracy: 0.5000 - val_loss: 1.9609 - val_accuracy: 0.5714 - 31ms/epoch - 31ms/step\n",
            "Epoch 68/200\n",
            "1/1 - 0s - loss: 1.6441 - accuracy: 0.5000 - val_loss: 1.9592 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 69/200\n",
            "1/1 - 0s - loss: 1.6432 - accuracy: 0.5000 - val_loss: 1.9576 - val_accuracy: 0.5714 - 29ms/epoch - 29ms/step\n",
            "Epoch 70/200\n",
            "1/1 - 0s - loss: 1.6424 - accuracy: 0.5000 - val_loss: 1.9561 - val_accuracy: 0.5714 - 29ms/epoch - 29ms/step\n",
            "Epoch 71/200\n",
            "1/1 - 0s - loss: 1.6416 - accuracy: 0.5000 - val_loss: 1.9546 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 72/200\n",
            "1/1 - 0s - loss: 1.6408 - accuracy: 0.5000 - val_loss: 1.9531 - val_accuracy: 0.5714 - 30ms/epoch - 30ms/step\n",
            "Epoch 73/200\n",
            "1/1 - 0s - loss: 1.6400 - accuracy: 0.5000 - val_loss: 1.9518 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 74/200\n",
            "1/1 - 0s - loss: 1.6392 - accuracy: 0.5000 - val_loss: 1.9504 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 75/200\n",
            "1/1 - 0s - loss: 1.6385 - accuracy: 0.5000 - val_loss: 1.9490 - val_accuracy: 0.5714 - 50ms/epoch - 50ms/step\n",
            "Epoch 76/200\n",
            "1/1 - 0s - loss: 1.6377 - accuracy: 0.5000 - val_loss: 1.9477 - val_accuracy: 0.5714 - 51ms/epoch - 51ms/step\n",
            "Epoch 77/200\n",
            "1/1 - 0s - loss: 1.6370 - accuracy: 0.5000 - val_loss: 1.9463 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 78/200\n",
            "1/1 - 0s - loss: 1.6363 - accuracy: 0.5000 - val_loss: 1.9450 - val_accuracy: 0.5714 - 44ms/epoch - 44ms/step\n",
            "Epoch 79/200\n",
            "1/1 - 0s - loss: 1.6356 - accuracy: 0.5000 - val_loss: 1.9437 - val_accuracy: 0.5714 - 37ms/epoch - 37ms/step\n",
            "Epoch 80/200\n",
            "1/1 - 0s - loss: 1.6349 - accuracy: 0.5000 - val_loss: 1.9424 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 81/200\n",
            "1/1 - 0s - loss: 1.6342 - accuracy: 0.4444 - val_loss: 1.9411 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 82/200\n",
            "1/1 - 0s - loss: 1.6335 - accuracy: 0.4444 - val_loss: 1.9397 - val_accuracy: 0.5714 - 49ms/epoch - 49ms/step\n",
            "Epoch 83/200\n",
            "1/1 - 0s - loss: 1.6328 - accuracy: 0.4444 - val_loss: 1.9384 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 84/200\n",
            "1/1 - 0s - loss: 1.6321 - accuracy: 0.4444 - val_loss: 1.9370 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 85/200\n",
            "1/1 - 0s - loss: 1.6315 - accuracy: 0.4444 - val_loss: 1.9357 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 86/200\n",
            "1/1 - 0s - loss: 1.6308 - accuracy: 0.3889 - val_loss: 1.9343 - val_accuracy: 0.4286 - 38ms/epoch - 38ms/step\n",
            "Epoch 87/200\n",
            "1/1 - 0s - loss: 1.6302 - accuracy: 0.3889 - val_loss: 1.9329 - val_accuracy: 0.4286 - 36ms/epoch - 36ms/step\n",
            "Epoch 88/200\n",
            "1/1 - 0s - loss: 1.6296 - accuracy: 0.3889 - val_loss: 1.9316 - val_accuracy: 0.4286 - 35ms/epoch - 35ms/step\n",
            "Epoch 89/200\n",
            "1/1 - 0s - loss: 1.6290 - accuracy: 0.3889 - val_loss: 1.9303 - val_accuracy: 0.4286 - 35ms/epoch - 35ms/step\n",
            "Epoch 90/200\n",
            "1/1 - 0s - loss: 1.6284 - accuracy: 0.3889 - val_loss: 1.9290 - val_accuracy: 0.4286 - 45ms/epoch - 45ms/step\n",
            "Epoch 91/200\n",
            "1/1 - 0s - loss: 1.6277 - accuracy: 0.3889 - val_loss: 1.9277 - val_accuracy: 0.4286 - 35ms/epoch - 35ms/step\n",
            "Epoch 92/200\n",
            "1/1 - 0s - loss: 1.6271 - accuracy: 0.3889 - val_loss: 1.9264 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 93/200\n",
            "1/1 - 0s - loss: 1.6265 - accuracy: 0.4444 - val_loss: 1.9252 - val_accuracy: 0.4286 - 37ms/epoch - 37ms/step\n",
            "Epoch 94/200\n",
            "1/1 - 0s - loss: 1.6258 - accuracy: 0.4444 - val_loss: 1.9240 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 95/200\n",
            "1/1 - 0s - loss: 1.6252 - accuracy: 0.4444 - val_loss: 1.9229 - val_accuracy: 0.4286 - 35ms/epoch - 35ms/step\n",
            "Epoch 96/200\n",
            "1/1 - 0s - loss: 1.6246 - accuracy: 0.4444 - val_loss: 1.9221 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 97/200\n",
            "1/1 - 0s - loss: 1.6240 - accuracy: 0.4444 - val_loss: 1.9213 - val_accuracy: 0.4286 - 53ms/epoch - 53ms/step\n",
            "Epoch 98/200\n",
            "1/1 - 0s - loss: 1.6234 - accuracy: 0.4444 - val_loss: 1.9206 - val_accuracy: 0.4286 - 51ms/epoch - 51ms/step\n",
            "Epoch 99/200\n",
            "1/1 - 0s - loss: 1.6228 - accuracy: 0.4444 - val_loss: 1.9199 - val_accuracy: 0.4286 - 35ms/epoch - 35ms/step\n",
            "Epoch 100/200\n",
            "1/1 - 0s - loss: 1.6222 - accuracy: 0.4444 - val_loss: 1.9192 - val_accuracy: 0.4286 - 49ms/epoch - 49ms/step\n",
            "Epoch 101/200\n",
            "1/1 - 0s - loss: 1.6216 - accuracy: 0.4444 - val_loss: 1.9184 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 102/200\n",
            "1/1 - 0s - loss: 1.6210 - accuracy: 0.4444 - val_loss: 1.9176 - val_accuracy: 0.4286 - 30ms/epoch - 30ms/step\n",
            "Epoch 103/200\n",
            "1/1 - 0s - loss: 1.6204 - accuracy: 0.4444 - val_loss: 1.9167 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 104/200\n",
            "1/1 - 0s - loss: 1.6198 - accuracy: 0.4444 - val_loss: 1.9158 - val_accuracy: 0.4286 - 31ms/epoch - 31ms/step\n",
            "Epoch 105/200\n",
            "1/1 - 0s - loss: 1.6192 - accuracy: 0.4444 - val_loss: 1.9149 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 106/200\n",
            "1/1 - 0s - loss: 1.6187 - accuracy: 0.4444 - val_loss: 1.9140 - val_accuracy: 0.4286 - 34ms/epoch - 34ms/step\n",
            "Epoch 107/200\n",
            "1/1 - 0s - loss: 1.6181 - accuracy: 0.4444 - val_loss: 1.9131 - val_accuracy: 0.4286 - 31ms/epoch - 31ms/step\n",
            "Epoch 108/200\n",
            "1/1 - 0s - loss: 1.6175 - accuracy: 0.3889 - val_loss: 1.9121 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 109/200\n",
            "1/1 - 0s - loss: 1.6169 - accuracy: 0.3889 - val_loss: 1.9112 - val_accuracy: 0.4286 - 35ms/epoch - 35ms/step\n",
            "Epoch 110/200\n",
            "1/1 - 0s - loss: 1.6163 - accuracy: 0.3889 - val_loss: 1.9104 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 111/200\n",
            "1/1 - 0s - loss: 1.6158 - accuracy: 0.3889 - val_loss: 1.9098 - val_accuracy: 0.4286 - 31ms/epoch - 31ms/step\n",
            "Epoch 112/200\n",
            "1/1 - 0s - loss: 1.6152 - accuracy: 0.3889 - val_loss: 1.9091 - val_accuracy: 0.4286 - 36ms/epoch - 36ms/step\n",
            "Epoch 113/200\n",
            "1/1 - 0s - loss: 1.6147 - accuracy: 0.3889 - val_loss: 1.9085 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 114/200\n",
            "1/1 - 0s - loss: 1.6141 - accuracy: 0.3889 - val_loss: 1.9077 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 115/200\n",
            "1/1 - 0s - loss: 1.6136 - accuracy: 0.3889 - val_loss: 1.9070 - val_accuracy: 0.4286 - 54ms/epoch - 54ms/step\n",
            "Epoch 116/200\n",
            "1/1 - 0s - loss: 1.6130 - accuracy: 0.3889 - val_loss: 1.9063 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 117/200\n",
            "1/1 - 0s - loss: 1.6125 - accuracy: 0.3889 - val_loss: 1.9056 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 118/200\n",
            "1/1 - 0s - loss: 1.6119 - accuracy: 0.3889 - val_loss: 1.9049 - val_accuracy: 0.4286 - 31ms/epoch - 31ms/step\n",
            "Epoch 119/200\n",
            "1/1 - 0s - loss: 1.6114 - accuracy: 0.3889 - val_loss: 1.9042 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 120/200\n",
            "1/1 - 0s - loss: 1.6108 - accuracy: 0.3889 - val_loss: 1.9034 - val_accuracy: 0.4286 - 30ms/epoch - 30ms/step\n",
            "Epoch 121/200\n",
            "1/1 - 0s - loss: 1.6103 - accuracy: 0.3889 - val_loss: 1.9027 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 122/200\n",
            "1/1 - 0s - loss: 1.6098 - accuracy: 0.3889 - val_loss: 1.9021 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 123/200\n",
            "1/1 - 0s - loss: 1.6092 - accuracy: 0.3889 - val_loss: 1.9014 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 124/200\n",
            "1/1 - 0s - loss: 1.6087 - accuracy: 0.3889 - val_loss: 1.9008 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 125/200\n",
            "1/1 - 0s - loss: 1.6082 - accuracy: 0.3889 - val_loss: 1.9001 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 126/200\n",
            "1/1 - 0s - loss: 1.6077 - accuracy: 0.3889 - val_loss: 1.8994 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 127/200\n",
            "1/1 - 0s - loss: 1.6071 - accuracy: 0.3333 - val_loss: 1.8988 - val_accuracy: 0.4286 - 38ms/epoch - 38ms/step\n",
            "Epoch 128/200\n",
            "1/1 - 0s - loss: 1.6066 - accuracy: 0.3333 - val_loss: 1.8981 - val_accuracy: 0.4286 - 30ms/epoch - 30ms/step\n",
            "Epoch 129/200\n",
            "1/1 - 0s - loss: 1.6061 - accuracy: 0.3333 - val_loss: 1.8974 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 130/200\n",
            "1/1 - 0s - loss: 1.6056 - accuracy: 0.3333 - val_loss: 1.8968 - val_accuracy: 0.4286 - 31ms/epoch - 31ms/step\n",
            "Epoch 131/200\n",
            "1/1 - 0s - loss: 1.6050 - accuracy: 0.3333 - val_loss: 1.8961 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 132/200\n",
            "1/1 - 0s - loss: 1.6045 - accuracy: 0.3333 - val_loss: 1.8956 - val_accuracy: 0.4286 - 31ms/epoch - 31ms/step\n",
            "Epoch 133/200\n",
            "1/1 - 0s - loss: 1.6040 - accuracy: 0.3333 - val_loss: 1.8950 - val_accuracy: 0.4286 - 41ms/epoch - 41ms/step\n",
            "Epoch 134/200\n",
            "1/1 - 0s - loss: 1.6035 - accuracy: 0.3333 - val_loss: 1.8945 - val_accuracy: 0.4286 - 31ms/epoch - 31ms/step\n",
            "Epoch 135/200\n",
            "1/1 - 0s - loss: 1.6029 - accuracy: 0.3333 - val_loss: 1.8941 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 136/200\n",
            "1/1 - 0s - loss: 1.6024 - accuracy: 0.3333 - val_loss: 1.8936 - val_accuracy: 0.4286 - 30ms/epoch - 30ms/step\n",
            "Epoch 137/200\n",
            "1/1 - 0s - loss: 1.6019 - accuracy: 0.3333 - val_loss: 1.8931 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 138/200\n",
            "1/1 - 0s - loss: 1.6014 - accuracy: 0.3333 - val_loss: 1.8926 - val_accuracy: 0.4286 - 30ms/epoch - 30ms/step\n",
            "Epoch 139/200\n",
            "1/1 - 0s - loss: 1.6008 - accuracy: 0.3333 - val_loss: 1.8921 - val_accuracy: 0.4286 - 30ms/epoch - 30ms/step\n",
            "Epoch 140/200\n",
            "1/1 - 0s - loss: 1.6003 - accuracy: 0.3333 - val_loss: 1.8916 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 141/200\n",
            "1/1 - 0s - loss: 1.5998 - accuracy: 0.3333 - val_loss: 1.8911 - val_accuracy: 0.4286 - 31ms/epoch - 31ms/step\n",
            "Epoch 142/200\n",
            "1/1 - 0s - loss: 1.5992 - accuracy: 0.3333 - val_loss: 1.8905 - val_accuracy: 0.4286 - 30ms/epoch - 30ms/step\n",
            "Epoch 143/200\n",
            "1/1 - 0s - loss: 1.5987 - accuracy: 0.3333 - val_loss: 1.8899 - val_accuracy: 0.4286 - 41ms/epoch - 41ms/step\n",
            "Epoch 144/200\n",
            "1/1 - 0s - loss: 1.5982 - accuracy: 0.3333 - val_loss: 1.8893 - val_accuracy: 0.4286 - 30ms/epoch - 30ms/step\n",
            "Epoch 145/200\n",
            "1/1 - 0s - loss: 1.5977 - accuracy: 0.3333 - val_loss: 1.8887 - val_accuracy: 0.4286 - 34ms/epoch - 34ms/step\n",
            "Epoch 146/200\n",
            "1/1 - 0s - loss: 1.5971 - accuracy: 0.3333 - val_loss: 1.8881 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 147/200\n",
            "1/1 - 0s - loss: 1.5966 - accuracy: 0.3333 - val_loss: 1.8876 - val_accuracy: 0.4286 - 51ms/epoch - 51ms/step\n",
            "Epoch 148/200\n",
            "1/1 - 0s - loss: 1.5961 - accuracy: 0.3333 - val_loss: 1.8870 - val_accuracy: 0.4286 - 31ms/epoch - 31ms/step\n",
            "Epoch 149/200\n",
            "1/1 - 0s - loss: 1.5956 - accuracy: 0.3333 - val_loss: 1.8865 - val_accuracy: 0.4286 - 34ms/epoch - 34ms/step\n",
            "Epoch 150/200\n",
            "1/1 - 0s - loss: 1.5950 - accuracy: 0.3333 - val_loss: 1.8859 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 151/200\n",
            "1/1 - 0s - loss: 1.5945 - accuracy: 0.3333 - val_loss: 1.8855 - val_accuracy: 0.4286 - 31ms/epoch - 31ms/step\n",
            "Epoch 152/200\n",
            "1/1 - 0s - loss: 1.5940 - accuracy: 0.3333 - val_loss: 1.8849 - val_accuracy: 0.4286 - 30ms/epoch - 30ms/step\n",
            "Epoch 153/200\n",
            "1/1 - 0s - loss: 1.5935 - accuracy: 0.3333 - val_loss: 1.8843 - val_accuracy: 0.4286 - 29ms/epoch - 29ms/step\n",
            "Epoch 154/200\n",
            "1/1 - 0s - loss: 1.5930 - accuracy: 0.2778 - val_loss: 1.8837 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 155/200\n",
            "1/1 - 0s - loss: 1.5925 - accuracy: 0.2778 - val_loss: 1.8830 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 156/200\n",
            "1/1 - 0s - loss: 1.5920 - accuracy: 0.2778 - val_loss: 1.8823 - val_accuracy: 0.4286 - 30ms/epoch - 30ms/step\n",
            "Epoch 157/200\n",
            "1/1 - 0s - loss: 1.5915 - accuracy: 0.2778 - val_loss: 1.8817 - val_accuracy: 0.4286 - 30ms/epoch - 30ms/step\n",
            "Epoch 158/200\n",
            "1/1 - 0s - loss: 1.5910 - accuracy: 0.2778 - val_loss: 1.8811 - val_accuracy: 0.4286 - 31ms/epoch - 31ms/step\n",
            "Epoch 159/200\n",
            "1/1 - 0s - loss: 1.5905 - accuracy: 0.2778 - val_loss: 1.8805 - val_accuracy: 0.4286 - 34ms/epoch - 34ms/step\n",
            "Epoch 160/200\n",
            "1/1 - 0s - loss: 1.5900 - accuracy: 0.2778 - val_loss: 1.8799 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 161/200\n",
            "1/1 - 0s - loss: 1.5895 - accuracy: 0.2778 - val_loss: 1.8794 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 162/200\n",
            "1/1 - 0s - loss: 1.5889 - accuracy: 0.2778 - val_loss: 1.8788 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 163/200\n",
            "1/1 - 0s - loss: 1.5884 - accuracy: 0.2778 - val_loss: 1.8782 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 164/200\n",
            "1/1 - 0s - loss: 1.5879 - accuracy: 0.2778 - val_loss: 1.8777 - val_accuracy: 0.4286 - 36ms/epoch - 36ms/step\n",
            "Epoch 165/200\n",
            "1/1 - 0s - loss: 1.5874 - accuracy: 0.2778 - val_loss: 1.8773 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 166/200\n",
            "1/1 - 0s - loss: 1.5869 - accuracy: 0.2778 - val_loss: 1.8769 - val_accuracy: 0.4286 - 56ms/epoch - 56ms/step\n",
            "Epoch 167/200\n",
            "1/1 - 0s - loss: 1.5864 - accuracy: 0.2778 - val_loss: 1.8766 - val_accuracy: 0.4286 - 48ms/epoch - 48ms/step\n",
            "Epoch 168/200\n",
            "1/1 - 0s - loss: 1.5859 - accuracy: 0.2778 - val_loss: 1.8761 - val_accuracy: 0.4286 - 56ms/epoch - 56ms/step\n",
            "Epoch 169/200\n",
            "1/1 - 0s - loss: 1.5853 - accuracy: 0.2778 - val_loss: 1.8756 - val_accuracy: 0.4286 - 65ms/epoch - 65ms/step\n",
            "Epoch 170/200\n",
            "1/1 - 0s - loss: 1.5848 - accuracy: 0.2778 - val_loss: 1.8750 - val_accuracy: 0.4286 - 56ms/epoch - 56ms/step\n",
            "Epoch 171/200\n",
            "1/1 - 0s - loss: 1.5843 - accuracy: 0.2778 - val_loss: 1.8745 - val_accuracy: 0.4286 - 60ms/epoch - 60ms/step\n",
            "Epoch 172/200\n",
            "1/1 - 0s - loss: 1.5838 - accuracy: 0.2778 - val_loss: 1.8740 - val_accuracy: 0.4286 - 59ms/epoch - 59ms/step\n",
            "Epoch 173/200\n",
            "1/1 - 0s - loss: 1.5833 - accuracy: 0.2778 - val_loss: 1.8735 - val_accuracy: 0.4286 - 46ms/epoch - 46ms/step\n",
            "Epoch 174/200\n",
            "1/1 - 0s - loss: 1.5828 - accuracy: 0.2778 - val_loss: 1.8730 - val_accuracy: 0.4286 - 68ms/epoch - 68ms/step\n",
            "Epoch 175/200\n",
            "1/1 - 0s - loss: 1.5823 - accuracy: 0.2778 - val_loss: 1.8725 - val_accuracy: 0.4286 - 45ms/epoch - 45ms/step\n",
            "Epoch 176/200\n",
            "1/1 - 0s - loss: 1.5818 - accuracy: 0.2778 - val_loss: 1.8720 - val_accuracy: 0.4286 - 61ms/epoch - 61ms/step\n",
            "Epoch 177/200\n",
            "1/1 - 0s - loss: 1.5813 - accuracy: 0.2778 - val_loss: 1.8715 - val_accuracy: 0.4286 - 49ms/epoch - 49ms/step\n",
            "Epoch 178/200\n",
            "1/1 - 0s - loss: 1.5808 - accuracy: 0.2778 - val_loss: 1.8709 - val_accuracy: 0.4286 - 47ms/epoch - 47ms/step\n",
            "Epoch 179/200\n",
            "1/1 - 0s - loss: 1.5803 - accuracy: 0.2778 - val_loss: 1.8704 - val_accuracy: 0.4286 - 65ms/epoch - 65ms/step\n",
            "Epoch 180/200\n",
            "1/1 - 0s - loss: 1.5798 - accuracy: 0.2778 - val_loss: 1.8699 - val_accuracy: 0.4286 - 71ms/epoch - 71ms/step\n",
            "Epoch 181/200\n",
            "1/1 - 0s - loss: 1.5793 - accuracy: 0.2778 - val_loss: 1.8694 - val_accuracy: 0.4286 - 63ms/epoch - 63ms/step\n",
            "Epoch 182/200\n",
            "1/1 - 0s - loss: 1.5788 - accuracy: 0.2778 - val_loss: 1.8689 - val_accuracy: 0.4286 - 51ms/epoch - 51ms/step\n",
            "Epoch 183/200\n",
            "1/1 - 0s - loss: 1.5783 - accuracy: 0.2778 - val_loss: 1.8684 - val_accuracy: 0.4286 - 64ms/epoch - 64ms/step\n",
            "Epoch 184/200\n",
            "1/1 - 0s - loss: 1.5778 - accuracy: 0.2778 - val_loss: 1.8679 - val_accuracy: 0.4286 - 52ms/epoch - 52ms/step\n",
            "Epoch 185/200\n",
            "1/1 - 0s - loss: 1.5774 - accuracy: 0.2778 - val_loss: 1.8674 - val_accuracy: 0.4286 - 68ms/epoch - 68ms/step\n",
            "Epoch 186/200\n",
            "1/1 - 0s - loss: 1.5769 - accuracy: 0.2222 - val_loss: 1.8670 - val_accuracy: 0.4286 - 73ms/epoch - 73ms/step\n",
            "Epoch 187/200\n",
            "1/1 - 0s - loss: 1.5764 - accuracy: 0.2222 - val_loss: 1.8666 - val_accuracy: 0.4286 - 66ms/epoch - 66ms/step\n",
            "Epoch 188/200\n",
            "1/1 - 0s - loss: 1.5759 - accuracy: 0.2222 - val_loss: 1.8662 - val_accuracy: 0.4286 - 48ms/epoch - 48ms/step\n",
            "Epoch 189/200\n",
            "1/1 - 0s - loss: 1.5755 - accuracy: 0.2222 - val_loss: 1.8658 - val_accuracy: 0.4286 - 44ms/epoch - 44ms/step\n",
            "Epoch 190/200\n",
            "1/1 - 0s - loss: 1.5750 - accuracy: 0.2222 - val_loss: 1.8654 - val_accuracy: 0.4286 - 65ms/epoch - 65ms/step\n",
            "Epoch 191/200\n",
            "1/1 - 0s - loss: 1.5745 - accuracy: 0.2222 - val_loss: 1.8649 - val_accuracy: 0.4286 - 45ms/epoch - 45ms/step\n",
            "Epoch 192/200\n",
            "1/1 - 0s - loss: 1.5741 - accuracy: 0.2222 - val_loss: 1.8644 - val_accuracy: 0.4286 - 45ms/epoch - 45ms/step\n",
            "Epoch 193/200\n",
            "1/1 - 0s - loss: 1.5736 - accuracy: 0.2222 - val_loss: 1.8639 - val_accuracy: 0.4286 - 61ms/epoch - 61ms/step\n",
            "Epoch 194/200\n",
            "1/1 - 0s - loss: 1.5731 - accuracy: 0.2222 - val_loss: 1.8634 - val_accuracy: 0.4286 - 67ms/epoch - 67ms/step\n",
            "Epoch 195/200\n",
            "1/1 - 0s - loss: 1.5727 - accuracy: 0.2222 - val_loss: 1.8629 - val_accuracy: 0.4286 - 46ms/epoch - 46ms/step\n",
            "Epoch 196/200\n",
            "1/1 - 0s - loss: 1.5722 - accuracy: 0.2222 - val_loss: 1.8625 - val_accuracy: 0.4286 - 51ms/epoch - 51ms/step\n",
            "Epoch 197/200\n",
            "1/1 - 0s - loss: 1.5717 - accuracy: 0.2222 - val_loss: 1.8620 - val_accuracy: 0.4286 - 64ms/epoch - 64ms/step\n",
            "Epoch 198/200\n",
            "1/1 - 0s - loss: 1.5713 - accuracy: 0.2222 - val_loss: 1.8615 - val_accuracy: 0.4286 - 59ms/epoch - 59ms/step\n",
            "Epoch 199/200\n",
            "1/1 - 0s - loss: 1.5708 - accuracy: 0.2222 - val_loss: 1.8610 - val_accuracy: 0.4286 - 52ms/epoch - 52ms/step\n",
            "Epoch 200/200\n",
            "1/1 - 0s - loss: 1.5703 - accuracy: 0.2222 - val_loss: 1.8605 - val_accuracy: 0.4286 - 64ms/epoch - 64ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'\n",
        "\n",
        "def plot_metric(history, metric):\n",
        "    train_metrics = history.history[metric]\n",
        "    val_metrics = history.history['val_'+metric]\n",
        "    epochs = range(1, len(train_metrics) + 1)\n",
        "    plt.plot(epochs, train_metrics)\n",
        "    plt.plot(epochs, val_metrics)\n",
        "    plt.title('Training and validation '+ metric)\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Bed28yK-TgMA"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metric(history, 'accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "t8B3DUkCTtug",
        "outputId": "b7fe78a9-0c53-47b8-aaa7-31ff4fe8e9fc"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"408.10125pt\" height=\"325.986375pt\" viewBox=\"0 0 408.10125 325.986375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-11-23T17:51:29.744813</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 325.986375 \nL 408.10125 325.986375 \nL 408.10125 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 288.430125 \nL 400.90125 288.430125 \nL 400.90125 22.318125 \nL 43.78125 22.318125 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m607a1113d6\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m607a1113d6\" x=\"58.382547\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(55.201297 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m607a1113d6\" x=\"99.168294\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <g transform=\"translate(92.805794 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m607a1113d6\" x=\"139.954041\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(133.591541 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m607a1113d6\" x=\"180.739788\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <g transform=\"translate(174.377288 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m607a1113d6\" x=\"221.525535\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(211.981785 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m607a1113d6\" x=\"262.311282\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(252.767532 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m607a1113d6\" x=\"303.097029\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(293.553279 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m607a1113d6\" x=\"343.882776\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(334.339026 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m607a1113d6\" x=\"384.668523\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(375.124773 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- Epochs -->\n     <g transform=\"translate(204.425625 316.706687) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"m33cc2ed922\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m33cc2ed922\" x=\"43.78125\" y=\"287.259545\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.2 -->\n      <g transform=\"translate(20.878125 291.058764) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m33cc2ed922\" x=\"43.78125\" y=\"238.095159\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.3 -->\n      <g transform=\"translate(20.878125 241.894378) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m33cc2ed922\" x=\"43.78125\" y=\"188.930774\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 192.729992) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m33cc2ed922\" x=\"43.78125\" y=\"139.766388\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.5 -->\n      <g transform=\"translate(20.878125 143.565607) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m33cc2ed922\" x=\"43.78125\" y=\"90.602003\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 94.401221) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use xlink:href=\"#m33cc2ed922\" x=\"43.78125\" y=\"41.437617\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.7 -->\n      <g transform=\"translate(20.878125 45.236836) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- accuracy -->\n     <g transform=\"translate(14.798438 177.9335) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-61\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"61.279297\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"116.259766\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"171.240234\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"234.619141\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"275.732422\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"337.011719\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"391.992188\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 60.013977 85.139296 \nL 63.276837 139.766388 \nL 64.908267 112.452828 \nL 66.539697 112.452828 \nL 68.171127 139.766388 \nL 188.896938 139.766388 \nL 190.528367 167.079934 \nL 197.054087 167.079934 \nL 198.685517 194.39348 \nL 208.474096 194.39348 \nL 210.105526 167.079934 \nL 232.945544 167.079934 \nL 234.576974 194.39348 \nL 263.942712 194.39348 \nL 265.574142 221.707026 \nL 307.991319 221.707026 \nL 309.622748 249.020572 \nL 360.197075 249.020572 \nL 361.828504 276.334125 \nL 384.668523 276.334125 \nL 384.668523 276.334125 \n\" clip-path=\"url(#p16e426008c)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 60.013977 104.648957 \nL 63.276837 104.648957 \nL 64.908267 34.414125 \nL 66.539697 104.648957 \nL 197.054087 104.648957 \nL 198.685517 174.883804 \nL 384.668523 174.883804 \nL 384.668523 174.883804 \n\" clip-path=\"url(#p16e426008c)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 288.430125 \nL 43.78125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 400.90125 288.430125 \nL 400.90125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 288.430125 \nL 400.90125 288.430125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 22.318125 \nL 400.90125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_18\">\n    <!-- Training and validation accuracy -->\n    <g transform=\"translate(125.049375 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"487.59375\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"550.972656\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"614.449219\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"646.236328\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"705.416016\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"766.695312\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"794.478516\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"822.261719\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"885.738281\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"947.017578\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"986.226562\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1014.009766\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1075.191406\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1138.570312\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1170.357422\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1231.636719\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1286.617188\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"1341.597656\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"1404.976562\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1446.089844\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1507.369141\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"1562.349609\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 288.5075 60.230625 \nL 393.90125 60.230625 \nQ 395.90125 60.230625 395.90125 58.230625 \nL 395.90125 29.318125 \nQ 395.90125 27.318125 393.90125 27.318125 \nL 288.5075 27.318125 \nQ 286.5075 27.318125 286.5075 29.318125 \nL 286.5075 58.230625 \nQ 286.5075 60.230625 288.5075 60.230625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 290.5075 35.416562 \nL 300.5075 35.416562 \nL 310.5075 35.416562 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_19\">\n     <!-- train_accuracy -->\n     <g transform=\"translate(318.5075 38.916562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"344.042969\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"399.023438\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"454.003906\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"517.382812\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"558.496094\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"619.775391\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"674.755859\"/>\n     </g>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 290.5075 50.372813 \nL 300.5075 50.372813 \nL 310.5075 50.372813 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_20\">\n     <!-- val_accuracy -->\n     <g transform=\"translate(318.5075 53.872813) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"369.482422\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"432.861328\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"473.974609\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"535.253906\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"590.234375\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p16e426008c\">\n   <rect x=\"43.78125\" y=\"22.318125\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metric(history, 'loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "OjtvHggWSqNj",
        "outputId": "8e627392-78c8-4ffd-eb0f-1cc08151e0f2"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"398.560625pt\" height=\"325.986375pt\" viewBox=\"0 0 398.560625 325.986375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-11-23T17:51:40.484174</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 325.986375 \nL 398.560625 325.986375 \nL 398.560625 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 34.240625 288.430125 \nL 391.360625 288.430125 \nL 391.360625 22.318125 \nL 34.240625 22.318125 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m59b3fee5b8\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m59b3fee5b8\" x=\"48.841922\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(45.660672 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m59b3fee5b8\" x=\"89.627669\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <g transform=\"translate(83.265169 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m59b3fee5b8\" x=\"130.413416\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(124.050916 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m59b3fee5b8\" x=\"171.199163\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <g transform=\"translate(164.836663 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m59b3fee5b8\" x=\"211.98491\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(202.44116 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m59b3fee5b8\" x=\"252.770657\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(243.226907 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m59b3fee5b8\" x=\"293.556404\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(284.012654 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m59b3fee5b8\" x=\"334.342151\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(324.798401 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m59b3fee5b8\" x=\"375.127898\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(365.584148 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- Epochs -->\n     <g transform=\"translate(194.885 316.706687) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"m5cd1821568\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m5cd1821568\" x=\"34.240625\" y=\"254.700931\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 2 -->\n      <g transform=\"translate(20.878125 258.50015) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m5cd1821568\" x=\"34.240625\" y=\"204.354309\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 3 -->\n      <g transform=\"translate(20.878125 208.153527) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-33\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m5cd1821568\" x=\"34.240625\" y=\"154.007687\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 4 -->\n      <g transform=\"translate(20.878125 157.806905) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-34\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m5cd1821568\" x=\"34.240625\" y=\"103.661064\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 5 -->\n      <g transform=\"translate(20.878125 107.460283) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m5cd1821568\" x=\"34.240625\" y=\"53.314442\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 6 -->\n      <g transform=\"translate(20.878125 57.113661) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-36\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- loss -->\n     <g transform=\"translate(14.798438 165.031937) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-6c\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"27.783203\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"88.964844\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"141.064453\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 50.473352 111.771325 \nL 52.104782 132.034047 \nL 53.736212 154.245693 \nL 55.367642 185.011228 \nL 56.999072 192.722189 \nL 58.630502 227.495908 \nL 60.261932 246.883138 \nL 61.893361 251.458358 \nL 63.524791 254.427454 \nL 65.156221 256.668244 \nL 66.787651 258.458612 \nL 68.419081 259.918067 \nL 70.050511 261.146794 \nL 71.681941 262.20189 \nL 74.9448 263.922716 \nL 78.20766 265.262464 \nL 81.47052 266.3397 \nL 84.73338 267.219226 \nL 89.627669 268.265145 \nL 94.521959 269.062902 \nL 101.047678 269.866025 \nL 109.204828 270.591461 \nL 118.993407 271.197749 \nL 132.044846 271.764342 \nL 153.253435 272.443108 \nL 180.987742 273.119335 \nL 226.667779 273.989162 \nL 321.290712 275.526105 \nL 375.127898 276.334125 \nL 375.127898 276.334125 \n\" clip-path=\"url(#p0771696fde)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 50.473352 34.414125 \nL 52.104782 39.592393 \nL 53.736212 42.404614 \nL 55.367642 121.391754 \nL 56.999072 129.490995 \nL 58.630502 134.072133 \nL 60.261932 137.183315 \nL 61.893361 179.8628 \nL 63.524791 184.295203 \nL 65.156221 187.268319 \nL 66.787651 189.550126 \nL 68.419081 191.397307 \nL 70.050511 226.613141 \nL 71.681941 233.479711 \nL 73.313371 236.587159 \nL 74.9448 238.774102 \nL 76.57623 240.499531 \nL 78.20766 241.934258 \nL 79.83909 243.162079 \nL 83.10195 245.180647 \nL 86.36481 246.791863 \nL 89.627669 248.110839 \nL 92.890529 249.207749 \nL 97.784819 250.554634 \nL 102.679108 251.631438 \nL 109.204828 252.76269 \nL 115.730547 253.660581 \nL 123.887697 254.520133 \nL 133.676276 255.270794 \nL 154.884864 256.496917 \nL 171.199163 257.26664 \nL 207.09062 258.662967 \nL 226.667779 259.171775 \nL 262.559236 259.932525 \nL 375.127898 261.724766 \nL 375.127898 261.724766 \n\" clip-path=\"url(#p0771696fde)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 34.240625 288.430125 \nL 34.240625 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 391.360625 288.430125 \nL 391.360625 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 34.240625 288.430125 \nL 391.360625 288.430125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 34.240625 22.318125 \nL 391.360625 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_17\">\n    <!-- Training and validation loss -->\n    <g transform=\"translate(130.990625 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"487.59375\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"550.972656\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"614.449219\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"646.236328\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"705.416016\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"766.695312\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"794.478516\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"822.261719\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"885.738281\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"947.017578\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"986.226562\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1014.009766\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1075.191406\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1138.570312\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1170.357422\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1198.140625\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1259.322266\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1311.421875\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 304.77 60.230625 \nL 384.360625 60.230625 \nQ 386.360625 60.230625 386.360625 58.230625 \nL 386.360625 29.318125 \nQ 386.360625 27.318125 384.360625 27.318125 \nL 304.77 27.318125 \nQ 302.77 27.318125 302.77 29.318125 \nL 302.77 58.230625 \nQ 302.77 60.230625 304.77 60.230625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 306.77 35.416562 \nL 316.77 35.416562 \nL 326.77 35.416562 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_18\">\n     <!-- train_loss -->\n     <g transform=\"translate(334.77 38.916562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 306.77 50.372813 \nL 316.77 50.372813 \nL 326.77 50.372813 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_19\">\n     <!-- val_loss -->\n     <g transform=\"translate(334.77 53.872813) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p0771696fde\">\n   <rect x=\"34.240625\" y=\"22.318125\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test set\n",
        "model.evaluate(X_test, y_test, verbose=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j174Cs5BTKAu",
        "outputId": "18d6ccd8-8584-4a78-d242-f6dc7b6e81ef"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 - 0s - loss: 1.8482 - accuracy: 0.5429 - 24ms/epoch - 12ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.8481781482696533, 0.5428571701049805]"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.regularizers import l2\n",
        "\n",
        "def create_regularized_model(factor, rate):\n",
        "    model = Sequential([\n",
        "        Dense(64, activity_regularizer=l1(factor), activation=\"linear\", input_shape=(2,)),\n",
        "        Dropout(rate),\n",
        "        Dense(32, activation=\"relu\"),\n",
        "        Dropout(rate),\n",
        "        Dense(16,  activation=\"relu\"),\n",
        "        Dropout(rate),\n",
        "        Dense(1, activation='sigmoid')\n",
        "\n",
        "    ])\n",
        "    return model"
      ],
      "metadata": {
        "id": "SKJt4CJ_TKJf"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Re-build the model with weight decay and dropout layers\n",
        "model = create_regularized_model(1e-2, 0.5)"
      ],
      "metadata": {
        "id": "EB29KIZ5SqRB"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "leIpw55zVRCr",
        "outputId": "354bb731-d998-4976-a091-21ef2d24163e"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_46 (Dense)            (None, 64)                192       \n",
            "                                                                 \n",
            " dropout_29 (Dropout)        (None, 64)                0         \n",
            "                                                                 \n",
            " dense_47 (Dense)            (None, 32)                2080      \n",
            "                                                                 \n",
            " dropout_30 (Dropout)        (None, 32)                0         \n",
            "                                                                 \n",
            " dense_48 (Dense)            (None, 16)                528       \n",
            "                                                                 \n",
            " dropout_31 (Dropout)        (None, 16)                0         \n",
            "                                                                 \n",
            " dense_49 (Dense)            (None, 1)                 17        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2817 (11.00 KB)\n",
            "Trainable params: 2817 (11.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        "    )"
      ],
      "metadata": {
        "id": "TRi1VWRdVRE_"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model, with some of the data reserved for validation\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=200,\n",
        "    validation_split=0.25,\n",
        "    batch_size=40,\n",
        "    verbose=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdL2sggkV7Pd",
        "outputId": "e994f213-aa5d-4322-d88a-94dd60365fba"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "1/1 - 1s - loss: 0.7850 - accuracy: 0.6111 - val_loss: 0.7938 - val_accuracy: 0.4286 - 1s/epoch - 1s/step\n",
            "Epoch 2/200\n",
            "1/1 - 0s - loss: 0.8453 - accuracy: 0.3889 - val_loss: 0.7923 - val_accuracy: 0.4286 - 35ms/epoch - 35ms/step\n",
            "Epoch 3/200\n",
            "1/1 - 0s - loss: 0.7771 - accuracy: 0.5556 - val_loss: 0.7909 - val_accuracy: 0.4286 - 34ms/epoch - 34ms/step\n",
            "Epoch 4/200\n",
            "1/1 - 0s - loss: 0.8103 - accuracy: 0.5000 - val_loss: 0.7901 - val_accuracy: 0.4286 - 31ms/epoch - 31ms/step\n",
            "Epoch 5/200\n",
            "1/1 - 0s - loss: 0.7087 - accuracy: 0.6667 - val_loss: 0.7894 - val_accuracy: 0.4286 - 38ms/epoch - 38ms/step\n",
            "Epoch 6/200\n",
            "1/1 - 0s - loss: 0.7973 - accuracy: 0.4444 - val_loss: 0.7886 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 7/200\n",
            "1/1 - 0s - loss: 0.8916 - accuracy: 0.3333 - val_loss: 0.7880 - val_accuracy: 0.4286 - 55ms/epoch - 55ms/step\n",
            "Epoch 8/200\n",
            "1/1 - 0s - loss: 0.7031 - accuracy: 0.7222 - val_loss: 0.7875 - val_accuracy: 0.4286 - 36ms/epoch - 36ms/step\n",
            "Epoch 9/200\n",
            "1/1 - 0s - loss: 0.8295 - accuracy: 0.3889 - val_loss: 0.7871 - val_accuracy: 0.4286 - 34ms/epoch - 34ms/step\n",
            "Epoch 10/200\n",
            "1/1 - 0s - loss: 0.7664 - accuracy: 0.4444 - val_loss: 0.7866 - val_accuracy: 0.4286 - 36ms/epoch - 36ms/step\n",
            "Epoch 11/200\n",
            "1/1 - 0s - loss: 0.8021 - accuracy: 0.5556 - val_loss: 0.7862 - val_accuracy: 0.4286 - 34ms/epoch - 34ms/step\n",
            "Epoch 12/200\n",
            "1/1 - 0s - loss: 0.8298 - accuracy: 0.3889 - val_loss: 0.7855 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 13/200\n",
            "1/1 - 0s - loss: 0.8115 - accuracy: 0.3889 - val_loss: 0.7848 - val_accuracy: 0.4286 - 52ms/epoch - 52ms/step\n",
            "Epoch 14/200\n",
            "1/1 - 0s - loss: 0.7804 - accuracy: 0.3333 - val_loss: 0.7841 - val_accuracy: 0.4286 - 37ms/epoch - 37ms/step\n",
            "Epoch 15/200\n",
            "1/1 - 0s - loss: 0.8388 - accuracy: 0.3889 - val_loss: 0.7834 - val_accuracy: 0.4286 - 52ms/epoch - 52ms/step\n",
            "Epoch 16/200\n",
            "1/1 - 0s - loss: 0.8115 - accuracy: 0.5556 - val_loss: 0.7826 - val_accuracy: 0.4286 - 36ms/epoch - 36ms/step\n",
            "Epoch 17/200\n",
            "1/1 - 0s - loss: 0.8150 - accuracy: 0.4444 - val_loss: 0.7818 - val_accuracy: 0.4286 - 38ms/epoch - 38ms/step\n",
            "Epoch 18/200\n",
            "1/1 - 0s - loss: 0.8573 - accuracy: 0.3333 - val_loss: 0.7809 - val_accuracy: 0.4286 - 41ms/epoch - 41ms/step\n",
            "Epoch 19/200\n",
            "1/1 - 0s - loss: 0.7877 - accuracy: 0.6111 - val_loss: 0.7801 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 20/200\n",
            "1/1 - 0s - loss: 0.7339 - accuracy: 0.5000 - val_loss: 0.7793 - val_accuracy: 0.4286 - 35ms/epoch - 35ms/step\n",
            "Epoch 21/200\n",
            "1/1 - 0s - loss: 0.7764 - accuracy: 0.3333 - val_loss: 0.7787 - val_accuracy: 0.4286 - 35ms/epoch - 35ms/step\n",
            "Epoch 22/200\n",
            "1/1 - 0s - loss: 0.7908 - accuracy: 0.4444 - val_loss: 0.7783 - val_accuracy: 0.4286 - 55ms/epoch - 55ms/step\n",
            "Epoch 23/200\n",
            "1/1 - 0s - loss: 0.7527 - accuracy: 0.5000 - val_loss: 0.7778 - val_accuracy: 0.4286 - 36ms/epoch - 36ms/step\n",
            "Epoch 24/200\n",
            "1/1 - 0s - loss: 0.7883 - accuracy: 0.5000 - val_loss: 0.7772 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 25/200\n",
            "1/1 - 0s - loss: 0.7721 - accuracy: 0.5556 - val_loss: 0.7768 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 26/200\n",
            "1/1 - 0s - loss: 0.8175 - accuracy: 0.5556 - val_loss: 0.7764 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 27/200\n",
            "1/1 - 0s - loss: 0.8082 - accuracy: 0.5000 - val_loss: 0.7759 - val_accuracy: 0.4286 - 35ms/epoch - 35ms/step\n",
            "Epoch 28/200\n",
            "1/1 - 0s - loss: 0.8283 - accuracy: 0.3333 - val_loss: 0.7754 - val_accuracy: 0.4286 - 34ms/epoch - 34ms/step\n",
            "Epoch 29/200\n",
            "1/1 - 0s - loss: 0.7966 - accuracy: 0.5000 - val_loss: 0.7749 - val_accuracy: 0.4286 - 38ms/epoch - 38ms/step\n",
            "Epoch 30/200\n",
            "1/1 - 0s - loss: 0.7384 - accuracy: 0.6111 - val_loss: 0.7745 - val_accuracy: 0.4286 - 35ms/epoch - 35ms/step\n",
            "Epoch 31/200\n",
            "1/1 - 0s - loss: 0.7722 - accuracy: 0.5000 - val_loss: 0.7740 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 32/200\n",
            "1/1 - 0s - loss: 0.7438 - accuracy: 0.6667 - val_loss: 0.7737 - val_accuracy: 0.4286 - 32ms/epoch - 32ms/step\n",
            "Epoch 33/200\n",
            "1/1 - 0s - loss: 0.7854 - accuracy: 0.5556 - val_loss: 0.7734 - val_accuracy: 0.4286 - 51ms/epoch - 51ms/step\n",
            "Epoch 34/200\n",
            "1/1 - 0s - loss: 0.8199 - accuracy: 0.3333 - val_loss: 0.7730 - val_accuracy: 0.4286 - 35ms/epoch - 35ms/step\n",
            "Epoch 35/200\n",
            "1/1 - 0s - loss: 0.7846 - accuracy: 0.3889 - val_loss: 0.7727 - val_accuracy: 0.4286 - 46ms/epoch - 46ms/step\n",
            "Epoch 36/200\n",
            "1/1 - 0s - loss: 0.7437 - accuracy: 0.5000 - val_loss: 0.7725 - val_accuracy: 0.4286 - 35ms/epoch - 35ms/step\n",
            "Epoch 37/200\n",
            "1/1 - 0s - loss: 0.7447 - accuracy: 0.6667 - val_loss: 0.7721 - val_accuracy: 0.4286 - 54ms/epoch - 54ms/step\n",
            "Epoch 38/200\n",
            "1/1 - 0s - loss: 0.7688 - accuracy: 0.4444 - val_loss: 0.7717 - val_accuracy: 0.4286 - 39ms/epoch - 39ms/step\n",
            "Epoch 39/200\n",
            "1/1 - 0s - loss: 0.7579 - accuracy: 0.5556 - val_loss: 0.7714 - val_accuracy: 0.2857 - 44ms/epoch - 44ms/step\n",
            "Epoch 40/200\n",
            "1/1 - 0s - loss: 0.8197 - accuracy: 0.3889 - val_loss: 0.7708 - val_accuracy: 0.2857 - 55ms/epoch - 55ms/step\n",
            "Epoch 41/200\n",
            "1/1 - 0s - loss: 0.7662 - accuracy: 0.6667 - val_loss: 0.7702 - val_accuracy: 0.2857 - 35ms/epoch - 35ms/step\n",
            "Epoch 42/200\n",
            "1/1 - 0s - loss: 0.7824 - accuracy: 0.5000 - val_loss: 0.7696 - val_accuracy: 0.4286 - 54ms/epoch - 54ms/step\n",
            "Epoch 43/200\n",
            "1/1 - 0s - loss: 0.7827 - accuracy: 0.5000 - val_loss: 0.7691 - val_accuracy: 0.4286 - 34ms/epoch - 34ms/step\n",
            "Epoch 44/200\n",
            "1/1 - 0s - loss: 0.7841 - accuracy: 0.4444 - val_loss: 0.7686 - val_accuracy: 0.4286 - 34ms/epoch - 34ms/step\n",
            "Epoch 45/200\n",
            "1/1 - 0s - loss: 0.8548 - accuracy: 0.2778 - val_loss: 0.7681 - val_accuracy: 0.4286 - 33ms/epoch - 33ms/step\n",
            "Epoch 46/200\n",
            "1/1 - 0s - loss: 0.8108 - accuracy: 0.3889 - val_loss: 0.7676 - val_accuracy: 0.4286 - 40ms/epoch - 40ms/step\n",
            "Epoch 47/200\n",
            "1/1 - 0s - loss: 0.7841 - accuracy: 0.5556 - val_loss: 0.7672 - val_accuracy: 0.4286 - 37ms/epoch - 37ms/step\n",
            "Epoch 48/200\n",
            "1/1 - 0s - loss: 0.7812 - accuracy: 0.4444 - val_loss: 0.7668 - val_accuracy: 0.4286 - 36ms/epoch - 36ms/step\n",
            "Epoch 49/200\n",
            "1/1 - 0s - loss: 0.7933 - accuracy: 0.5000 - val_loss: 0.7663 - val_accuracy: 0.4286 - 48ms/epoch - 48ms/step\n",
            "Epoch 50/200\n",
            "1/1 - 0s - loss: 0.8138 - accuracy: 0.4444 - val_loss: 0.7660 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 51/200\n",
            "1/1 - 0s - loss: 0.7429 - accuracy: 0.6667 - val_loss: 0.7656 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 52/200\n",
            "1/1 - 0s - loss: 0.8007 - accuracy: 0.4444 - val_loss: 0.7653 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 53/200\n",
            "1/1 - 0s - loss: 0.7731 - accuracy: 0.5556 - val_loss: 0.7650 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 54/200\n",
            "1/1 - 0s - loss: 0.7105 - accuracy: 0.6111 - val_loss: 0.7646 - val_accuracy: 0.5714 - 41ms/epoch - 41ms/step\n",
            "Epoch 55/200\n",
            "1/1 - 0s - loss: 0.8206 - accuracy: 0.4444 - val_loss: 0.7642 - val_accuracy: 0.5714 - 70ms/epoch - 70ms/step\n",
            "Epoch 56/200\n",
            "1/1 - 0s - loss: 0.8166 - accuracy: 0.4444 - val_loss: 0.7641 - val_accuracy: 0.5714 - 53ms/epoch - 53ms/step\n",
            "Epoch 57/200\n",
            "1/1 - 0s - loss: 0.7801 - accuracy: 0.2778 - val_loss: 0.7640 - val_accuracy: 0.5714 - 71ms/epoch - 71ms/step\n",
            "Epoch 58/200\n",
            "1/1 - 0s - loss: 0.7640 - accuracy: 0.3889 - val_loss: 0.7638 - val_accuracy: 0.5714 - 66ms/epoch - 66ms/step\n",
            "Epoch 59/200\n",
            "1/1 - 0s - loss: 0.7876 - accuracy: 0.5000 - val_loss: 0.7637 - val_accuracy: 0.5714 - 61ms/epoch - 61ms/step\n",
            "Epoch 60/200\n",
            "1/1 - 0s - loss: 0.7418 - accuracy: 0.5556 - val_loss: 0.7635 - val_accuracy: 0.5714 - 66ms/epoch - 66ms/step\n",
            "Epoch 61/200\n",
            "1/1 - 0s - loss: 0.7520 - accuracy: 0.7222 - val_loss: 0.7634 - val_accuracy: 0.5714 - 49ms/epoch - 49ms/step\n",
            "Epoch 62/200\n",
            "1/1 - 0s - loss: 0.7640 - accuracy: 0.5556 - val_loss: 0.7633 - val_accuracy: 0.5714 - 63ms/epoch - 63ms/step\n",
            "Epoch 63/200\n",
            "1/1 - 0s - loss: 0.8088 - accuracy: 0.3333 - val_loss: 0.7631 - val_accuracy: 0.5714 - 61ms/epoch - 61ms/step\n",
            "Epoch 64/200\n",
            "1/1 - 0s - loss: 0.7175 - accuracy: 0.5556 - val_loss: 0.7629 - val_accuracy: 0.5714 - 48ms/epoch - 48ms/step\n",
            "Epoch 65/200\n",
            "1/1 - 0s - loss: 0.7326 - accuracy: 0.6111 - val_loss: 0.7627 - val_accuracy: 0.5714 - 62ms/epoch - 62ms/step\n",
            "Epoch 66/200\n",
            "1/1 - 0s - loss: 0.7818 - accuracy: 0.4444 - val_loss: 0.7624 - val_accuracy: 0.5714 - 74ms/epoch - 74ms/step\n",
            "Epoch 67/200\n",
            "1/1 - 0s - loss: 0.7432 - accuracy: 0.6667 - val_loss: 0.7622 - val_accuracy: 0.5714 - 68ms/epoch - 68ms/step\n",
            "Epoch 68/200\n",
            "1/1 - 0s - loss: 0.7337 - accuracy: 0.5556 - val_loss: 0.7619 - val_accuracy: 0.5714 - 64ms/epoch - 64ms/step\n",
            "Epoch 69/200\n",
            "1/1 - 0s - loss: 0.8092 - accuracy: 0.3889 - val_loss: 0.7617 - val_accuracy: 0.5714 - 69ms/epoch - 69ms/step\n",
            "Epoch 70/200\n",
            "1/1 - 0s - loss: 0.7373 - accuracy: 0.5000 - val_loss: 0.7615 - val_accuracy: 0.5714 - 47ms/epoch - 47ms/step\n",
            "Epoch 71/200\n",
            "1/1 - 0s - loss: 0.7438 - accuracy: 0.6111 - val_loss: 0.7614 - val_accuracy: 0.5714 - 72ms/epoch - 72ms/step\n",
            "Epoch 72/200\n",
            "1/1 - 0s - loss: 0.7195 - accuracy: 0.7222 - val_loss: 0.7612 - val_accuracy: 0.5714 - 66ms/epoch - 66ms/step\n",
            "Epoch 73/200\n",
            "1/1 - 0s - loss: 0.8007 - accuracy: 0.3889 - val_loss: 0.7612 - val_accuracy: 0.5714 - 63ms/epoch - 63ms/step\n",
            "Epoch 74/200\n",
            "1/1 - 0s - loss: 0.7486 - accuracy: 0.6111 - val_loss: 0.7612 - val_accuracy: 0.5714 - 65ms/epoch - 65ms/step\n",
            "Epoch 75/200\n",
            "1/1 - 0s - loss: 0.7887 - accuracy: 0.3889 - val_loss: 0.7611 - val_accuracy: 0.5714 - 68ms/epoch - 68ms/step\n",
            "Epoch 76/200\n",
            "1/1 - 0s - loss: 0.7502 - accuracy: 0.6667 - val_loss: 0.7610 - val_accuracy: 0.5714 - 63ms/epoch - 63ms/step\n",
            "Epoch 77/200\n",
            "1/1 - 0s - loss: 0.7736 - accuracy: 0.4444 - val_loss: 0.7610 - val_accuracy: 0.5714 - 68ms/epoch - 68ms/step\n",
            "Epoch 78/200\n",
            "1/1 - 0s - loss: 0.7510 - accuracy: 0.6667 - val_loss: 0.7610 - val_accuracy: 0.5714 - 66ms/epoch - 66ms/step\n",
            "Epoch 79/200\n",
            "1/1 - 0s - loss: 0.8253 - accuracy: 0.5000 - val_loss: 0.7609 - val_accuracy: 0.5714 - 70ms/epoch - 70ms/step\n",
            "Epoch 80/200\n",
            "1/1 - 0s - loss: 0.7761 - accuracy: 0.5000 - val_loss: 0.7609 - val_accuracy: 0.5714 - 70ms/epoch - 70ms/step\n",
            "Epoch 81/200\n",
            "1/1 - 0s - loss: 0.7811 - accuracy: 0.3889 - val_loss: 0.7608 - val_accuracy: 0.5714 - 73ms/epoch - 73ms/step\n",
            "Epoch 82/200\n",
            "1/1 - 0s - loss: 0.7691 - accuracy: 0.5000 - val_loss: 0.7606 - val_accuracy: 0.5714 - 50ms/epoch - 50ms/step\n",
            "Epoch 83/200\n",
            "1/1 - 0s - loss: 0.7626 - accuracy: 0.5556 - val_loss: 0.7605 - val_accuracy: 0.5714 - 49ms/epoch - 49ms/step\n",
            "Epoch 84/200\n",
            "1/1 - 0s - loss: 0.7766 - accuracy: 0.5556 - val_loss: 0.7604 - val_accuracy: 0.5714 - 64ms/epoch - 64ms/step\n",
            "Epoch 85/200\n",
            "1/1 - 0s - loss: 0.8103 - accuracy: 0.4444 - val_loss: 0.7603 - val_accuracy: 0.5714 - 62ms/epoch - 62ms/step\n",
            "Epoch 86/200\n",
            "1/1 - 0s - loss: 0.7810 - accuracy: 0.4444 - val_loss: 0.7601 - val_accuracy: 0.5714 - 63ms/epoch - 63ms/step\n",
            "Epoch 87/200\n",
            "1/1 - 0s - loss: 0.7781 - accuracy: 0.4444 - val_loss: 0.7598 - val_accuracy: 0.5714 - 64ms/epoch - 64ms/step\n",
            "Epoch 88/200\n",
            "1/1 - 0s - loss: 0.7603 - accuracy: 0.5000 - val_loss: 0.7595 - val_accuracy: 0.5714 - 72ms/epoch - 72ms/step\n",
            "Epoch 89/200\n",
            "1/1 - 0s - loss: 0.7998 - accuracy: 0.3889 - val_loss: 0.7592 - val_accuracy: 0.5714 - 62ms/epoch - 62ms/step\n",
            "Epoch 90/200\n",
            "1/1 - 0s - loss: 0.7726 - accuracy: 0.5556 - val_loss: 0.7588 - val_accuracy: 0.5714 - 56ms/epoch - 56ms/step\n",
            "Epoch 91/200\n",
            "1/1 - 0s - loss: 0.8272 - accuracy: 0.2778 - val_loss: 0.7584 - val_accuracy: 0.5714 - 65ms/epoch - 65ms/step\n",
            "Epoch 92/200\n",
            "1/1 - 0s - loss: 0.7619 - accuracy: 0.5556 - val_loss: 0.7581 - val_accuracy: 0.5714 - 63ms/epoch - 63ms/step\n",
            "Epoch 93/200\n",
            "1/1 - 0s - loss: 0.7186 - accuracy: 0.6111 - val_loss: 0.7577 - val_accuracy: 0.5714 - 73ms/epoch - 73ms/step\n",
            "Epoch 94/200\n",
            "1/1 - 0s - loss: 0.7647 - accuracy: 0.4444 - val_loss: 0.7573 - val_accuracy: 0.5714 - 64ms/epoch - 64ms/step\n",
            "Epoch 95/200\n",
            "1/1 - 0s - loss: 0.8138 - accuracy: 0.3333 - val_loss: 0.7569 - val_accuracy: 0.5714 - 47ms/epoch - 47ms/step\n",
            "Epoch 96/200\n",
            "1/1 - 0s - loss: 0.7660 - accuracy: 0.6111 - val_loss: 0.7565 - val_accuracy: 0.5714 - 44ms/epoch - 44ms/step\n",
            "Epoch 97/200\n",
            "1/1 - 0s - loss: 0.7339 - accuracy: 0.6667 - val_loss: 0.7562 - val_accuracy: 0.5714 - 44ms/epoch - 44ms/step\n",
            "Epoch 98/200\n",
            "1/1 - 0s - loss: 0.7272 - accuracy: 0.4444 - val_loss: 0.7558 - val_accuracy: 0.5714 - 45ms/epoch - 45ms/step\n",
            "Epoch 99/200\n",
            "1/1 - 0s - loss: 0.8108 - accuracy: 0.3889 - val_loss: 0.7555 - val_accuracy: 0.5714 - 60ms/epoch - 60ms/step\n",
            "Epoch 100/200\n",
            "1/1 - 0s - loss: 0.7831 - accuracy: 0.3333 - val_loss: 0.7550 - val_accuracy: 0.5714 - 64ms/epoch - 64ms/step\n",
            "Epoch 101/200\n",
            "1/1 - 0s - loss: 0.7312 - accuracy: 0.5000 - val_loss: 0.7547 - val_accuracy: 0.5714 - 62ms/epoch - 62ms/step\n",
            "Epoch 102/200\n",
            "1/1 - 0s - loss: 0.7452 - accuracy: 0.6111 - val_loss: 0.7543 - val_accuracy: 0.5714 - 64ms/epoch - 64ms/step\n",
            "Epoch 103/200\n",
            "1/1 - 0s - loss: 0.7254 - accuracy: 0.5556 - val_loss: 0.7539 - val_accuracy: 0.5714 - 49ms/epoch - 49ms/step\n",
            "Epoch 104/200\n",
            "1/1 - 0s - loss: 0.7890 - accuracy: 0.4444 - val_loss: 0.7536 - val_accuracy: 0.5714 - 51ms/epoch - 51ms/step\n",
            "Epoch 105/200\n",
            "1/1 - 0s - loss: 0.7510 - accuracy: 0.5556 - val_loss: 0.7534 - val_accuracy: 0.5714 - 52ms/epoch - 52ms/step\n",
            "Epoch 106/200\n",
            "1/1 - 0s - loss: 0.8012 - accuracy: 0.3889 - val_loss: 0.7533 - val_accuracy: 0.5714 - 75ms/epoch - 75ms/step\n",
            "Epoch 107/200\n",
            "1/1 - 0s - loss: 0.7329 - accuracy: 0.7222 - val_loss: 0.7532 - val_accuracy: 0.5714 - 70ms/epoch - 70ms/step\n",
            "Epoch 108/200\n",
            "1/1 - 0s - loss: 0.7426 - accuracy: 0.7222 - val_loss: 0.7530 - val_accuracy: 0.5714 - 63ms/epoch - 63ms/step\n",
            "Epoch 109/200\n",
            "1/1 - 0s - loss: 0.7279 - accuracy: 0.5000 - val_loss: 0.7528 - val_accuracy: 0.5714 - 63ms/epoch - 63ms/step\n",
            "Epoch 110/200\n",
            "1/1 - 0s - loss: 0.7327 - accuracy: 0.6667 - val_loss: 0.7526 - val_accuracy: 0.5714 - 50ms/epoch - 50ms/step\n",
            "Epoch 111/200\n",
            "1/1 - 0s - loss: 0.7525 - accuracy: 0.6111 - val_loss: 0.7524 - val_accuracy: 0.5714 - 60ms/epoch - 60ms/step\n",
            "Epoch 112/200\n",
            "1/1 - 0s - loss: 0.7867 - accuracy: 0.5000 - val_loss: 0.7522 - val_accuracy: 0.5714 - 66ms/epoch - 66ms/step\n",
            "Epoch 113/200\n",
            "1/1 - 0s - loss: 0.7758 - accuracy: 0.6111 - val_loss: 0.7522 - val_accuracy: 0.5714 - 69ms/epoch - 69ms/step\n",
            "Epoch 114/200\n",
            "1/1 - 0s - loss: 0.7451 - accuracy: 0.6111 - val_loss: 0.7522 - val_accuracy: 0.5714 - 46ms/epoch - 46ms/step\n",
            "Epoch 115/200\n",
            "1/1 - 0s - loss: 0.7553 - accuracy: 0.6111 - val_loss: 0.7522 - val_accuracy: 0.5714 - 36ms/epoch - 36ms/step\n",
            "Epoch 116/200\n",
            "1/1 - 0s - loss: 0.7713 - accuracy: 0.4444 - val_loss: 0.7522 - val_accuracy: 0.5714 - 38ms/epoch - 38ms/step\n",
            "Epoch 117/200\n",
            "1/1 - 0s - loss: 0.7425 - accuracy: 0.6667 - val_loss: 0.7521 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 118/200\n",
            "1/1 - 0s - loss: 0.7825 - accuracy: 0.4444 - val_loss: 0.7520 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 119/200\n",
            "1/1 - 0s - loss: 0.7456 - accuracy: 0.6667 - val_loss: 0.7520 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 120/200\n",
            "1/1 - 0s - loss: 0.7549 - accuracy: 0.5000 - val_loss: 0.7519 - val_accuracy: 0.5714 - 36ms/epoch - 36ms/step\n",
            "Epoch 121/200\n",
            "1/1 - 0s - loss: 0.7278 - accuracy: 0.5000 - val_loss: 0.7518 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 122/200\n",
            "1/1 - 0s - loss: 0.7682 - accuracy: 0.4444 - val_loss: 0.7519 - val_accuracy: 0.5714 - 31ms/epoch - 31ms/step\n",
            "Epoch 123/200\n",
            "1/1 - 0s - loss: 0.7538 - accuracy: 0.4444 - val_loss: 0.7520 - val_accuracy: 0.5714 - 38ms/epoch - 38ms/step\n",
            "Epoch 124/200\n",
            "1/1 - 0s - loss: 0.7519 - accuracy: 0.2778 - val_loss: 0.7522 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 125/200\n",
            "1/1 - 0s - loss: 0.7802 - accuracy: 0.2778 - val_loss: 0.7523 - val_accuracy: 0.5714 - 36ms/epoch - 36ms/step\n",
            "Epoch 126/200\n",
            "1/1 - 0s - loss: 0.7710 - accuracy: 0.4444 - val_loss: 0.7523 - val_accuracy: 0.5714 - 59ms/epoch - 59ms/step\n",
            "Epoch 127/200\n",
            "1/1 - 0s - loss: 0.7329 - accuracy: 0.5000 - val_loss: 0.7523 - val_accuracy: 0.5714 - 36ms/epoch - 36ms/step\n",
            "Epoch 128/200\n",
            "1/1 - 0s - loss: 0.7131 - accuracy: 0.6667 - val_loss: 0.7521 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 129/200\n",
            "1/1 - 0s - loss: 0.8158 - accuracy: 0.3889 - val_loss: 0.7520 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 130/200\n",
            "1/1 - 0s - loss: 0.7505 - accuracy: 0.7778 - val_loss: 0.7518 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 131/200\n",
            "1/1 - 0s - loss: 0.7720 - accuracy: 0.4444 - val_loss: 0.7516 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 132/200\n",
            "1/1 - 0s - loss: 0.7392 - accuracy: 0.5556 - val_loss: 0.7515 - val_accuracy: 0.5714 - 38ms/epoch - 38ms/step\n",
            "Epoch 133/200\n",
            "1/1 - 0s - loss: 0.7655 - accuracy: 0.4444 - val_loss: 0.7515 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 134/200\n",
            "1/1 - 0s - loss: 0.7852 - accuracy: 0.4444 - val_loss: 0.7513 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 135/200\n",
            "1/1 - 0s - loss: 0.7525 - accuracy: 0.5556 - val_loss: 0.7511 - val_accuracy: 0.5714 - 38ms/epoch - 38ms/step\n",
            "Epoch 136/200\n",
            "1/1 - 0s - loss: 0.7543 - accuracy: 0.5000 - val_loss: 0.7509 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 137/200\n",
            "1/1 - 0s - loss: 0.7527 - accuracy: 0.5000 - val_loss: 0.7508 - val_accuracy: 0.5714 - 36ms/epoch - 36ms/step\n",
            "Epoch 138/200\n",
            "1/1 - 0s - loss: 0.7258 - accuracy: 0.5556 - val_loss: 0.7507 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 139/200\n",
            "1/1 - 0s - loss: 0.7773 - accuracy: 0.5000 - val_loss: 0.7506 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 140/200\n",
            "1/1 - 0s - loss: 0.7702 - accuracy: 0.3889 - val_loss: 0.7505 - val_accuracy: 0.5714 - 43ms/epoch - 43ms/step\n",
            "Epoch 141/200\n",
            "1/1 - 0s - loss: 0.7668 - accuracy: 0.5556 - val_loss: 0.7504 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 142/200\n",
            "1/1 - 0s - loss: 0.7499 - accuracy: 0.5000 - val_loss: 0.7502 - val_accuracy: 0.5714 - 49ms/epoch - 49ms/step\n",
            "Epoch 143/200\n",
            "1/1 - 0s - loss: 0.7739 - accuracy: 0.5000 - val_loss: 0.7499 - val_accuracy: 0.5714 - 54ms/epoch - 54ms/step\n",
            "Epoch 144/200\n",
            "1/1 - 0s - loss: 0.7392 - accuracy: 0.5556 - val_loss: 0.7495 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 145/200\n",
            "1/1 - 0s - loss: 0.8020 - accuracy: 0.3889 - val_loss: 0.7492 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 146/200\n",
            "1/1 - 0s - loss: 0.7567 - accuracy: 0.4444 - val_loss: 0.7489 - val_accuracy: 0.5714 - 50ms/epoch - 50ms/step\n",
            "Epoch 147/200\n",
            "1/1 - 0s - loss: 0.7120 - accuracy: 0.6111 - val_loss: 0.7485 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 148/200\n",
            "1/1 - 0s - loss: 0.7454 - accuracy: 0.5556 - val_loss: 0.7480 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 149/200\n",
            "1/1 - 0s - loss: 0.7478 - accuracy: 0.4444 - val_loss: 0.7476 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 150/200\n",
            "1/1 - 0s - loss: 0.7656 - accuracy: 0.5000 - val_loss: 0.7472 - val_accuracy: 0.5714 - 50ms/epoch - 50ms/step\n",
            "Epoch 151/200\n",
            "1/1 - 0s - loss: 0.7696 - accuracy: 0.6111 - val_loss: 0.7469 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 152/200\n",
            "1/1 - 0s - loss: 0.6975 - accuracy: 0.5556 - val_loss: 0.7465 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 153/200\n",
            "1/1 - 0s - loss: 0.7061 - accuracy: 0.5556 - val_loss: 0.7460 - val_accuracy: 0.5714 - 52ms/epoch - 52ms/step\n",
            "Epoch 154/200\n",
            "1/1 - 0s - loss: 0.7188 - accuracy: 0.6667 - val_loss: 0.7456 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 155/200\n",
            "1/1 - 0s - loss: 0.7425 - accuracy: 0.5556 - val_loss: 0.7452 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 156/200\n",
            "1/1 - 0s - loss: 0.7389 - accuracy: 0.5000 - val_loss: 0.7447 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 157/200\n",
            "1/1 - 0s - loss: 0.7379 - accuracy: 0.5556 - val_loss: 0.7441 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 158/200\n",
            "1/1 - 0s - loss: 0.7739 - accuracy: 0.3889 - val_loss: 0.7435 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 159/200\n",
            "1/1 - 0s - loss: 0.7385 - accuracy: 0.5000 - val_loss: 0.7430 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 160/200\n",
            "1/1 - 0s - loss: 0.7553 - accuracy: 0.6111 - val_loss: 0.7427 - val_accuracy: 0.5714 - 52ms/epoch - 52ms/step\n",
            "Epoch 161/200\n",
            "1/1 - 0s - loss: 0.7410 - accuracy: 0.5000 - val_loss: 0.7424 - val_accuracy: 0.5714 - 37ms/epoch - 37ms/step\n",
            "Epoch 162/200\n",
            "1/1 - 0s - loss: 0.7703 - accuracy: 0.4444 - val_loss: 0.7421 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 163/200\n",
            "1/1 - 0s - loss: 0.7273 - accuracy: 0.5556 - val_loss: 0.7418 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 164/200\n",
            "1/1 - 0s - loss: 0.7132 - accuracy: 0.6111 - val_loss: 0.7416 - val_accuracy: 0.5714 - 37ms/epoch - 37ms/step\n",
            "Epoch 165/200\n",
            "1/1 - 0s - loss: 0.7408 - accuracy: 0.6111 - val_loss: 0.7413 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 166/200\n",
            "1/1 - 0s - loss: 0.7410 - accuracy: 0.4444 - val_loss: 0.7410 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 167/200\n",
            "1/1 - 0s - loss: 0.7788 - accuracy: 0.4444 - val_loss: 0.7408 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 168/200\n",
            "1/1 - 0s - loss: 0.7590 - accuracy: 0.6111 - val_loss: 0.7406 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 169/200\n",
            "1/1 - 0s - loss: 0.7427 - accuracy: 0.5556 - val_loss: 0.7404 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 170/200\n",
            "1/1 - 0s - loss: 0.7261 - accuracy: 0.5000 - val_loss: 0.7400 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 171/200\n",
            "1/1 - 0s - loss: 0.7100 - accuracy: 0.5556 - val_loss: 0.7395 - val_accuracy: 0.5714 - 54ms/epoch - 54ms/step\n",
            "Epoch 172/200\n",
            "1/1 - 0s - loss: 0.7339 - accuracy: 0.6111 - val_loss: 0.7390 - val_accuracy: 0.5714 - 37ms/epoch - 37ms/step\n",
            "Epoch 173/200\n",
            "1/1 - 0s - loss: 0.7620 - accuracy: 0.5000 - val_loss: 0.7386 - val_accuracy: 0.5714 - 53ms/epoch - 53ms/step\n",
            "Epoch 174/200\n",
            "1/1 - 0s - loss: 0.7551 - accuracy: 0.6111 - val_loss: 0.7382 - val_accuracy: 0.5714 - 43ms/epoch - 43ms/step\n",
            "Epoch 175/200\n",
            "1/1 - 0s - loss: 0.7180 - accuracy: 0.7222 - val_loss: 0.7379 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 176/200\n",
            "1/1 - 0s - loss: 0.7214 - accuracy: 0.6667 - val_loss: 0.7375 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 177/200\n",
            "1/1 - 0s - loss: 0.8110 - accuracy: 0.3333 - val_loss: 0.7371 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 178/200\n",
            "1/1 - 0s - loss: 0.7562 - accuracy: 0.4444 - val_loss: 0.7366 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 179/200\n",
            "1/1 - 0s - loss: 0.7318 - accuracy: 0.5556 - val_loss: 0.7361 - val_accuracy: 0.5714 - 36ms/epoch - 36ms/step\n",
            "Epoch 180/200\n",
            "1/1 - 0s - loss: 0.7821 - accuracy: 0.4444 - val_loss: 0.7355 - val_accuracy: 0.5714 - 53ms/epoch - 53ms/step\n",
            "Epoch 181/200\n",
            "1/1 - 0s - loss: 0.7298 - accuracy: 0.5000 - val_loss: 0.7351 - val_accuracy: 0.5714 - 36ms/epoch - 36ms/step\n",
            "Epoch 182/200\n",
            "1/1 - 0s - loss: 0.7241 - accuracy: 0.5000 - val_loss: 0.7346 - val_accuracy: 0.5714 - 41ms/epoch - 41ms/step\n",
            "Epoch 183/200\n",
            "1/1 - 0s - loss: 0.7413 - accuracy: 0.5000 - val_loss: 0.7342 - val_accuracy: 0.5714 - 51ms/epoch - 51ms/step\n",
            "Epoch 184/200\n",
            "1/1 - 0s - loss: 0.7238 - accuracy: 0.5000 - val_loss: 0.7337 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 185/200\n",
            "1/1 - 0s - loss: 0.7673 - accuracy: 0.6111 - val_loss: 0.7334 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 186/200\n",
            "1/1 - 0s - loss: 0.7547 - accuracy: 0.6667 - val_loss: 0.7332 - val_accuracy: 0.5714 - 37ms/epoch - 37ms/step\n",
            "Epoch 187/200\n",
            "1/1 - 0s - loss: 0.6999 - accuracy: 0.6667 - val_loss: 0.7331 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 188/200\n",
            "1/1 - 0s - loss: 0.6995 - accuracy: 0.5556 - val_loss: 0.7328 - val_accuracy: 0.5714 - 32ms/epoch - 32ms/step\n",
            "Epoch 189/200\n",
            "1/1 - 0s - loss: 0.7206 - accuracy: 0.6667 - val_loss: 0.7325 - val_accuracy: 0.5714 - 34ms/epoch - 34ms/step\n",
            "Epoch 190/200\n",
            "1/1 - 0s - loss: 0.7384 - accuracy: 0.5000 - val_loss: 0.7322 - val_accuracy: 0.5714 - 36ms/epoch - 36ms/step\n",
            "Epoch 191/200\n",
            "1/1 - 0s - loss: 0.7692 - accuracy: 0.4444 - val_loss: 0.7319 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 192/200\n",
            "1/1 - 0s - loss: 0.7174 - accuracy: 0.6111 - val_loss: 0.7317 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 193/200\n",
            "1/1 - 0s - loss: 0.7646 - accuracy: 0.6111 - val_loss: 0.7313 - val_accuracy: 0.5714 - 56ms/epoch - 56ms/step\n",
            "Epoch 194/200\n",
            "1/1 - 0s - loss: 0.6993 - accuracy: 0.6111 - val_loss: 0.7308 - val_accuracy: 0.5714 - 39ms/epoch - 39ms/step\n",
            "Epoch 195/200\n",
            "1/1 - 0s - loss: 0.7236 - accuracy: 0.5000 - val_loss: 0.7304 - val_accuracy: 0.5714 - 36ms/epoch - 36ms/step\n",
            "Epoch 196/200\n",
            "1/1 - 0s - loss: 0.7373 - accuracy: 0.5000 - val_loss: 0.7300 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n",
            "Epoch 197/200\n",
            "1/1 - 0s - loss: 0.6837 - accuracy: 0.7778 - val_loss: 0.7296 - val_accuracy: 0.5714 - 35ms/epoch - 35ms/step\n",
            "Epoch 198/200\n",
            "1/1 - 0s - loss: 0.7340 - accuracy: 0.4444 - val_loss: 0.7293 - val_accuracy: 0.5714 - 36ms/epoch - 36ms/step\n",
            "Epoch 199/200\n",
            "1/1 - 0s - loss: 0.7462 - accuracy: 0.5000 - val_loss: 0.7291 - val_accuracy: 0.5714 - 37ms/epoch - 37ms/step\n",
            "Epoch 200/200\n",
            "1/1 - 0s - loss: 0.7613 - accuracy: 0.6111 - val_loss: 0.7288 - val_accuracy: 0.5714 - 33ms/epoch - 33ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metric(history, 'accuracy')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "yuBLFN9LV7Z5",
        "outputId": "b63fb04a-1211-43ab-f02e-faa1b4f3434b"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"408.10125pt\" height=\"325.986375pt\" viewBox=\"0 0 408.10125 325.986375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-11-23T18:14:51.818674</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 325.986375 \nL 408.10125 325.986375 \nL 408.10125 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 43.78125 288.430125 \nL 400.90125 288.430125 \nL 400.90125 22.318125 \nL 43.78125 22.318125 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m309321b7d9\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m309321b7d9\" x=\"58.382547\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(55.201297 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m309321b7d9\" x=\"99.168294\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <g transform=\"translate(92.805794 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m309321b7d9\" x=\"139.954041\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(133.591541 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m309321b7d9\" x=\"180.739788\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <g transform=\"translate(174.377288 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m309321b7d9\" x=\"221.525535\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(211.981785 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m309321b7d9\" x=\"262.311282\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(252.767532 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m309321b7d9\" x=\"303.097029\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(293.553279 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m309321b7d9\" x=\"343.882776\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(334.339026 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m309321b7d9\" x=\"384.668523\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(375.124773 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- Epochs -->\n     <g transform=\"translate(204.425625 316.706687) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"md1ee4dff2b\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#md1ee4dff2b\" x=\"43.78125\" y=\"265.582131\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.3 -->\n      <g transform=\"translate(20.878125 269.38135) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-33\" d=\"M 2597 2516 \nQ 3050 2419 3304 2112 \nQ 3559 1806 3559 1356 \nQ 3559 666 3084 287 \nQ 2609 -91 1734 -91 \nQ 1441 -91 1130 -33 \nQ 819 25 488 141 \nL 488 750 \nQ 750 597 1062 519 \nQ 1375 441 1716 441 \nQ 2309 441 2620 675 \nQ 2931 909 2931 1356 \nQ 2931 1769 2642 2001 \nQ 2353 2234 1838 2234 \nL 1294 2234 \nL 1294 2753 \nL 1863 2753 \nQ 2328 2753 2575 2939 \nQ 2822 3125 2822 3475 \nQ 2822 3834 2567 4026 \nQ 2313 4219 1838 4219 \nQ 1578 4219 1281 4162 \nQ 984 4106 628 3988 \nL 628 4550 \nQ 988 4650 1302 4700 \nQ 1616 4750 1894 4750 \nQ 2613 4750 3031 4423 \nQ 3450 4097 3450 3541 \nQ 3450 3153 3228 2886 \nQ 3006 2619 2597 2516 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-33\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#md1ee4dff2b\" x=\"43.78125\" y=\"217.198131\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.4 -->\n      <g transform=\"translate(20.878125 220.99735) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-34\" d=\"M 2419 4116 \nL 825 1625 \nL 2419 1625 \nL 2419 4116 \nz\nM 2253 4666 \nL 3047 4666 \nL 3047 1625 \nL 3713 1625 \nL 3713 1100 \nL 3047 1100 \nL 3047 0 \nL 2419 0 \nL 2419 1100 \nL 313 1100 \nL 313 1709 \nL 2253 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-34\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#md1ee4dff2b\" x=\"43.78125\" y=\"168.814131\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.5 -->\n      <g transform=\"translate(20.878125 172.61335) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#md1ee4dff2b\" x=\"43.78125\" y=\"120.430131\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.6 -->\n      <g transform=\"translate(20.878125 124.22935) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-36\" d=\"M 2113 2584 \nQ 1688 2584 1439 2293 \nQ 1191 2003 1191 1497 \nQ 1191 994 1439 701 \nQ 1688 409 2113 409 \nQ 2538 409 2786 701 \nQ 3034 994 3034 1497 \nQ 3034 2003 2786 2293 \nQ 2538 2584 2113 2584 \nz\nM 3366 4563 \nL 3366 3988 \nQ 3128 4100 2886 4159 \nQ 2644 4219 2406 4219 \nQ 1781 4219 1451 3797 \nQ 1122 3375 1075 2522 \nQ 1259 2794 1537 2939 \nQ 1816 3084 2150 3084 \nQ 2853 3084 3261 2657 \nQ 3669 2231 3669 1497 \nQ 3669 778 3244 343 \nQ 2819 -91 2113 -91 \nQ 1303 -91 875 529 \nQ 447 1150 447 2328 \nQ 447 3434 972 4092 \nQ 1497 4750 2381 4750 \nQ 2619 4750 2861 4703 \nQ 3103 4656 3366 4563 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-36\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#md1ee4dff2b\" x=\"43.78125\" y=\"72.046131\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.7 -->\n      <g transform=\"translate(20.878125 75.84535) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_15\">\n      <g>\n       <use xlink:href=\"#md1ee4dff2b\" x=\"43.78125\" y=\"23.662131\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_16\">\n      <!-- 0.8 -->\n      <g transform=\"translate(20.878125 27.46135) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_17\">\n     <!-- accuracy -->\n     <g transform=\"translate(14.798438 177.9335) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-75\" d=\"M 544 1381 \nL 544 3500 \nL 1119 3500 \nL 1119 1403 \nQ 1119 906 1312 657 \nQ 1506 409 1894 409 \nQ 2359 409 2629 706 \nQ 2900 1003 2900 1516 \nL 2900 3500 \nL 3475 3500 \nL 3475 0 \nL 2900 0 \nL 2900 538 \nQ 2691 219 2414 64 \nQ 2138 -91 1772 -91 \nQ 1169 -91 856 284 \nQ 544 659 544 1381 \nz\nM 1991 3584 \nL 1991 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-79\" d=\"M 2059 -325 \nQ 1816 -950 1584 -1140 \nQ 1353 -1331 966 -1331 \nL 506 -1331 \nL 506 -850 \nL 844 -850 \nQ 1081 -850 1212 -737 \nQ 1344 -625 1503 -206 \nL 1606 56 \nL 191 3500 \nL 800 3500 \nL 1894 763 \nL 2988 3500 \nL 3597 3500 \nL 2059 -325 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-61\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"61.279297\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"116.259766\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"171.240234\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"234.619141\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"275.732422\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"337.011719\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"391.992188\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 60.013977 115.054135 \nL 61.645407 222.574128 \nL 63.276837 141.934119 \nL 64.908267 168.814131 \nL 66.539697 88.174122 \nL 68.171127 195.69413 \nL 69.802557 249.454127 \nL 71.433986 61.294138 \nL 73.065416 222.574128 \nL 74.696846 195.69413 \nL 76.328276 141.934119 \nL 77.959706 222.574128 \nL 79.591136 222.574128 \nL 81.222566 249.454127 \nL 82.853996 222.574128 \nL 84.485425 141.934119 \nL 87.748285 249.454127 \nL 89.379715 115.054135 \nL 91.011145 168.814131 \nL 92.642575 249.454127 \nL 94.274005 195.69413 \nL 95.905435 168.814131 \nL 97.536864 168.814131 \nL 99.168294 141.934119 \nL 100.799724 141.934119 \nL 102.431154 168.814131 \nL 104.062584 249.454127 \nL 105.694014 168.814131 \nL 107.325444 115.054135 \nL 108.956874 168.814131 \nL 110.588303 88.174122 \nL 112.219733 141.934119 \nL 113.851163 249.454127 \nL 115.482593 222.574128 \nL 117.114023 168.814131 \nL 118.745453 88.174122 \nL 120.376883 195.69413 \nL 122.008313 141.934119 \nL 123.639742 222.574128 \nL 125.271172 88.174122 \nL 126.902602 168.814131 \nL 128.534032 168.814131 \nL 130.165462 195.69413 \nL 131.796892 276.334125 \nL 133.428322 222.574128 \nL 135.059752 141.934119 \nL 136.691181 195.69413 \nL 138.322611 168.814131 \nL 139.954041 195.69413 \nL 141.585471 88.174122 \nL 143.216901 195.69413 \nL 144.848331 141.934119 \nL 146.479761 115.054135 \nL 148.111191 195.69413 \nL 149.74262 195.69413 \nL 151.37405 276.334125 \nL 154.63691 168.814131 \nL 156.26834 141.934119 \nL 157.89977 61.294138 \nL 159.5312 141.934119 \nL 161.16263 249.454127 \nL 162.79406 141.934119 \nL 164.425489 115.054135 \nL 166.056919 195.69413 \nL 167.688349 88.174122 \nL 169.319779 141.934119 \nL 170.951209 222.574128 \nL 175.845499 61.294138 \nL 177.476928 222.574128 \nL 179.108358 115.054135 \nL 180.739788 222.574128 \nL 182.371218 88.174122 \nL 184.002648 195.69413 \nL 185.634078 88.174122 \nL 187.265508 168.814131 \nL 188.896938 168.814131 \nL 190.528367 222.574128 \nL 192.159797 168.814131 \nL 193.791227 141.934119 \nL 195.422657 141.934119 \nL 197.054087 195.69413 \nL 200.316947 195.69413 \nL 201.948377 168.814131 \nL 203.579806 222.574128 \nL 205.211236 141.934119 \nL 206.842666 276.334125 \nL 208.474096 141.934119 \nL 210.105526 115.054135 \nL 211.736956 195.69413 \nL 213.368386 249.454127 \nL 214.999816 115.054135 \nL 216.631245 88.174122 \nL 218.262675 195.69413 \nL 221.525535 249.454127 \nL 223.156965 168.814131 \nL 224.788395 115.054135 \nL 226.419825 141.934119 \nL 228.051255 195.69413 \nL 229.682684 141.934119 \nL 231.314114 222.574128 \nL 232.945544 61.294138 \nL 234.576974 61.294138 \nL 236.208404 168.814131 \nL 237.839834 88.174122 \nL 239.471264 115.054135 \nL 241.102694 168.814131 \nL 242.734123 115.054135 \nL 245.996983 115.054135 \nL 247.628413 195.69413 \nL 249.259843 88.174122 \nL 250.891273 195.69413 \nL 252.522703 88.174122 \nL 254.154133 168.814131 \nL 255.785562 168.814131 \nL 257.416992 195.69413 \nL 259.048422 195.69413 \nL 260.679852 276.334125 \nL 262.311282 276.334125 \nL 263.942712 195.69413 \nL 265.574142 168.814131 \nL 267.205572 88.174122 \nL 268.837001 222.574128 \nL 270.468431 34.414125 \nL 272.099861 195.69413 \nL 273.731291 141.934119 \nL 275.362721 195.69413 \nL 276.994151 195.69413 \nL 278.625581 141.934119 \nL 280.257011 168.814131 \nL 281.88844 168.814131 \nL 283.51987 141.934119 \nL 285.1513 168.814131 \nL 286.78273 222.574128 \nL 288.41416 141.934119 \nL 290.04559 168.814131 \nL 291.67702 168.814131 \nL 293.30845 141.934119 \nL 294.93988 222.574128 \nL 296.571309 195.69413 \nL 298.202739 115.054135 \nL 299.834169 141.934119 \nL 301.465599 195.69413 \nL 303.097029 168.814131 \nL 304.728459 115.054135 \nL 306.359889 141.934119 \nL 307.991319 141.934119 \nL 309.622748 88.174122 \nL 311.254178 141.934119 \nL 312.885608 168.814131 \nL 314.517038 141.934119 \nL 316.148468 222.574128 \nL 319.411328 115.054135 \nL 321.042758 168.814131 \nL 322.674187 195.69413 \nL 324.305617 141.934119 \nL 325.937047 115.054135 \nL 327.568477 115.054135 \nL 329.199907 195.69413 \nL 330.831337 195.69413 \nL 332.462767 115.054135 \nL 335.725626 168.814131 \nL 338.988486 115.054135 \nL 340.619916 168.814131 \nL 343.882776 61.294138 \nL 345.514206 88.174122 \nL 347.145636 249.454127 \nL 350.408495 141.934119 \nL 352.039925 195.69413 \nL 353.671355 168.814131 \nL 358.565645 168.814131 \nL 360.197075 115.054135 \nL 361.828504 88.174122 \nL 363.459934 88.174122 \nL 365.091364 141.934119 \nL 366.722794 88.174122 \nL 368.354224 168.814131 \nL 369.985654 195.69413 \nL 371.617084 115.054135 \nL 374.879943 115.054135 \nL 376.511373 168.814131 \nL 378.142803 168.814131 \nL 379.774233 34.414125 \nL 381.405663 195.69413 \nL 383.037093 168.814131 \nL 384.668523 115.054135 \nL 384.668523 115.054135 \n\" clip-path=\"url(#pf33bc05d70)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_17\">\n    <path d=\"M 60.013977 203.374129 \nL 120.376883 203.374129 \nL 122.008313 272.494125 \nL 125.271172 272.494125 \nL 126.902602 203.374129 \nL 138.322611 203.374129 \nL 139.954041 134.254119 \nL 384.668523 134.254119 \nL 384.668523 134.254119 \n\" clip-path=\"url(#pf33bc05d70)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 43.78125 288.430125 \nL 43.78125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 400.90125 288.430125 \nL 400.90125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 43.78125 288.430125 \nL 400.90125 288.430125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 43.78125 22.318125 \nL 400.90125 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_18\">\n    <!-- Training and validation accuracy -->\n    <g transform=\"translate(125.049375 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"487.59375\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"550.972656\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"614.449219\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"646.236328\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"705.416016\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"766.695312\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"794.478516\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"822.261719\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"885.738281\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"947.017578\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"986.226562\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1014.009766\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1075.191406\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1138.570312\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1170.357422\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1231.636719\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1286.617188\"/>\n     <use xlink:href=\"#DejaVuSans-75\" x=\"1341.597656\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"1404.976562\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"1446.089844\"/>\n     <use xlink:href=\"#DejaVuSans-63\" x=\"1507.369141\"/>\n     <use xlink:href=\"#DejaVuSans-79\" x=\"1562.349609\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 50.78125 60.230625 \nL 156.175 60.230625 \nQ 158.175 60.230625 158.175 58.230625 \nL 158.175 29.318125 \nQ 158.175 27.318125 156.175 27.318125 \nL 50.78125 27.318125 \nQ 48.78125 27.318125 48.78125 29.318125 \nL 48.78125 58.230625 \nQ 48.78125 60.230625 50.78125 60.230625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 52.78125 35.416562 \nL 62.78125 35.416562 \nL 72.78125 35.416562 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_19\">\n     <!-- train_accuracy -->\n     <g transform=\"translate(80.78125 38.916562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"344.042969\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"399.023438\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"454.003906\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"517.382812\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"558.496094\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"619.775391\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"674.755859\"/>\n     </g>\n    </g>\n    <g id=\"line2d_19\">\n     <path d=\"M 52.78125 50.372813 \nL 62.78125 50.372813 \nL 72.78125 50.372813 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_20\">\n     <!-- val_accuracy -->\n     <g transform=\"translate(80.78125 53.872813) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"259.521484\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"314.501953\"/>\n      <use xlink:href=\"#DejaVuSans-75\" x=\"369.482422\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"432.861328\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"473.974609\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"535.253906\"/>\n      <use xlink:href=\"#DejaVuSans-79\" x=\"590.234375\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pf33bc05d70\">\n   <rect x=\"43.78125\" y=\"22.318125\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metric(history, 'loss')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "IxAio9gyVRHe",
        "outputId": "964b9ffb-f383-40cf-a4df-dc61c15137d1"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<svg xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"414.46375pt\" height=\"325.986375pt\" viewBox=\"0 0 414.46375 325.986375\" xmlns=\"http://www.w3.org/2000/svg\" version=\"1.1\">\n <metadata>\n  <rdf:RDF xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2023-11-23T18:14:56.647922</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.7.1, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linejoin: round; stroke-linecap: butt}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 325.986375 \nL 414.46375 325.986375 \nL 414.46375 0 \nL 0 0 \nz\n\" style=\"fill: #ffffff\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 50.14375 288.430125 \nL 407.26375 288.430125 \nL 407.26375 22.318125 \nL 50.14375 22.318125 \nz\n\" style=\"fill: #ffffff\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path id=\"m95b1b4a59b\" d=\"M 0 0 \nL 0 3.5 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m95b1b4a59b\" x=\"64.745047\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(61.563797 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-30\" d=\"M 2034 4250 \nQ 1547 4250 1301 3770 \nQ 1056 3291 1056 2328 \nQ 1056 1369 1301 889 \nQ 1547 409 2034 409 \nQ 2525 409 2770 889 \nQ 3016 1369 3016 2328 \nQ 3016 3291 2770 3770 \nQ 2525 4250 2034 4250 \nz\nM 2034 4750 \nQ 2819 4750 3233 4129 \nQ 3647 3509 3647 2328 \nQ 3647 1150 3233 529 \nQ 2819 -91 2034 -91 \nQ 1250 -91 836 529 \nQ 422 1150 422 2328 \nQ 422 3509 836 4129 \nQ 1250 4750 2034 4750 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use xlink:href=\"#m95b1b4a59b\" x=\"105.530794\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 25 -->\n      <g transform=\"translate(99.168294 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-32\" d=\"M 1228 531 \nL 3431 531 \nL 3431 0 \nL 469 0 \nL 469 531 \nQ 828 903 1448 1529 \nQ 2069 2156 2228 2338 \nQ 2531 2678 2651 2914 \nQ 2772 3150 2772 3378 \nQ 2772 3750 2511 3984 \nQ 2250 4219 1831 4219 \nQ 1534 4219 1204 4116 \nQ 875 4013 500 3803 \nL 500 4441 \nQ 881 4594 1212 4672 \nQ 1544 4750 1819 4750 \nQ 2544 4750 2975 4387 \nQ 3406 4025 3406 3419 \nQ 3406 3131 3298 2873 \nQ 3191 2616 2906 2266 \nQ 2828 2175 2409 1742 \nQ 1991 1309 1228 531 \nz\n\" transform=\"scale(0.015625)\"/>\n        <path id=\"DejaVuSans-35\" d=\"M 691 4666 \nL 3169 4666 \nL 3169 4134 \nL 1269 4134 \nL 1269 2991 \nQ 1406 3038 1543 3061 \nQ 1681 3084 1819 3084 \nQ 2600 3084 3056 2656 \nQ 3513 2228 3513 1497 \nQ 3513 744 3044 326 \nQ 2575 -91 1722 -91 \nQ 1428 -91 1123 -41 \nQ 819 9 494 109 \nL 494 744 \nQ 775 591 1075 516 \nQ 1375 441 1709 441 \nQ 2250 441 2565 725 \nQ 2881 1009 2881 1497 \nQ 2881 1984 2565 2268 \nQ 2250 2553 1709 2553 \nQ 1456 2553 1204 2497 \nQ 953 2441 691 2322 \nL 691 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use xlink:href=\"#m95b1b4a59b\" x=\"146.316541\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 50 -->\n      <g transform=\"translate(139.954041 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-35\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use xlink:href=\"#m95b1b4a59b\" x=\"187.102288\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 75 -->\n      <g transform=\"translate(180.739788 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-37\" d=\"M 525 4666 \nL 3525 4666 \nL 3525 4397 \nL 1831 0 \nL 1172 0 \nL 2766 4134 \nL 525 4134 \nL 525 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-37\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use xlink:href=\"#m95b1b4a59b\" x=\"227.888035\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 100 -->\n      <g transform=\"translate(218.344285 303.028562) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-31\" d=\"M 794 531 \nL 1825 531 \nL 1825 4091 \nL 703 3866 \nL 703 4441 \nL 1819 4666 \nL 2450 4666 \nL 2450 531 \nL 3481 531 \nL 3481 0 \nL 794 0 \nL 794 531 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use xlink:href=\"#m95b1b4a59b\" x=\"268.673782\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 125 -->\n      <g transform=\"translate(259.130032 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-32\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use xlink:href=\"#m95b1b4a59b\" x=\"309.459529\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 150 -->\n      <g transform=\"translate(299.915779 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_8\">\n     <g id=\"line2d_8\">\n      <g>\n       <use xlink:href=\"#m95b1b4a59b\" x=\"350.245276\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 175 -->\n      <g transform=\"translate(340.701526 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-31\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_9\">\n     <g id=\"line2d_9\">\n      <g>\n       <use xlink:href=\"#m95b1b4a59b\" x=\"391.031023\" y=\"288.430125\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 200 -->\n      <g transform=\"translate(381.487273 303.028562) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-32\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"127.246094\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_10\">\n     <!-- Epochs -->\n     <g transform=\"translate(210.788125 316.706687) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-45\" d=\"M 628 4666 \nL 3578 4666 \nL 3578 4134 \nL 1259 4134 \nL 1259 2753 \nL 3481 2753 \nL 3481 2222 \nL 1259 2222 \nL 1259 531 \nL 3634 531 \nL 3634 0 \nL 628 0 \nL 628 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-70\" d=\"M 1159 525 \nL 1159 -1331 \nL 581 -1331 \nL 581 3500 \nL 1159 3500 \nL 1159 2969 \nQ 1341 3281 1617 3432 \nQ 1894 3584 2278 3584 \nQ 2916 3584 3314 3078 \nQ 3713 2572 3713 1747 \nQ 3713 922 3314 415 \nQ 2916 -91 2278 -91 \nQ 1894 -91 1617 61 \nQ 1341 213 1159 525 \nz\nM 3116 1747 \nQ 3116 2381 2855 2742 \nQ 2594 3103 2138 3103 \nQ 1681 3103 1420 2742 \nQ 1159 2381 1159 1747 \nQ 1159 1113 1420 752 \nQ 1681 391 2138 391 \nQ 2594 391 2855 752 \nQ 3116 1113 3116 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-6f\" d=\"M 1959 3097 \nQ 1497 3097 1228 2736 \nQ 959 2375 959 1747 \nQ 959 1119 1226 758 \nQ 1494 397 1959 397 \nQ 2419 397 2687 759 \nQ 2956 1122 2956 1747 \nQ 2956 2369 2687 2733 \nQ 2419 3097 1959 3097 \nz\nM 1959 3584 \nQ 2709 3584 3137 3096 \nQ 3566 2609 3566 1747 \nQ 3566 888 3137 398 \nQ 2709 -91 1959 -91 \nQ 1206 -91 779 398 \nQ 353 888 353 1747 \nQ 353 2609 779 3096 \nQ 1206 3584 1959 3584 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-63\" d=\"M 3122 3366 \nL 3122 2828 \nQ 2878 2963 2633 3030 \nQ 2388 3097 2138 3097 \nQ 1578 3097 1268 2742 \nQ 959 2388 959 1747 \nQ 959 1106 1268 751 \nQ 1578 397 2138 397 \nQ 2388 397 2633 464 \nQ 2878 531 3122 666 \nL 3122 134 \nQ 2881 22 2623 -34 \nQ 2366 -91 2075 -91 \nQ 1284 -91 818 406 \nQ 353 903 353 1747 \nQ 353 2603 823 3093 \nQ 1294 3584 2113 3584 \nQ 2378 3584 2631 3529 \nQ 2884 3475 3122 3366 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-68\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 4863 \nL 1159 4863 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n       <path id=\"DejaVuSans-73\" d=\"M 2834 3397 \nL 2834 2853 \nQ 2591 2978 2328 3040 \nQ 2066 3103 1784 3103 \nQ 1356 3103 1142 2972 \nQ 928 2841 928 2578 \nQ 928 2378 1081 2264 \nQ 1234 2150 1697 2047 \nL 1894 2003 \nQ 2506 1872 2764 1633 \nQ 3022 1394 3022 966 \nQ 3022 478 2636 193 \nQ 2250 -91 1575 -91 \nQ 1294 -91 989 -36 \nQ 684 19 347 128 \nL 347 722 \nQ 666 556 975 473 \nQ 1284 391 1588 391 \nQ 1994 391 2212 530 \nQ 2431 669 2431 922 \nQ 2431 1156 2273 1281 \nQ 2116 1406 1581 1522 \nL 1381 1569 \nQ 847 1681 609 1914 \nQ 372 2147 372 2553 \nQ 372 3047 722 3315 \nQ 1072 3584 1716 3584 \nQ 2034 3584 2315 3537 \nQ 2597 3491 2834 3397 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-45\"/>\n      <use xlink:href=\"#DejaVuSans-70\" x=\"63.183594\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"126.660156\"/>\n      <use xlink:href=\"#DejaVuSans-63\" x=\"187.841797\"/>\n      <use xlink:href=\"#DejaVuSans-68\" x=\"242.822266\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"306.201172\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_10\">\n      <defs>\n       <path id=\"m5587550629\" d=\"M 0 0 \nL -3.5 0 \n\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </defs>\n      <g>\n       <use xlink:href=\"#m5587550629\" x=\"50.14375\" y=\"257.36639\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 0.70 -->\n      <g transform=\"translate(20.878125 261.165609) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-2e\" d=\"M 684 794 \nL 1344 794 \nL 1344 0 \nL 684 0 \nL 684 794 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_11\">\n      <g>\n       <use xlink:href=\"#m5587550629\" x=\"50.14375\" y=\"199.175193\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 0.75 -->\n      <g transform=\"translate(20.878125 202.974412) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-37\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_12\">\n      <g>\n       <use xlink:href=\"#m5587550629\" x=\"50.14375\" y=\"140.983995\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 0.80 -->\n      <g transform=\"translate(20.878125 144.783214) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-38\" d=\"M 2034 2216 \nQ 1584 2216 1326 1975 \nQ 1069 1734 1069 1313 \nQ 1069 891 1326 650 \nQ 1584 409 2034 409 \nQ 2484 409 2743 651 \nQ 3003 894 3003 1313 \nQ 3003 1734 2745 1975 \nQ 2488 2216 2034 2216 \nz\nM 1403 2484 \nQ 997 2584 770 2862 \nQ 544 3141 544 3541 \nQ 544 4100 942 4425 \nQ 1341 4750 2034 4750 \nQ 2731 4750 3128 4425 \nQ 3525 4100 3525 3541 \nQ 3525 3141 3298 2862 \nQ 3072 2584 2669 2484 \nQ 3125 2378 3379 2068 \nQ 3634 1759 3634 1313 \nQ 3634 634 3220 271 \nQ 2806 -91 2034 -91 \nQ 1263 -91 848 271 \nQ 434 634 434 1313 \nQ 434 1759 690 2068 \nQ 947 2378 1403 2484 \nz\nM 1172 3481 \nQ 1172 3119 1398 2916 \nQ 1625 2713 2034 2713 \nQ 2441 2713 2670 2916 \nQ 2900 3119 2900 3481 \nQ 2900 3844 2670 4047 \nQ 2441 4250 2034 4250 \nQ 1625 4250 1398 4047 \nQ 1172 3844 1172 3481 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_13\">\n      <g>\n       <use xlink:href=\"#m5587550629\" x=\"50.14375\" y=\"82.792797\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 0.85 -->\n      <g transform=\"translate(20.878125 86.592016) scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-38\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-35\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_14\">\n      <g>\n       <use xlink:href=\"#m5587550629\" x=\"50.14375\" y=\"24.6016\" style=\"stroke: #000000; stroke-width: 0.8\"/>\n      </g>\n     </g>\n     <g id=\"text_15\">\n      <!-- 0.90 -->\n      <g transform=\"translate(20.878125 28.400819) scale(0.1 -0.1)\">\n       <defs>\n        <path id=\"DejaVuSans-39\" d=\"M 703 97 \nL 703 672 \nQ 941 559 1184 500 \nQ 1428 441 1663 441 \nQ 2288 441 2617 861 \nQ 2947 1281 2994 2138 \nQ 2813 1869 2534 1725 \nQ 2256 1581 1919 1581 \nQ 1219 1581 811 2004 \nQ 403 2428 403 3163 \nQ 403 3881 828 4315 \nQ 1253 4750 1959 4750 \nQ 2769 4750 3195 4129 \nQ 3622 3509 3622 2328 \nQ 3622 1225 3098 567 \nQ 2575 -91 1691 -91 \nQ 1453 -91 1209 -44 \nQ 966 3 703 97 \nz\nM 1959 2075 \nQ 2384 2075 2632 2365 \nQ 2881 2656 2881 3163 \nQ 2881 3666 2632 3958 \nQ 2384 4250 1959 4250 \nQ 1534 4250 1286 3958 \nQ 1038 3666 1038 3163 \nQ 1038 2656 1286 2365 \nQ 1534 2075 1959 2075 \nz\n\" transform=\"scale(0.015625)\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-30\"/>\n       <use xlink:href=\"#DejaVuSans-2e\" x=\"63.623047\"/>\n       <use xlink:href=\"#DejaVuSans-39\" x=\"95.410156\"/>\n       <use xlink:href=\"#DejaVuSans-30\" x=\"159.033203\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"text_16\">\n     <!-- loss -->\n     <g transform=\"translate(14.798438 165.031937) rotate(-90) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-6c\" d=\"M 603 4863 \nL 1178 4863 \nL 1178 0 \nL 603 0 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-6c\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"27.783203\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"88.964844\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"141.064453\"/>\n     </g>\n    </g>\n   </g>\n   <g id=\"line2d_15\">\n    <path d=\"M 66.376477 158.435219 \nL 68.007907 88.229104 \nL 69.639337 167.689016 \nL 71.270767 129.005704 \nL 72.902197 247.248404 \nL 76.165057 34.414125 \nL 77.796486 253.804359 \nL 79.427916 106.682035 \nL 81.059346 180.04383 \nL 82.690776 138.575617 \nL 84.322206 106.264501 \nL 85.953636 127.625879 \nL 87.585066 163.819665 \nL 89.216496 95.780231 \nL 90.847925 127.655708 \nL 92.479355 123.545299 \nL 94.110785 74.308903 \nL 95.742215 155.289945 \nL 97.373645 217.94535 \nL 99.005075 168.432794 \nL 100.636505 151.729912 \nL 102.267935 196.073621 \nL 103.899364 154.594587 \nL 105.530794 173.491551 \nL 107.162224 120.660368 \nL 108.793654 131.434324 \nL 110.425084 108.086625 \nL 112.056514 144.905567 \nL 113.687944 212.631522 \nL 115.319374 173.303283 \nL 116.950803 206.438784 \nL 118.582233 157.966491 \nL 120.213663 117.798329 \nL 121.845093 158.851227 \nL 123.476523 206.529034 \nL 125.107953 205.357039 \nL 126.739383 177.312413 \nL 128.370813 189.925905 \nL 130.002242 118.045006 \nL 131.633672 180.267823 \nL 133.265102 161.500996 \nL 134.896532 161.129524 \nL 136.527962 159.44378 \nL 138.159392 77.205072 \nL 139.790822 128.447351 \nL 141.422252 159.467712 \nL 143.053681 162.886371 \nL 144.685111 148.81106 \nL 146.316541 124.869351 \nL 147.947971 207.450119 \nL 149.579401 140.162649 \nL 151.210831 172.232706 \nL 152.842261 245.124802 \nL 154.473691 116.999264 \nL 156.10512 121.656719 \nL 157.73655 164.187323 \nL 159.36798 182.858212 \nL 160.99941 155.438881 \nL 162.63084 208.754956 \nL 164.26227 196.792773 \nL 165.8937 182.882006 \nL 167.52513 130.759569 \nL 169.15656 236.994649 \nL 170.787989 219.386289 \nL 172.419419 162.207384 \nL 174.050849 207.075317 \nL 175.682279 218.160048 \nL 177.313709 130.295002 \nL 178.945139 214.013358 \nL 180.576569 206.391405 \nL 182.207999 234.62534 \nL 183.839428 140.200524 \nL 185.470858 200.795937 \nL 187.102288 154.137305 \nL 188.733718 198.974022 \nL 190.365148 171.696898 \nL 191.996578 198.00188 \nL 193.628008 111.575138 \nL 195.259438 168.770207 \nL 196.890867 163.033434 \nL 198.522297 176.956479 \nL 200.153727 184.568582 \nL 201.785157 168.213657 \nL 203.416587 129.031302 \nL 205.048017 163.108214 \nL 206.679447 166.493228 \nL 208.310877 187.227716 \nL 209.942306 141.167047 \nL 211.573736 172.872638 \nL 213.205166 109.301698 \nL 214.836596 185.358768 \nL 216.468026 235.667128 \nL 219.730886 124.90251 \nL 221.362316 180.507564 \nL 222.993745 217.875079 \nL 224.625175 225.664767 \nL 226.256605 128.392063 \nL 227.888035 160.685907 \nL 229.519465 220.99864 \nL 231.150895 204.815542 \nL 232.782325 227.790589 \nL 234.413755 153.775752 \nL 236.045184 198.007499 \nL 237.676614 139.594722 \nL 239.308044 219.058797 \nL 240.939474 207.755414 \nL 242.570904 224.874373 \nL 244.202334 219.306931 \nL 245.833764 196.226373 \nL 247.465194 156.517713 \nL 249.096623 169.168109 \nL 250.728053 204.832538 \nL 252.359483 193.040448 \nL 253.990913 174.366853 \nL 255.622343 207.850727 \nL 257.253773 161.316058 \nL 258.885203 204.271132 \nL 260.516633 193.429679 \nL 262.148062 225.038639 \nL 263.779492 178.006176 \nL 265.410922 194.80118 \nL 267.042352 196.915557 \nL 268.673782 164.021322 \nL 270.305212 174.761149 \nL 271.936642 219.067676 \nL 273.568072 242.115561 \nL 275.199501 122.636838 \nL 276.830931 198.580975 \nL 278.462361 173.599767 \nL 280.093791 211.780776 \nL 281.725221 181.105042 \nL 283.356651 158.200057 \nL 284.988081 196.290262 \nL 286.619511 194.215009 \nL 288.25094 196.02541 \nL 289.88237 227.330948 \nL 291.5138 167.427078 \nL 293.14523 175.634508 \nL 294.77666 179.653281 \nL 296.40809 199.312544 \nL 298.03952 171.353936 \nL 299.67095 211.769261 \nL 301.30238 138.617378 \nL 304.565239 243.405344 \nL 306.196669 204.516699 \nL 307.828099 201.703704 \nL 309.459529 180.99745 \nL 311.090959 176.38113 \nL 312.722389 260.226987 \nL 314.353819 250.31536 \nL 315.985248 235.486976 \nL 317.616678 207.931334 \nL 319.248108 212.109032 \nL 320.879538 213.207217 \nL 322.510968 171.336039 \nL 324.142398 212.602872 \nL 325.773828 193.033789 \nL 327.405258 209.635808 \nL 329.036687 175.571868 \nL 330.668117 225.548157 \nL 332.299547 242.032942 \nL 333.930977 209.841696 \nL 335.562407 209.620963 \nL 337.193837 165.64165 \nL 338.825267 188.680101 \nL 343.719556 245.726372 \nL 345.350986 217.923082 \nL 346.982416 185.217532 \nL 348.613846 193.203952 \nL 350.245276 236.4467 \nL 351.876706 232.408851 \nL 353.508136 128.200535 \nL 355.139565 191.908272 \nL 356.770995 220.333735 \nL 358.402425 161.846386 \nL 360.033855 222.710605 \nL 361.665285 229.314148 \nL 363.296715 209.28355 \nL 364.928145 229.668139 \nL 366.559575 179.016262 \nL 368.191004 193.694531 \nL 369.822434 257.535596 \nL 371.453864 257.917197 \nL 373.085294 233.425875 \nL 374.716724 212.668842 \nL 376.348154 176.871849 \nL 377.979584 237.074285 \nL 379.611014 182.129418 \nL 381.242443 258.192177 \nL 382.873873 229.93868 \nL 384.505303 213.910484 \nL 386.136733 276.334125 \nL 387.768163 217.743346 \nL 389.399593 203.619338 \nL 391.031023 185.979207 \nL 391.031023 185.979207 \n\" clip-path=\"url(#pe8cf7a6fa4)\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"line2d_16\">\n    <path d=\"M 66.376477 148.166064 \nL 68.007907 149.978337 \nL 69.639337 151.522012 \nL 71.270767 152.515103 \nL 76.165057 154.949828 \nL 82.690776 157.021473 \nL 85.953636 158.7145 \nL 89.216496 160.251031 \nL 90.847925 161.271384 \nL 92.479355 162.139263 \nL 97.373645 165.109102 \nL 100.636505 166.286854 \nL 102.267935 166.820374 \nL 105.530794 168.031909 \nL 107.162224 168.437442 \nL 115.319374 171.203058 \nL 121.845093 172.735287 \nL 123.476523 173.024072 \nL 128.370813 174.296235 \nL 138.159392 178.12452 \nL 141.422252 179.1353 \nL 146.316541 180.604195 \nL 149.579401 181.391121 \nL 151.210831 181.741783 \nL 154.473691 182.622773 \nL 165.8937 183.692448 \nL 172.419419 184.732363 \nL 178.945139 185.742311 \nL 182.207999 186.10865 \nL 183.839428 186.088047 \nL 188.733718 186.350263 \nL 195.259438 186.505651 \nL 205.048017 187.440055 \nL 209.942306 188.43058 \nL 211.573736 188.982135 \nL 229.519465 193.73317 \nL 232.782325 194.60757 \nL 236.045184 195.191729 \nL 242.570904 195.915043 \nL 245.833764 196.352486 \nL 247.465194 196.557403 \nL 258.885203 196.899671 \nL 262.148062 197.077812 \nL 270.305212 196.494554 \nL 271.936642 196.511411 \nL 280.093791 197.398228 \nL 281.725221 197.487091 \nL 288.25094 198.297602 \nL 291.5138 198.462284 \nL 296.40809 198.929556 \nL 304.565239 200.900893 \nL 307.828099 201.993668 \nL 312.722389 203.226569 \nL 320.879538 206.039841 \nL 322.510968 206.750183 \nL 324.142398 207.277875 \nL 329.036687 208.374188 \nL 342.088126 210.787824 \nL 345.350986 211.94206 \nL 350.245276 213.315087 \nL 353.508136 214.143426 \nL 361.665285 217.072059 \nL 364.928145 218.150544 \nL 366.559575 218.531451 \nL 369.822434 218.896195 \nL 377.979584 220.510003 \nL 381.242443 221.472224 \nL 384.505303 222.482103 \nL 386.136733 222.942368 \nL 391.031023 223.89689 \nL 391.031023 223.89689 \n\" clip-path=\"url(#pe8cf7a6fa4)\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 50.14375 288.430125 \nL 50.14375 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 407.26375 288.430125 \nL 407.26375 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 50.14375 288.430125 \nL 407.26375 288.430125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 50.14375 22.318125 \nL 407.26375 22.318125 \n\" style=\"fill: none; stroke: #000000; stroke-width: 0.8; stroke-linejoin: miter; stroke-linecap: square\"/>\n   </g>\n   <g id=\"text_17\">\n    <!-- Training and validation loss -->\n    <g transform=\"translate(146.89375 16.318125) scale(0.12 -0.12)\">\n     <defs>\n      <path id=\"DejaVuSans-54\" d=\"M -19 4666 \nL 3928 4666 \nL 3928 4134 \nL 2272 4134 \nL 2272 0 \nL 1638 0 \nL 1638 4134 \nL -19 4134 \nL -19 4666 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-72\" d=\"M 2631 2963 \nQ 2534 3019 2420 3045 \nQ 2306 3072 2169 3072 \nQ 1681 3072 1420 2755 \nQ 1159 2438 1159 1844 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1341 3275 1631 3429 \nQ 1922 3584 2338 3584 \nQ 2397 3584 2469 3576 \nQ 2541 3569 2628 3553 \nL 2631 2963 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-61\" d=\"M 2194 1759 \nQ 1497 1759 1228 1600 \nQ 959 1441 959 1056 \nQ 959 750 1161 570 \nQ 1363 391 1709 391 \nQ 2188 391 2477 730 \nQ 2766 1069 2766 1631 \nL 2766 1759 \nL 2194 1759 \nz\nM 3341 1997 \nL 3341 0 \nL 2766 0 \nL 2766 531 \nQ 2569 213 2275 61 \nQ 1981 -91 1556 -91 \nQ 1019 -91 701 211 \nQ 384 513 384 1019 \nQ 384 1609 779 1909 \nQ 1175 2209 1959 2209 \nL 2766 2209 \nL 2766 2266 \nQ 2766 2663 2505 2880 \nQ 2244 3097 1772 3097 \nQ 1472 3097 1187 3025 \nQ 903 2953 641 2809 \nL 641 3341 \nQ 956 3463 1253 3523 \nQ 1550 3584 1831 3584 \nQ 2591 3584 2966 3190 \nQ 3341 2797 3341 1997 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-69\" d=\"M 603 3500 \nL 1178 3500 \nL 1178 0 \nL 603 0 \nL 603 3500 \nz\nM 603 4863 \nL 1178 4863 \nL 1178 4134 \nL 603 4134 \nL 603 4863 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-6e\" d=\"M 3513 2113 \nL 3513 0 \nL 2938 0 \nL 2938 2094 \nQ 2938 2591 2744 2837 \nQ 2550 3084 2163 3084 \nQ 1697 3084 1428 2787 \nQ 1159 2491 1159 1978 \nL 1159 0 \nL 581 0 \nL 581 3500 \nL 1159 3500 \nL 1159 2956 \nQ 1366 3272 1645 3428 \nQ 1925 3584 2291 3584 \nQ 2894 3584 3203 3211 \nQ 3513 2838 3513 2113 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-67\" d=\"M 2906 1791 \nQ 2906 2416 2648 2759 \nQ 2391 3103 1925 3103 \nQ 1463 3103 1205 2759 \nQ 947 2416 947 1791 \nQ 947 1169 1205 825 \nQ 1463 481 1925 481 \nQ 2391 481 2648 825 \nQ 2906 1169 2906 1791 \nz\nM 3481 434 \nQ 3481 -459 3084 -895 \nQ 2688 -1331 1869 -1331 \nQ 1566 -1331 1297 -1286 \nQ 1028 -1241 775 -1147 \nL 775 -588 \nQ 1028 -725 1275 -790 \nQ 1522 -856 1778 -856 \nQ 2344 -856 2625 -561 \nQ 2906 -266 2906 331 \nL 2906 616 \nQ 2728 306 2450 153 \nQ 2172 0 1784 0 \nQ 1141 0 747 490 \nQ 353 981 353 1791 \nQ 353 2603 747 3093 \nQ 1141 3584 1784 3584 \nQ 2172 3584 2450 3431 \nQ 2728 3278 2906 2969 \nL 2906 3500 \nL 3481 3500 \nL 3481 434 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-20\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-64\" d=\"M 2906 2969 \nL 2906 4863 \nL 3481 4863 \nL 3481 0 \nL 2906 0 \nL 2906 525 \nQ 2725 213 2448 61 \nQ 2172 -91 1784 -91 \nQ 1150 -91 751 415 \nQ 353 922 353 1747 \nQ 353 2572 751 3078 \nQ 1150 3584 1784 3584 \nQ 2172 3584 2448 3432 \nQ 2725 3281 2906 2969 \nz\nM 947 1747 \nQ 947 1113 1208 752 \nQ 1469 391 1925 391 \nQ 2381 391 2643 752 \nQ 2906 1113 2906 1747 \nQ 2906 2381 2643 2742 \nQ 2381 3103 1925 3103 \nQ 1469 3103 1208 2742 \nQ 947 2381 947 1747 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-76\" d=\"M 191 3500 \nL 800 3500 \nL 1894 563 \nL 2988 3500 \nL 3597 3500 \nL 2284 0 \nL 1503 0 \nL 191 3500 \nz\n\" transform=\"scale(0.015625)\"/>\n      <path id=\"DejaVuSans-74\" d=\"M 1172 4494 \nL 1172 3500 \nL 2356 3500 \nL 2356 3053 \nL 1172 3053 \nL 1172 1153 \nQ 1172 725 1289 603 \nQ 1406 481 1766 481 \nL 2356 481 \nL 2356 0 \nL 1766 0 \nQ 1100 0 847 248 \nQ 594 497 594 1153 \nL 594 3053 \nL 172 3053 \nL 172 3500 \nL 594 3500 \nL 594 4494 \nL 1172 4494 \nz\n\" transform=\"scale(0.015625)\"/>\n     </defs>\n     <use xlink:href=\"#DejaVuSans-54\"/>\n     <use xlink:href=\"#DejaVuSans-72\" x=\"46.333984\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"87.447266\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"148.726562\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"176.509766\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"239.888672\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"267.671875\"/>\n     <use xlink:href=\"#DejaVuSans-67\" x=\"331.050781\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"394.527344\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"426.314453\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"487.59375\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"550.972656\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"614.449219\"/>\n     <use xlink:href=\"#DejaVuSans-76\" x=\"646.236328\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"705.416016\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"766.695312\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"794.478516\"/>\n     <use xlink:href=\"#DejaVuSans-64\" x=\"822.261719\"/>\n     <use xlink:href=\"#DejaVuSans-61\" x=\"885.738281\"/>\n     <use xlink:href=\"#DejaVuSans-74\" x=\"947.017578\"/>\n     <use xlink:href=\"#DejaVuSans-69\" x=\"986.226562\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1014.009766\"/>\n     <use xlink:href=\"#DejaVuSans-6e\" x=\"1075.191406\"/>\n     <use xlink:href=\"#DejaVuSans-20\" x=\"1138.570312\"/>\n     <use xlink:href=\"#DejaVuSans-6c\" x=\"1170.357422\"/>\n     <use xlink:href=\"#DejaVuSans-6f\" x=\"1198.140625\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1259.322266\"/>\n     <use xlink:href=\"#DejaVuSans-73\" x=\"1311.421875\"/>\n    </g>\n   </g>\n   <g id=\"legend_1\">\n    <g id=\"patch_7\">\n     <path d=\"M 320.673125 60.230625 \nL 400.26375 60.230625 \nQ 402.26375 60.230625 402.26375 58.230625 \nL 402.26375 29.318125 \nQ 402.26375 27.318125 400.26375 27.318125 \nL 320.673125 27.318125 \nQ 318.673125 27.318125 318.673125 29.318125 \nL 318.673125 58.230625 \nQ 318.673125 60.230625 320.673125 60.230625 \nz\n\" style=\"fill: #ffffff; opacity: 0.8; stroke: #cccccc; stroke-linejoin: miter\"/>\n    </g>\n    <g id=\"line2d_17\">\n     <path d=\"M 322.673125 35.416562 \nL 332.673125 35.416562 \nL 342.673125 35.416562 \n\" style=\"fill: none; stroke: #1f77b4; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_18\">\n     <!-- train_loss -->\n     <g transform=\"translate(350.673125 38.916562) scale(0.1 -0.1)\">\n      <defs>\n       <path id=\"DejaVuSans-5f\" d=\"M 3263 -1063 \nL 3263 -1509 \nL -63 -1509 \nL -63 -1063 \nL 3263 -1063 \nz\n\" transform=\"scale(0.015625)\"/>\n      </defs>\n      <use xlink:href=\"#DejaVuSans-74\"/>\n      <use xlink:href=\"#DejaVuSans-72\" x=\"39.208984\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"80.322266\"/>\n      <use xlink:href=\"#DejaVuSans-69\" x=\"141.601562\"/>\n      <use xlink:href=\"#DejaVuSans-6e\" x=\"169.384766\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"232.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"282.763672\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"310.546875\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"371.728516\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"423.828125\"/>\n     </g>\n    </g>\n    <g id=\"line2d_18\">\n     <path d=\"M 322.673125 50.372813 \nL 332.673125 50.372813 \nL 342.673125 50.372813 \n\" style=\"fill: none; stroke: #ff7f0e; stroke-width: 1.5; stroke-linecap: square\"/>\n    </g>\n    <g id=\"text_19\">\n     <!-- val_loss -->\n     <g transform=\"translate(350.673125 53.872813) scale(0.1 -0.1)\">\n      <use xlink:href=\"#DejaVuSans-76\"/>\n      <use xlink:href=\"#DejaVuSans-61\" x=\"59.179688\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"120.458984\"/>\n      <use xlink:href=\"#DejaVuSans-5f\" x=\"148.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6c\" x=\"198.242188\"/>\n      <use xlink:href=\"#DejaVuSans-6f\" x=\"226.025391\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"287.207031\"/>\n      <use xlink:href=\"#DejaVuSans-73\" x=\"339.306641\"/>\n     </g>\n    </g>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"pe8cf7a6fa4\">\n   <rect x=\"50.14375\" y=\"22.318125\" width=\"357.12\" height=\"266.112\"/>\n  </clipPath>\n </defs>\n</svg>\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The weight regularization layer of keras is applying penalties to the parameters of layers. The weight regularization layer will expose three keyword arguments as follows:\n",
        "#Kernel Regularizer\n",
        "#Bias Regularizer\n",
        "#Activity Regularizer\n",
        "\n"
      ],
      "metadata": {
        "id": "ki8x7ckbMndq"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "h54WYarTMnhN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xKUSuivGMnj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wgf7b9i9Mnmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2hJNU0hbMnpy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "tf-tutorial",
      "language": "python",
      "name": "tf-tutorial"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}